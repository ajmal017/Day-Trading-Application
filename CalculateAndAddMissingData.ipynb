{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED\n"
     ]
    }
   ],
   "source": [
    "from nyse_dates_prds import *\n",
    "from sys import stdout\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import urllib\n",
    "import time\n",
    "\n",
    "print \"LOADED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED\n"
     ]
    }
   ],
   "source": [
    "def returns_create(highlowclose, periods, start):\n",
    "    \"\"\"\n",
    "    This calculates the return values which is the closing price divided by the previous\n",
    "    period's closing price minus 1. This gets us a percentage increase or decrease over\n",
    "    that time period.\n",
    "    \"\"\"\n",
    "    rets_dict, count = {}, 0\n",
    "    for name in highlowclose.keys():\n",
    "        df     = pd.DataFrame()\n",
    "        close  = highlowclose[name]['Closes']\n",
    "        # Return periods include 1,2,3,4,and 5 minute intervals that other indicators dont\n",
    "        prds   = [1,2,3,4,5] + periods[name][0]\n",
    "        \n",
    "        # Create our return values for each different period length, replacing any infinis\n",
    "        # that occur due to a bug in pandas when dividing by zero.\n",
    "        for x in range(32):\n",
    "            df[x] = (((close / close.shift(prds[x])) - 1.).fillna(0)).replace([np.inf], 0)\n",
    "        \n",
    "        # Starting value is used because this is an update method, updated from that point\n",
    "        rets_dict[name] = df[start:]\n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush()\n",
    "        count += 1\n",
    "    print \"RET DONE\"\n",
    "    return rets_dict\n",
    "\n",
    "def per_create(highlowclose, periods, start):\n",
    "    \"\"\"\n",
    "    Calculates the price to earnings ratio which is the closing price divided by the\n",
    "    difference between the closing price and the previous period's closing price.\n",
    "    \"\"\"\n",
    "    per_dict, count = {}, 0\n",
    "    for name in highlowclose.keys():\n",
    "        df     = pd.DataFrame()\n",
    "        cl     = highlowclose[name]['Closes']\n",
    "        prds   = periods[name][0]\n",
    "        \n",
    "        # For each different period, first subtract current closing price by previous\n",
    "        # periods closing price, replacing any zero with NaN to prevent divide by zero\n",
    "        # bug in pandas and then convert NaN back to zero after the series division done\n",
    "        for x in range(32): \n",
    "            clshf = (cl - cl.shift(prds[x])).replace(0,np.NaN)\n",
    "            df[x] = (cl / clshf).fillna(0)\n",
    "        \n",
    "        per_dict[name] = df[start:]\n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush()\n",
    "        count += 1\n",
    "    print \"PER DONE\"\n",
    "    return per_dict\n",
    "\n",
    "def kdo_create(highlowclose, periods, start):  \n",
    "    \"\"\"\n",
    "    This is the stochastic oscillator calculation, which takes each periods max and min\n",
    "    value. Then we first subtract the closing price minus the minimum, then we subtract\n",
    "    the max from the min. We then divide our first calculation by the second and multiply\n",
    "    by 100 which gets us the K oscillator. Then we take the rolling mean value of the small\n",
    "    period of the k values to get our D oscillator.\n",
    "    \"\"\"\n",
    "    d_dict, count = {}, 0\n",
    "    for name in highlowclose.keys(): \n",
    "        d_df       = pd.DataFrame()\n",
    "        high, low  = highlowclose[name]['Highs'], highlowclose[name]['Lows']\n",
    "        close      = highlowclose[name]['Closes']\n",
    "        prds       = periods[name][1]\n",
    "        \n",
    "        # For each period, there's a small and large period, large for k oscillator calc\n",
    "        # and the small for the d oscillator using the k oscillators.\n",
    "        for x in range(32):\n",
    "            num  = prds[x]\n",
    "            num2 = prds[x+1]\n",
    "            # Get rolling period minimums and maximums for lows and highs respectively\n",
    "            prev_max  = high.rolling(window = num2, center = False).max()\n",
    "            prev_min  = low.rolling(window  = num2, center = False).min()\n",
    "        \n",
    "            cl  =  close    - prev_min\n",
    "            hl  = (prev_max - prev_min).replace(0., np.NaN)\n",
    "            \n",
    "            # K and D oscillators, the D which is important to us\n",
    "            k_df    = ((cl / hl) * 100.).fillna(0.)\n",
    "            d_df[x] = (k_df.rolling(window=num, center=False).mean()).fillna(0.)\n",
    "            \n",
    "        d_dict[name] = d_df[start:]\n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush()\n",
    "        count += 1\n",
    "    print \"KDO DONE\"\n",
    "    return d_dict\n",
    "\n",
    "def cci_create(highlowclose, periods, start):\n",
    "    \"\"\"\n",
    "    This is our commodity channel index calculation\n",
    "    \"\"\"\n",
    "    cci_dict, count, constant = {}, 0, 0.015\n",
    "    for name in highlowclose.keys():\n",
    "        df   = pd.DataFrame()\n",
    "        # Typical price == closing + high + low / 3 at each time step for ref\n",
    "        typ  = highlowclose[name]['Typical']\n",
    "        prds = periods[name][0]\n",
    "        \n",
    "        for x in range(32):\n",
    "            num = prds[x]    \n",
    "            # Get rolling standard deviations and means\n",
    "            typ_std  = typ.rolling(window = num, center = False).std()\n",
    "            typ_mean = typ.rolling(window = num, center = False).mean()\n",
    "            ttmean   = typ - typ_mean\n",
    "            # Replace any zeros with NaN to avoid divide by zero bug in next step\n",
    "            ctmad    = (constant * typ_std).replace(0.,np.NaN)\n",
    "            df[x]    = (ttmean / ctmad).fillna(0.)\n",
    "        \n",
    "        cci_dict[name] = df[start:]      \n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush()\n",
    "        count += 1\n",
    "    print \"CCI DONE\"\n",
    "    return cci_dict\n",
    "\n",
    "def vol_create(highlowclose, periods, start):\n",
    "    \"\"\"\n",
    "    This is the volatility indicator calculation. We get this by taking the period return \n",
    "    values for that company, and then taking the standard deviation of each periods returns,\n",
    "    and multiplying that by the square root of the period length\n",
    "    \"\"\"\n",
    "    vol_dict, count = {}, 0\n",
    "    for name in highlowclose.keys():\n",
    "        vol_df = pd.DataFrame()\n",
    "        close  = highlowclose[name]['Closes']\n",
    "        prds   = periods[name][2]\n",
    "        \n",
    "        for x in range(32): \n",
    "            # Uses two different periods, small and large, small for return calc portion,\n",
    "            # and large for the actual vol calculation\n",
    "            num       = prds[x]\n",
    "            num2      = prds[x+3]\n",
    "            rets      = (close / close.shift(num) - 1.).fillna(0.)\n",
    "            vol_df[x] = rets.rolling(window=num2, center=False).std() * np.sqrt(num2)\n",
    "        \n",
    "        vol_dict[name] = vol_df[start:]        \n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush()\n",
    "        count += 1\n",
    "    print \"VOL DONE\"\n",
    "    return vol_dict\n",
    "\n",
    "def bol_create(highlowclose, periods, start):\n",
    "    \"\"\"\n",
    "    This is the slightly altered bollinger band calculation. We get this by finding the \n",
    "    periods mean and standard deviation values, adding those together and multiplying by \n",
    "    two to get the upper band values. Rather than also calculating a lower band and using\n",
    "    it for if the rolling mean goes above/below, we do a modified version that works \n",
    "    better for our purpose in our case, just taking the ratio between the rolling mean \n",
    "    and the upper band. We then calculate the difference between closing prices and mean\n",
    "    prices, then subtract the upper band values by the mean prices, and then divide these\n",
    "    two answers to get our final bollinger band values.\n",
    "    \"\"\"\n",
    "    bol_dict, count = {}, 0\n",
    "    for name in highlowclose.keys():\n",
    "        df    = pd.DataFrame()\n",
    "        close = highlowclose[name]['Closes']\n",
    "        prds  = periods[name][0]\n",
    "        \n",
    "        for x in range(32):\n",
    "            num   = prds[x]\n",
    "            # Get rolling period means and standard deviations\n",
    "            rm    = (close.rolling(window=num, center=False).mean()).fillna(0)\n",
    "            rstd  = (close.rolling(window=num, center=False).std()).fillna(0)\n",
    "            # Create an upper band (lower band is rm - rstd*2) but since our bollinger\n",
    "            # calculation is slightly modified we dont need lower band.\n",
    "            upper = rm + rstd * 2. \n",
    "            clrm  = close - rm\n",
    "            uprm  = (upper - rm).replace(0.,np.NaN)\n",
    "            df[x] = (clrm / uprm).fillna(0.)\n",
    "            \n",
    "        bol_dict[name] = df[start:]        \n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush()\n",
    "        count += 1\n",
    "    print \"BOL DONE\"\n",
    "    return bol_dict\n",
    "\n",
    "def mom_create(highlowclose, periods, start):\n",
    "    \"\"\"\n",
    "    This is the momentum calculator, which is simply the the difference between current\n",
    "    closing price, and closing price x periods ago, multiplied by 100\n",
    "    \"\"\"\n",
    "    mom_dict, count = {}, 0\n",
    "    for name in highlowclose.keys():\n",
    "        df     = pd.DataFrame()\n",
    "        close  = highlowclose[name]['Closes']\n",
    "        prds   = periods[name][0]\n",
    "        \n",
    "        for x in range(32):\n",
    "            num   = prds[x]\n",
    "            df[x] = (((close - close.shift(num)) / close.shift(num)) * 100.).fillna(0.)\n",
    "        \n",
    "        mom_dict[name] = df[start:]        \n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush()\n",
    "        count += 1\n",
    "    print \"MOM DONE\"\n",
    "    return mom_dict\n",
    "\n",
    "def sma_create(highlowclose, periods, start):\n",
    "    \"\"\"\n",
    "    This is the simple moving average calculation. This is simply the mean closing price\n",
    "    during that period.\n",
    "    \"\"\"\n",
    "    sma_dict, count = {}, 0\n",
    "    for name in highlowclose.keys():\n",
    "        df    = pd.DataFrame()\n",
    "        close = highlowclose[name]['Closes']\n",
    "        prds  = periods[name][0]\n",
    "        \n",
    "        for x in range(32):\n",
    "            num   = prds[x]\n",
    "            # Rolling mean of closing prices, filling NaN's with zero\n",
    "            df[x] = (close.rolling(window=num, center=False).mean()).fillna(0.)\n",
    "            \n",
    "        sma_dict[name] = df[start:]        \n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush()\n",
    "        count += 1\n",
    "    print \"SMA DONE\"\n",
    "    return sma_dict\n",
    "\n",
    "def aro_create(highlowclose, periods, start):\n",
    "    \"\"\"\n",
    "    This is the aroon indicator calculation. For each periods values, you how many periods it has\n",
    "    been since you've had the max during that period as well as the min, and subtract from \n",
    "    eachother\n",
    "    \"\"\"\n",
    "    aro_dict, count = {}, 0\n",
    "    for name in highlowclose.keys():\n",
    "        df     = pd.DataFrame()\n",
    "        close  = highlowclose[name]['Closes']\n",
    "        prds   = periods[name][0]\n",
    "        \n",
    "        for x in range(32):\n",
    "            num   = prds[x]\n",
    "            # Using an applied method for each period to cut down on computation time\n",
    "            df[x] = close.rolling(window=num, center=False).apply(aro_apply, args=(num,))\n",
    "            \n",
    "        aro_dict[name] = df[start:]        \n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush()\n",
    "        count += 1\n",
    "    print \"ARO DONE\"\n",
    "    return aro_dict\n",
    "def aro_apply(df, prd):\n",
    "    # For each rolling period, find the number of days since last period min/max, then\n",
    "    # divide by the period length and finally multiply by 100 to get the upper/lower aroon bands\n",
    "    # Then subtract the upper by lower values\n",
    "    up      = ((prd - df.argmax()) / float(prd)) * 100.\n",
    "    down    = ((prd - df.argmin()) / float(prd)) * 100.\n",
    "    return up - down\n",
    "\n",
    "def mac_create(highlowclose, periods, start):\n",
    "    \"\"\"\n",
    "    This is the moving average convergence divergence calculation. To get this we take the \n",
    "    expected moving average of the smaller period, and the larger period. Subtract from eachother,\n",
    "    then take the expected moving average of the smallest period on those calculated values to get\n",
    "    an buy/sell indicator of the macd calculation and use both of these.\n",
    "    \"\"\"\n",
    "    mac_dict, mac_dict2, count = {}, {}, 0\n",
    "    for name in highlowclose.keys():\n",
    "        macd_df, macd_df2  = pd.DataFrame(), pd.DataFrame()\n",
    "        close              = highlowclose[name]['Closes']\n",
    "        prds               = periods[name][2]\n",
    "        \n",
    "        for x in range(32):\n",
    "            # This indicator uses 3 period lengths in its calculation, a small, medium, and large\n",
    "            num, num2, num3 = prds[x], prds[x+1], prds[x+3]\n",
    "            \n",
    "            # ewm stands for expected weighted moving means that its a rolling calculation which\n",
    "            # weights more recent vals more heavily than less recent. \n",
    "            # Get our mid and large rolling ewm averages of closing prices, subtract them, then\n",
    "            # get our modified version of the macd which is the ewm average of the macd, div macd \n",
    "            # by this and subtract one\n",
    "            mid    = close.ewm(ignore_na=False, span=num2, min_periods=0, adjust=True).mean()\n",
    "            large  = close.ewm(ignore_na=False, span=num3, min_periods=0, adjust=True).mean()\n",
    "            macd   = large - mid\n",
    "            small  = macd.ewm(ignore_na=False, span=num, min_periods=0, adjust=True).mean()\n",
    "            result = (macd / small) - 1.\n",
    "            \n",
    "            # we calculate two indicators for this one.\n",
    "            macd_df[x]  = macd\n",
    "            macd_df2[x] = result\n",
    "        \n",
    "        mac_dict[name]  = macd_df[start:]  \n",
    "        mac_dict2[name] = macd_df2[start:]\n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush()\n",
    "        count += 1\n",
    "    print \"MAC DONE\"\n",
    "    return mac_dict, mac_dict2\n",
    "    \n",
    "def adx_create(highlowclose, periods, start):\n",
    "    \"\"\"\n",
    "    This is the average directional index calculation. Get the true range values, then\n",
    "    get the positive and negative directional movment and put these in a dataframe that\n",
    "    is used for precalculation purposes during our real-time calculations. You'll keep\n",
    "    the directional index as well for the same purpose. This is the most complicated \n",
    "    indicator we have so don't fret if you dont follow it right away.\n",
    "    \"\"\"\n",
    "    tr_df_dict, adx_dict, adx_dict2, count = {}, {}, {}, 0\n",
    "    for name in highlowclose.keys():\n",
    "        adx_df, dx_df = pd.DataFrame(), pd.DataFrame()\n",
    "        \n",
    "        high, low = highlowclose[name]['Highs'], highlowclose[name]['Lows']\n",
    "        close     = highlowclose[name]['Closes']\n",
    "        prds      = periods[name][0]\n",
    "        \n",
    "        for x in range(32):\n",
    "            trpm_df = pd.DataFrame()\n",
    "            num     = prds[x]\n",
    "            \n",
    "            tr_df      = pd.DataFrame()\n",
    "            # Get our true range values by taking the maximum value of the below three calcs\n",
    "            tr_df[0]   = (high - low)\n",
    "            tr_df[1]   = (high - close.shift(num)).fillna(0.)\n",
    "            tr_df[2]   = (low  - close.shift(num)).fillna(0.)\n",
    "            true_range = tr_df.max(axis=1)\n",
    "            \n",
    "            # calculate positive and negative directional indicators\n",
    "            plus_dm   = (high - high.shift(num)).fillna(0.)\n",
    "            minus_dm  = (low.shift(num) - low).fillna(0.)\n",
    "            # For each pos/neg direc inds, if pos >= than minus, take positive, else take neg\n",
    "            plus_dm   = pd.Series(np.where(plus_dm >= minus_dm, plus_dm, 0.),index=plus_dm.index)\n",
    "            minus_dm  = pd.Series(np.where(minus_dm >= plus_dm, minus_dm, 0.),index=plus_dm.index)\n",
    "            # If any values are below 0, set them to 0\n",
    "            plus_dm[plus_dm < 0]   = 0.\n",
    "            minus_dm[minus_dm < 0] = 0.\n",
    "        \n",
    "            # Put the true_range and pos/neg directional indicators into a dataframe so these \n",
    "            # can provide precalculated values for the real-time calculations\n",
    "            trpm_df[0] = true_range\n",
    "            trpm_df[1] = plus_dm\n",
    "            trpm_df[2] = minus_dm\n",
    "            \n",
    "            # Dictionary key value is the company plus the period value\n",
    "            tr_name = name+str(x)\n",
    "            # We only need a certain number of precalculated values for each entry.\n",
    "            tr_df_dict[tr_name] = trpm_df[len(true_range)-num-1:]\n",
    "            \n",
    "            # Calculate first the average true range, using the expected weighted mean of the\n",
    "            # true ranges, then calculate the positive and negative directional movements\n",
    "            atr    = true_range.ewm(ignore_na=False, span=num, min_periods=0, adjust=True).mean()\n",
    "            pos_dm = plus_dm.ewm(ignore_na=False, span=num, min_periods=0, adjust=True).mean()\n",
    "            neg_dm = minus_dm.ewm(ignore_na=False, span=num, min_periods=0, adjust=True).mean()\n",
    "\n",
    "            # Calculate the positive and negative directional indexes, replacing divide by zero\n",
    "            # infinity bug by zero if any.\n",
    "            pos_di  = ((pos_dm / atr) * 100.).replace([np.inf],0.)\n",
    "            neg_di  = ((neg_dm / atr) * 100.).replace([np.inf],0.)\n",
    "            # Calculate the directional index, replacing any zero infinity bugs by zero\n",
    "            dx_df[x] = (abs(pos_di - neg_di) / (pos_di + neg_di)).replace([np.inf],0.)\n",
    "            \n",
    "            # Calculate the average weighted moving average directional index\n",
    "            adx_df[x] = dx_df[x].ewm(ignore_na=False, span=num, min_periods=0, \n",
    "                                     adjust=True).mean() * 100.\n",
    "        \n",
    "        adx_dict[name] = adx_df[start:]\n",
    "        adx_dict2[name] = dx_df[start:]\n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush()\n",
    "        count += 1\n",
    "    print \"ADX DONE\"\n",
    "    return adx_dict, adx_dict2, tr_df_dict\n",
    "\n",
    "def rsi_create(highlowclose, periods, start):\n",
    "    \"\"\"\n",
    "    This is the relative strength index calculation. Take the positive and\n",
    "    negative values of the deltas and set everything else to 0. Then get the\n",
    "    positive and negative mean values of the deltas. After this, divide these\n",
    "    two series and get the rsi by adding 1, dividing 100 by this, and subtracting\n",
    "    this from 100.\n",
    "    \"\"\"\n",
    "    rsi_dict, count = {}, 0\n",
    "    for name in highlowclose.keys():\n",
    "        rsi_df = pd.DataFrame()\n",
    "        \n",
    "        close   = highlowclose[name]['Closes']\n",
    "        prds    = periods[name][2]\n",
    "\n",
    "        for x in range(32):\n",
    "            # Uses both small and large periods\n",
    "            num  = prds[x]\n",
    "            num2 = prds[x+3]\n",
    "            # Get closing price differences using small period\n",
    "            deltas  = (close - close.shift(num)).fillna(0.)\n",
    "            \n",
    "            # set up/down df as values above/below zero setting others to 0\n",
    "            up, down = deltas.copy(), deltas.copy()\n",
    "            up[up < 0]     = 0\n",
    "            down[down > 0] = 0\n",
    "\n",
    "            # Get rolling means of up/down dfs with down dfs taking absolute vals\n",
    "            rolup_df   =  up.rolling(window=num2, center=False).mean()\n",
    "            roldown_df = (down.rolling(window=num2, center=False).mean()).abs()\n",
    "\n",
    "            rol_updown = (rolup_df / roldown_df).replace([np.inf],0.)\n",
    "            rsi_df[x] = (100. - (100. / (1. + rol_updown))).replace([np.inf],0.)\n",
    "\n",
    "        rsi_dict[name]  = rsi_df[start:]\n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush()\n",
    "        count += 1\n",
    "    print \"RSI DONE\"\n",
    "    return rsi_dict\n",
    "   \n",
    "print \"LOADED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED\n"
     ]
    }
   ],
   "source": [
    "def resample_intraday(hlc):\n",
    "    \"\"\"\n",
    "    Make the indexes the same for each company, meaning we resample the times to be at the \n",
    "    beginning of each minute, rather than sometime during that minute. The reason we have\n",
    "    to resample one trading day at a time rather than on the whole dataframe is because\n",
    "    when you resampled on everything at once, it would add in the hours before and after\n",
    "    our trading hours, meaning before 9:30AM and after 4:00PM. The reason I chose to take\n",
    "    the the day's resampling is because it would base it on the first and last time. If I \n",
    "    chose to instead just remove the hours before and after trading hours was because it\n",
    "    would add data that I didn't necessarily have and not allow me to know I was missing \n",
    "    it. For example, some days would might be missing from my data source and it would\n",
    "    automatically feed it information for that day and I wouldn't know it did this. For \n",
    "    this reason I chose to resample for each day so if I was missing values it wouldn't\n",
    "    automatically interpolate data without notice.\n",
    "    \"\"\"\n",
    "    new_hlc, count = {}, 0\n",
    "    for key, value in hlc.iteritems():\n",
    "        new_df = pd.DataFrame()\n",
    "\n",
    "        # Ensure we don't have duplicate rows that curiously occurred several times\n",
    "        value  = value.reset_index().drop_duplicates(subset='index', \n",
    "                                                     keep='last').set_index('index')\n",
    "        # Take our index from our dataframe and convert the first and last timestamps\n",
    "        # to yyyy-mm-dd format getting rid of the time after the date\n",
    "        index  = value.index\n",
    "        start  = datetime.datetime.strptime((str(index[0])[:10]), '%Y-%m-%d').date()\n",
    "        end    = datetime.datetime.strptime((str(index[-1])[:10]), '%Y-%m-%d').date()\n",
    "        # Call our trading days function that will give us a list of trading days \n",
    "        # between our two given dates we feed it.\n",
    "        rs2    = NYSE_tradingdays2(start, end)\n",
    "        # How many trading days between the two dates\n",
    "        length = len(rs2[:])\n",
    "\n",
    "        for x in range(length):\n",
    "            # For each trading timestamp, first convert to date only in str format instead\n",
    "            # of both date and time which is given as 00:00:00\n",
    "            date   = str(rs2[x])[:10]\n",
    "            # Retrieve that date's values from our dataframe\n",
    "            day    = value[date]\n",
    "            # Resample each day, setting the time value to be the top of every minute\n",
    "            # This was done to match datetimes since dataframes usually were a second \n",
    "            # or two off between companies which meant it was harder to call a datetime\n",
    "            # for one or more companies at once.\n",
    "            reday  = day.resample('T').pad().fillna(method='bfill')\n",
    "            # Series are mutable, so we need to create a new dataframe with this new series\n",
    "            new_df = new_df.append(reday)  \n",
    "\n",
    "        new_hlc[key] = new_df\n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush() \n",
    "        count += 1\n",
    "    return new_hlc\n",
    "\n",
    "def add_new_data(intra_data):\n",
    "    \"\"\"\n",
    "    Get our new data, starting from the next trading day after our last trading day's data. We\n",
    "    call retrieve_bonnet_data function passing this next date, then adjust the highs and lows \n",
    "    to be the day's highs and lows, not just that minutes highs and lows by calling our \n",
    "    adjust_bonnet_high_lows function, passing the data that was retrieved from our \n",
    "    retrieve_bonnet_data call, and this returns our adjusted data. We then change the\n",
    "    index datetime strings to pandas timestamp indexes to help in our future calculations. \n",
    "    Finally we calculate the typical values for these new values and return the this new data as\n",
    "    well as the old data.\n",
    "    \"\"\"\n",
    "    # Get a companies stock symbol, doesn't matter which as long as the stocks have the same\n",
    "    # last update date\n",
    "    comp_key  = intra_data.keys()[0]\n",
    "    new_adj   = {}\n",
    "    # Previous date is the last day that we updated our highlowclose dictionary since present\n",
    "    prev_date = str((intra_data[comp_key].index)[-1])[:10]\n",
    "    # End date is just set as a year from the last update, just for simple way for future date\n",
    "    end_date  = str(int(prev_date[:4])+1) + prev_date[4:]\n",
    "    start     = datetime.datetime.strptime(prev_date, '%Y-%m-%d').date()\n",
    "    end       = datetime.datetime.strptime(end_date, '%Y-%m-%d').date()\n",
    "    rs2       = NYSE_tradingdays2(start, end)\n",
    "    # From date will be next trading day after our last update\n",
    "    from_date = str(rs2[1])[:10]\n",
    "    # Grab today's date to then send it to our today_func\n",
    "    today     = str(datetime.date.today())\n",
    "    \n",
    "    # Get at least an extra trading day into the future because if not done, you won't get\n",
    "    # the current days data\n",
    "    to_date         = today_func(today, rs2)\n",
    "    # Retrieve our data from our data source\n",
    "    data, small_lst = retrieve_bonnet_data(from_date, to_date, intra_data)\n",
    "    # Adjust our highs and lows to be day highs/lows rather than minute highs/lows\n",
    "    adj             = adjust_bonnet_high_lows(data, small_lst)\n",
    "    \n",
    "    # Convert from string timestamps to pandas timestamps\n",
    "    for key, value in adj.iteritems():\n",
    "        new_indx = []\n",
    "        \n",
    "        for each in value.index:\n",
    "            new_indx.append(pd.Timestamp(each))\n",
    "        \n",
    "        # Create our typical values columns for each company\n",
    "        value.index      = new_indx\n",
    "        value['Typical'] = (value['Highs'] + value['Lows'] + value['Closes']) / 3.\n",
    "        new_adj[key]     = value\n",
    "    return intra_data, new_adj\n",
    "\n",
    "def today_func(today, rs2):\n",
    "    \"\"\"\n",
    "    Calculate the next trading day so that when you grab data it gets you today's\n",
    "    data as well, because if you plug today's date into that url grab, it will only\n",
    "    grab up until the end of yesterday's data.\n",
    "    \"\"\"\n",
    "    to_date   = 'None'\n",
    "    while to_date == 'None':\n",
    "        for x in range(len(rs2[:])):\n",
    "            if str(rs2[x])[:10] == today:\n",
    "                to_date = str(rs2[x+1])[:10]\n",
    "                break\n",
    "            \n",
    "        if to_date == 'None':\n",
    "            if int(today[len(today)-2:]) < 9:\n",
    "                tomor = '0' + str(int(today[len(today)-2:])+1)\n",
    "            elif int(today[len(today)-2:]) > 28:\n",
    "                print \"TO_DATE FAIL\"\n",
    "                return\n",
    "            else:\n",
    "                tomor = str(int(today[len(today)-2:])+1)\n",
    "            today = today[:len(today)-2]+tomor\n",
    "    return to_date\n",
    "\n",
    "def retrieve_bonnet_data(fromd, today, intra):\n",
    "    \"\"\"\n",
    "    This function retrieves our new intraday trading data from our data source thanks to\n",
    "    The Bonnot Gang site, that gives us free intraday data, which the have available from\n",
    "    mid 2011 to present, but we just grab the data we need.\n",
    "    \n",
    "    We grab each of our companies we're calculating for's data, and convert the .csv format to\n",
    "    our dataframe format.\n",
    "    \"\"\"\n",
    "    pages   = {}\n",
    "    small_lst = []\n",
    "    # NOTE THAT THE TICKERS USED TO RETRIEVE HAVE 3 DIFFERENCE FROM THE YAHOO TICKERS, THE\n",
    "    # DJI, GSPC, IXIC ALL DON'T INCLUDE THE ^ PRIOR TO THE SYMBOL\n",
    "    tickers  = ['BPOP','FITB','HBAN','CMCSA','EBAY',\n",
    "                      'AAPL','AMAT','BRCD','CSCO','GOOG','INTC',\n",
    "                      'LVLT','MSFT','MU','NVDA','ORCL','QCOM',\n",
    "                      'SIRI','WIN','YHOO','BHP','BP',\n",
    "                      'RIO','XOM','GE','F','MO','XRX','GS','JPM',\n",
    "                      'LYG','MS','RF','USB','WFC','MRK','PFE','LMT',\n",
    "                      'MGM','AMD','GLW','HPQ','S','T',\n",
    "                      'USO', 'GLD', 'SPY','DJI', 'GSPC', 'IXIC']\n",
    "    \n",
    "    for name in tickers:\n",
    "        # If not the 3 indexes\n",
    "        if name in intra.keys():\n",
    "            page = 'http://www.thebonnotgang.com/quotes/q.php?timeframe=1m&dayFrom='+\\\n",
    "                   fromd+'&dayTo='+today+'&symbol='+name\n",
    "        # If it is, we'll rename them back to their yahoo format for the dictionary\n",
    "        elif (name=='DJI')or(name=='GSPC')or(name=='IXIC'):\n",
    "            page = 'http://www.thebonnotgang.com/quotes/q.php?timeframe=1m&dayFrom='+\\\n",
    "                   fromd+'&dayTo='+today+'&symbol='+name\n",
    "\n",
    "            if (name != 'DJI') and (name != 'GSPC') and (name != 'IXIC'):\n",
    "                name = name\n",
    "            else:\n",
    "                name = '^' + name\n",
    "        \n",
    "        # Retrieve a list of symbols were using with the updated index names\n",
    "        small_lst.append(name)\n",
    "        # Get our data from our data source using our provided url, setting that \n",
    "        # stocks values into a dictionary with its name as the entry\n",
    "        pages[name] = urllib.urlopen(page).read()\n",
    "    \n",
    "    # Then take the steps to convert data from strings containing data we don't \n",
    "    # need to just the data we need in the format we need it. Floats for highs,\n",
    "    # lows, and closes as well as the dates for each entries\n",
    "    complete_list = []\n",
    "    for each in small_lst:\n",
    "        current = pages[each]\n",
    "        start   = current.find('2016')\n",
    "        end     = len(current)\n",
    "        test    = True\n",
    "        df_list = []\n",
    "\n",
    "        while test == True:\n",
    "            date_end = current.find(';',start)\n",
    "            open_end = current.find(';',date_end+1)\n",
    "            high_end = current.find(';',open_end+1)\n",
    "            low_end  = current.find(';',high_end+1)\n",
    "            close_end = current.find(';',low_end+1)\n",
    "\n",
    "            date  = current[start:date_end]\n",
    "            try:\n",
    "                high  = float(current[open_end+1:high_end].replace(',','.'))\n",
    "            except:\n",
    "                print each\n",
    "                raise\n",
    "            low   = float(current[high_end+1:low_end].replace(',','.'))\n",
    "            close = float(current[low_end+1:close_end].replace(',','.'))\n",
    "\n",
    "            t = int(date[11:13])-4\n",
    "            if t < 10:\n",
    "                t = '0'+str(t)\n",
    "            else:\n",
    "                t = str(t)\n",
    "            date = date[0:11]+t+date[13:]\n",
    "\n",
    "            day = [date, high, low, close]\n",
    "            df_list.append(day)\n",
    "\n",
    "            start = current.find('2016-', close_end)\n",
    "            if start == -1:\n",
    "                break\n",
    "        \n",
    "        # Put all these values into a dataframe renaming the columns\n",
    "        # Set the Time column to be the index\n",
    "        df = pd.DataFrame(df_list, columns=['Time','Highs','Lows','Closes'])\n",
    "        df = df.set_index('Time')\n",
    "        \n",
    "        # Append each dataframe to our list, then return that list with the list of names\n",
    "        complete_list.append(df)\n",
    "    return complete_list, small_lst\n",
    "\n",
    "def adjust_bonnet_high_lows(adjusted_intra, tickers):\n",
    "    \"\"\"\n",
    "    We need to convert our days high and low values for each day to be the day high and low rather\n",
    "    than the minute high and low values.\n",
    "    \"\"\"\n",
    "    new_adjusted_intra = {}\n",
    "    for df, z in zip(adjusted_intra, range(len(adjusted_intra))):\n",
    "        # Adjust our higs/lows to day highs/lows instead of minute highs/lows and combine into\n",
    "        # new dataframe with closes and our index\n",
    "        highs  = df['Highs'].values.tolist()\n",
    "        lows   = df['Lows'].values.tolist()\n",
    "        closes = df['Closes'].values.tolist()\n",
    "        index  = df.index\n",
    "        prev   = 0\n",
    "\n",
    "        for x in xrange(1,len(highs)):\n",
    "            if index[x][8:10] == index[x-1][8:10]:\n",
    "                highs[x] = max(highs[prev:x+1])\n",
    "                lows[x]  = min(lows[prev:x+1])\n",
    "            else:\n",
    "                prev = x\n",
    "\n",
    "        df         = pd.DataFrame([index,highs,lows,closes]).T\n",
    "        df.columns = ['Time','Highs','Lows','Closes']\n",
    "        df         = df.set_index(['Time'])\n",
    "        \n",
    "        # Create our dictionary with our dataframes containing all of our new data\n",
    "        new_adjusted_intra[tickers[z]] = df\n",
    "    return new_adjusted_intra\n",
    "\n",
    "print \"LOADED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED\n"
     ]
    }
   ],
   "source": [
    "def get_new_data(update=False):\n",
    "    \"\"\"\n",
    "    Get the new data we need by calling our add_new_data function, and then\n",
    "    resample that data w/ our resample_intraday function. Then return the \n",
    "    new data as well as the old data, and also the short date which is the\n",
    "    data about 130 trading day's prior to present that we need to calculate\n",
    "    all our data, but only use that much so we don't have to calculate more\n",
    "    data than needed.\n",
    "    \"\"\"\n",
    "    # Retrieve our previous high/low/close/typical dataframes dictionary\n",
    "    opp      = open('Pickles/pickleadjustedintracomplete.pickle','rb')\n",
    "    new_hlc = pickle.load(opp)\n",
    "    opp.close()\n",
    "    \n",
    "    if update == True:\n",
    "        hlc = {}\n",
    "        opp = open('Pickles/onlyupdatedintra.pickle','rb')\n",
    "        already_updated = pickle.load(opp)\n",
    "        opp.close()\n",
    "        \n",
    "        for key, val in new_hlc.iteritems():\n",
    "            if key not in already_updated.keys():\n",
    "                hlc[key] = val\n",
    "        \n",
    "        intra, adj    = add_new_data(hlc)\n",
    "        resampled_adj = resample_intraday(adj)\n",
    "    else:\n",
    "        intra, adj    = add_new_data(new_hlc)\n",
    "        resampled_adj = resample_intraday(adj)\n",
    "    \n",
    "    return intra, resampled_adj\n",
    "\n",
    "def update_hlc(intra, resampled_adj):\n",
    "    \"\"\"\n",
    "    Calculate new indicator values since our last day calculated up to\n",
    "    present. Then return these indicators for use in updating our files.\n",
    "    Adx_d3 is a precalculated dictionary with dataframes that needed to be put together\n",
    "    due to several factors that may eventually be seperated like the others but currently\n",
    "    isn't.\n",
    "    \"\"\"\n",
    "    highlowclose  = {}\n",
    "    # Current day\n",
    "    end_date      = str(datetime.date.today())\n",
    "    # Date 2 years prior for enough data to calculate new indicator values since update\n",
    "    prev_date     = str(int(end_date[:4])-2)+end_date[4:]\n",
    "    start         = datetime.datetime.strptime(prev_date, '%Y-%m-%d').date()\n",
    "    end           = datetime.datetime.strptime(end_date, '%Y-%m-%d').date()\n",
    "    # Version1 of trading days function is used for period calculation, other used\n",
    "    # for getting the date 2 years ago to give us a shortened version of our \n",
    "    # highlowclose dictionary\n",
    "    rs            = NYSE_tradingdays()\n",
    "    rs2           = NYSE_tradingdays2(start, end)\n",
    "    short         = str(rs2[0])[:10]\n",
    "    hlc_cols      = ['Highs','Lows','Closes','Typical']\n",
    "\n",
    "    # First append our new highs/lows/closes/typicals for each stock to historical data\n",
    "    for key,value in intra.iteritems():\n",
    "        intra[key] = intra[key][hlc_cols].append(resampled_adj[key][hlc_cols])\n",
    "    # Then retrieve only the last 2 years worth of data for each since we don't need \n",
    "    # more than that for indicator calculations unless the last update has been more\n",
    "    # than roughly 5.5 months ago.\n",
    "    for key,value in intra.iteritems():\n",
    "        highlowclose[key] = value[short:].reset_index().drop_duplicates(subset='index', \n",
    "                                                            keep='last').set_index('index')\n",
    "\n",
    "    # prd_lst is in number of days, while the plnums are in minutes.\n",
    "    # You need many different period lengths for each indicator.\n",
    "    prd_lst  = [1,  2,  3,  5,  8,  10, 12, 14, 16, 20, 25,  30,  40,  50,  80,  125]\n",
    "    plnums   = [10, 14, 16, 18, 20, 25, 30, 40, 50, 75, 100, 125, 150, 200, 250, 300]\n",
    "    plnums2  = [8, 10, 14, 16, 18, 20, 25, 30, 40, 50, 75,  100, 125, 150, 200, 250, 300, 350]\n",
    "    plnums3  = [6, 8, 10, 14, 16, 18, 20, 25, 30, 40, 50,  75,  100, 125, 150, 200, 250, 300, 350]\n",
    "    prds_dates = {}\n",
    "    # Make sure we have that day in our dataframe since some days are missing from our data source\n",
    "    for key in highlowclose.keys():\n",
    "        tl = []\n",
    "        for x in xrange(257, 110, -1):\n",
    "            try:\n",
    "                dt   = str(rs[x])[:10]\n",
    "                test = highlowclose[key][dt]\n",
    "                tl.append(dt)\n",
    "            except:\n",
    "                pass\n",
    "        # Get the dates of that number of days in the past, for example tl[1] is one day ago..\n",
    "        prd_lst  = [tl[1], tl[2], tl[3], tl[5], tl[8], tl[10], tl[12], tl[14], tl[16], tl[20], \n",
    "                    tl[25], tl[30], tl[40], tl[50], tl[80], tl[125]]\n",
    "        prds_dates[key] = prd_lst\n",
    "    \n",
    "    # Call our function that creates our period dictionary that converts the days into number\n",
    "    # of minutes and adds that to each of the three plnums.\n",
    "    prd_dict = create_prd_lst2(highlowclose, prds_dates, plnums, plnums2, plnums3)\n",
    "    \n",
    "    comp_key = resampled_adj.keys()[0]\n",
    "    # Get the starting date of our new values\n",
    "    start2   = str(resampled_adj[comp_key].index[0])[:10]\n",
    "    \n",
    "    # Dump our new highlowclose dictionary into a pickle file\n",
    "    opp = open('Pickles/pickleadjustedintracomplete.pickle','wb')\n",
    "    pickle.dump(intra, opp)\n",
    "    opp.close()\n",
    "    \n",
    "    return intra, highlowclose, prd_dict, start2\n",
    "\n",
    "def update_indicators(highlowclose, prd_dict, start2):\n",
    "    \"\"\"\n",
    "    Update all of our indicator values, starting from our start2 value which is the last\n",
    "    date in our indicator dictionaries. We get the added values, put them all in a list,\n",
    "    where we'll send them to our update_newbase_files() function to append them to our\n",
    "    old dictionaries. These functions are only called if you missed the real-time function\n",
    "    for that day for any reason.\n",
    "    \"\"\"\n",
    "    # Calculate all of our indicators, using our shortened highlowclose dictionary, the \n",
    "    # periods dictionary, and the date of the start of our new values\n",
    "    ret_d                 = returns_create(highlowclose, prd_dict, start2)\n",
    "    per_d                 = per_create(highlowclose, prd_dict, start2)\n",
    "    cci_d                 = cci_create(highlowclose, prd_dict, start2)\n",
    "    vol_d                 = vol_create(highlowclose, prd_dict, start2)\n",
    "    bol_d                 = bol_create(highlowclose, prd_dict, start2)\n",
    "    mom_d                 = mom_create(highlowclose, prd_dict, start2)\n",
    "    sma_d                 = sma_create(highlowclose, prd_dict, start2)\n",
    "    d_d                   = kdo_create(highlowclose, prd_dict, start2)\n",
    "    mac_d, mac_d2         = mac_create(highlowclose, prd_dict, start2)\n",
    "    rsi_d                 = rsi_create(highlowclose, prd_dict, start2)\n",
    "    adx_d, adx_d2, adx_d3 = adx_create(highlowclose, prd_dict, start2)\n",
    "    aro_d                 = aro_create(highlowclose, prd_dict, start2)\n",
    "    \n",
    "    # Combine them into list, minus adx_d2 and d3, since they aren't\n",
    "    # put into the same directory as the other indicators\n",
    "    short_lst = [adx_d, aro_d, cci_d, bol_d, d_d, mac_d, mac_d2,\n",
    "                 mom_d, per_d, ret_d, rsi_d, sma_d, vol_d]\n",
    "    \n",
    "    return adx_d2, adx_d3, short_lst\n",
    "\n",
    "print \"LOADED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED\n"
     ]
    }
   ],
   "source": [
    "def update_newbase_files(ind_vals, intra):\n",
    "    \"\"\"\n",
    "    Base files are where our combined data for each company is so we combine our\n",
    "    new data and then append these to our last dataframe. Currently theres 15 \n",
    "    dataframes each for each company. This is so that we only need to process about\n",
    "    4 months of data at a time, so we don't have to have so much data in memory at\n",
    "    once. We only process a max of 25000 rows at a time so it works out to roughly\n",
    "    4 months at a time processed.\n",
    "    \"\"\"\n",
    "    nms = ['adx', 'aro', 'cci', 'bol', 'kdo', 'mac', 'mactwo',\n",
    "           'mom', 'per', 'rets', 'rsi', 'sma', 'vol']\n",
    "    for name in intra.keys():\n",
    "        new_df = pd.DataFrame()\n",
    "        \n",
    "        for dic, nm in zip(ind_vals, nms):\n",
    "            nm_lst = []\n",
    "            \n",
    "            # Rename each column as the a combination of the stock symbol, the \n",
    "            # indicator abreviation, and the period number\n",
    "            for x in range(32):\n",
    "                nm_lst.append(name+'_'+nm+str(x))\n",
    "            # Set the indicators column names\n",
    "            dic[name].columns = nm_lst\n",
    "            \n",
    "            # Combine the indicators together\n",
    "            new_df = pd.concat([new_df, dic[name]], \n",
    "                               axis=1).fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "        # Open the last piece of the indicator dataframe, to have the new values \n",
    "        # added to it.\n",
    "        # NOTE: NEED TO CHANGE THIS AND THE DUMPING NAME WHEN THE LAST INDICATOR \n",
    "        #       BECOMES TOO LARGE AND YOU NEED TO ADD AN EXTRA PIECE\n",
    "        opp = open('NewBase/'+name+'/'+name+'_df14.pickle','rb')\n",
    "        old = pickle.load(opp)\n",
    "        opp.close()\n",
    "\n",
    "        new_comb = old.append(new_df)\n",
    "        # Drop any duplicate rows that mysteriously showed up several times during testing\n",
    "        new_comb = new_comb.reset_index().drop_duplicates(subset='index',\n",
    "                                                    keep='last').set_index('index')\n",
    "        # Dump the new indicator dataframe in place of the old one\n",
    "        opp = open('NewBase/'+name+'/'+name+'_df14.pickle','wb')\n",
    "        pickle.dump(new_comb, opp)\n",
    "        opp.close()\n",
    "    return\n",
    "\n",
    "def update_adx23short(new_intra, adx_d2, adx_d3):\n",
    "    \"\"\"\n",
    "    Update the adx2 and adx3 dictionaries that are precalculated for use in the the real-time \n",
    "    calculations to speed up calculation during real-time. These are updated during the real-time\n",
    "    calculations but if you miss a day for some reason these functions update your dictionaries\n",
    "    for you. Also update our short highlowclose dictionary that is a shortened version of our\n",
    "    normal highlowclose dictionary for speed purposes since we don't need the full dictionary\n",
    "    during real-time calcs.\n",
    "    \"\"\"\n",
    "    # Google server uses different names for these below symbols compared to yahoo symbols\n",
    "    ticks  = {'LMT':'NYSE:LMT', 'USO':'NYSEARCA:USO', 'GLD':'NYSEARCA:GLD',\n",
    "              'SPY':'NYSEARCA:SPY', '^DJI':'INDEXDJX:.DJI', '^GSPC':'INDEXSP:.INX',\n",
    "              '^IXIC':'INDEXNASDAQ:.IXIC'}\n",
    "    \n",
    "    # Open our old adx_d2 and shortened highlowclose dictionary, for updating\n",
    "    opp   = open('NewBase/ADXD/adx_d2.pickle','rb')\n",
    "    opp2  = open('Pickles/shortpickleintra.pickle','rb')\n",
    "    d2    = pickle.load(opp)\n",
    "    short = pickle.load(opp2)\n",
    "    opp.close()\n",
    "    opp2.close()\n",
    "\n",
    "    new_short, new_d2, new_d3 = {}, {}, {}\n",
    "    for name in new_intra.keys():\n",
    "        # Shortened hlc dictionary uses Google symbols rather than Yahoo symbols\n",
    "        # since it is used for our realtime data retrieval\n",
    "        if name not in ticks.keys():\n",
    "            name2 = name\n",
    "        else:\n",
    "            name2 = ticks[name]\n",
    "            \n",
    "        # Append new data to our old data\n",
    "        new_short[name2] = short[name2].append(new_intra[name])\n",
    "        new_d2[name2]    = d2[name2].append(adx_d2[name])\n",
    "        \n",
    "        # adx_d3 doesn't need to be added to old adx_d3 since it's completely\n",
    "        # updated, meaning we replace the old one with this\n",
    "        for w in range(32):\n",
    "            new_d3[name2+str(w)] = adx_d3[name+str(w)]\n",
    "\n",
    "    # Dump all our new dictionaries\n",
    "    opp  = open('Pickles/shortpickleintra2.pickle','wb')\n",
    "    opp2 = open('NewBase/ADXD/adx_d22.pickle','wb')\n",
    "    opp3 = open('NewBase/ADXD/adx_d32.pickle','wb')\n",
    "    pickle.dump(new_short, opp)\n",
    "    pickle.dump(new_d2, opp2)\n",
    "    pickle.dump(new_d3, opp3)\n",
    "    opp.close()\n",
    "    opp2.close()\n",
    "    opp3.close()\n",
    "    return\n",
    "\n",
    "print \"LOADED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you've already updated for dividends/splits after missing data, and needing\n",
    "# to update one or more stocks for this, then uncomment the first get_new_data call\n",
    "# and comment the second call.\n",
    "#old_intra, resampled_adj = get_new_data(update=True)\n",
    "old_intra, resampled_adj = get_new_data()\n",
    "# Then you call this function to using the two dictionaries returned from get_new_data()\n",
    "intra, highlowclose, prd_dict, start2 = update_hlc(old_intra, resampled_adj)\n",
    "# After that, you're returned the new combined dictionary, a shortened dictionary,\n",
    "# the period dictionary, and the date from which you'll be updating from.\n",
    "adx_d2, adx_d3, ind_vals = update_indicators(highlowclose, prd_dict, start2)\n",
    "# Then you finally update your indicators with the two functions below\n",
    "update_newbase_files(ind_vals, intra)\n",
    "update_adx23short(resampled_adj, adx_d2, adx_d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
