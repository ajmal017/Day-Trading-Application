{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Johnson & Johnson', 'IBM', 'United Technologies', 'Nike', 'General Electric', 'The Home Depot', 'Verizon', \"McDonald's\", 'American Express', 'Coca-Cola', 'Caterpillar', 'Visa', 'Walt Disney', 'Boeing', 'Intel', 'Pfizer', 'Procter & Gamble', 'Wal-Mart', 'Merck', 'UnitedHealth Group', 'Cisco Systems', '3M', 'Microsoft', 'JPMorgan Chase', 'Apple', 'Travelers', 'DuPont', 'Goldman Sachs', 'Chevron', 'ExxonMobil']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import Quandl\n",
    "import math\n",
    "import scipy.optimize as spo\n",
    "\n",
    "def retrieveStockCodes():\n",
    "    dow_jones_codes = pd.read_csv(\"C:/Users/JohnSmith2/Downloads/dowjonesA.csv\")\n",
    "    dj_df = pd.DataFrame(dow_jones_codes)\n",
    "    dj_df = dj_df.ix[:,['name','free_code']]\n",
    "    return dj_df\n",
    "    \n",
    "def retrieveDowJonesData(dj_df):\n",
    "    dowJonesDict = {}\n",
    "    for name, value in zip(dj_df['name'], dj_df['free_code']):\n",
    "        each = Quandl.get(value, trim_start=\"2010-04-15\", trim_end=\"2016-04-15\", authtoken=\"gEC9xAKi4avigPpoQPX1\",\n",
    "                         returns='numpy')\n",
    "        df = pd.DataFrame(each)\n",
    "        \n",
    "        #fill forward and backword missing data\n",
    "        df = df.fillna(method='ffill', inplace=True)\n",
    "        df = df.fillna(method='bfill', inplace=True)\n",
    "        \n",
    "        dowJonesDict[name] = pd.DataFrame(df)\n",
    "    return dowJonesDict\n",
    "\n",
    "dj_df = retrieveStockCodes()\n",
    "dowJonesDict = retrieveDowJonesData(dj_df)\n",
    "print dowJonesDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_rolling_mean(values, window):\n",
    "    \"\"\"Return rolling mean of given values, using specified window size.\"\"\"\n",
    "    return pd.rolling_mean(values, window=window)\n",
    "    \n",
    "def get_rolling_std(values, window):\n",
    "    \"\"\"Return rolling standard deviation of given values, using specified window size\"\"\"\n",
    "    return pd.rolling_std(values, window=window)\n",
    "    \n",
    "def get_bollinger_bands(rm, rstd):\n",
    "    \"\"\"Return upper and lower Bollinger Bands.\"\"\"\n",
    "    upper_band = rm + rstd * 2\n",
    "    lower_band = rm - rstd * 2\n",
    "    return upper_band, lower_band\n",
    "    \n",
    "def compute_daily_returns(df):\n",
    "    \"\"\"Compute and return the daily return values.\"\"\"\n",
    "    daily_returns = (df / df.shift(1)) - 1\n",
    "    daily_returns.ix[0,:] = 0 #Pandas leaves the 0th row full of NaNs\n",
    "    return daily_returns\n",
    "    \n",
    "def plot_data(df, title=\"Stock prices\", xlabel=\"Date\", ylabel=\"Price\"):\n",
    "    \"\"\"Plot stock prices with a custom title and meaningful axis labels.\"\"\"\n",
    "    ax = df.plot(title=title, fontsize=12)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    plt.show()\n",
    "    \n",
    "def createAdjVolAndCloseDfs(dowJonesDict):\n",
    "    i = 0\n",
    "    for each in dowJonesDict.keys():\n",
    "        if i == 0:\n",
    "            df = dowJonesDict[each]\n",
    "            adj_close_df = df[['Date','Adj. Close']].rename(columns={'Adj. Close': each})\n",
    "            adj_vol_df = df[['Date','Adj. Volume']].rename(columns={'Adj. Volume': each})\n",
    "            i = 1\n",
    "        else:\n",
    "            df = dowJonesDict[each]\n",
    "            next_adj_close_df = df[['Date','Adj. Close']].rename(columns={'Adj. Close': each})\n",
    "            next_adj_vol_df = df[['Date','Adj. Volume']].rename(columns={'Adj. Volume': each})\n",
    "            adj_close_df = pd.merge(adj_close_df, next_adj_close_df, on='Date')\n",
    "            adj_vol_df = pd.merge(adj_vol_df, next_adj_vol_df, on='Date')\n",
    "            \n",
    "    return adj_close_df, adj_vol_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def daily_return_stats(daily_returns):\n",
    "    #get mean and std deviation of daily returns\n",
    "    daily_returns.hist()\n",
    "    beta_XOM,alpha_XOM = np.polyfit(daily_returns['SPY'],daily_returns['XOM'],1)\n",
    "    # Calculate correlation coefficient\n",
    "    print daily_returns.corr(method='pearson')\n",
    "\n",
    "def daily_portfolio_values(adj_close_df, adj_vol_df, daily_returns):\n",
    "    # Daily portfolio value\n",
    "    \n",
    "    # TODO: \n",
    "    normalize_prices = prices/prices[0]\n",
    "    allocations = normalized_prices * adj_vol_df #allocs\n",
    "    position_vals = allocations * start_val\n",
    "    portfolio_val = position_vals.sum(axis=1)\n",
    "    \n",
    "    # Portfolio stats\n",
    "    daily_rets = daily_returns[1:]\n",
    "    cum_ret = (portfolio_val[-1]/portfolio_val[0]) - 1\n",
    "    avg_daily_ret = daily_rets.mean()\n",
    "    std_daily_ret = daily_rets.std()\n",
    "    \n",
    "    #Definition of portfolio:\n",
    "    #  Wi: portion of funds in asset i\n",
    "    #Cap weighted:\n",
    "    #  Wi = mktcap i / sum(mktcap all)\n",
    "    Rp(t) = sum(Wi*Ri(t))\n",
    "\n",
    "def sharpe_ratio(daily_returns):\n",
    "    # Sharpe ratio == risk adjusted return\n",
    "    # lower risk, higher return is better\n",
    "    # considers risk free rate of return too\n",
    "    # SR is an annual measure\n",
    "    var = 1.0 + var\n",
    "    s = newton_root(252, var)\n",
    "    daily_rf = s - 1\n",
    "    sharpe_ratio = mean(daily_returns - daily_rf)/std(daily_returns)\n",
    "    K = sqrt(252)    #weekly K = sqrt(52), etc.\n",
    "    SRannualized = K * sharpe_ratio\n",
    "    \n",
    "def newton_root(k, n):\n",
    "    k = 252\n",
    "    n = 1 + var\n",
    "    u, s = n, n+1\n",
    "    while u < s:\n",
    "        s = u\n",
    "        t = (k-1) * s + n // pow(s, k-1)\n",
    "        u = t // k\n",
    "    return s\n",
    "\n",
    "def forcasting_algorithm():\n",
    "    # Forcasting algorithm inputs:\n",
    "    # -Information feed\n",
    "    # -Historical price data\n",
    "    intrinsic_value = future_value / discount_rate #(ie. if dr=5%,fv=1, 1/.05 = 20$)\n",
    "    book_value = total_assets - (intangibal_assets + liabalities)\n",
    "    market_capitalization = num_shares * price\n",
    "\n",
    "def capm_equation():\n",
    "    #****CAPM EQUATION****\n",
    "    # Ri(t) == return for particular stock on a given day t\n",
    "    # Bi == beta\n",
    "    # Rm(t) == return on market (usually refers to S&P)\n",
    "    # Alphai(t) == alpha of particular stock on that day\n",
    "    \n",
    "    #For individual stocks\t\n",
    "    Ri(t) = Bi*Rm(t) + Alphai(t)\n",
    "    \n",
    "    #CAPM for Portfolios:\n",
    "    Bp = Sum(Wi * Bi)\n",
    "    Alphap(t) = Sum(Wi * alphai(t))\n",
    "    Rp(t) = Bp* Rm(t) + Alphap(t)\n",
    "\n",
    "def technical_analysis():\n",
    "    #Technical indicators:\n",
    "    momentum[t] = price[t]/price[t-n] - 1\n",
    "    SMA[t] = price[t]/price[t-n:t].mean() - 1\n",
    "    BB[t] = price[t]-SMA[t]/2*std[t]\n",
    "    normed = values - mean / values.std()\n",
    "    \n",
    "    #Grinolds fundamental law:\n",
    "    performance = skill * sqrt(breadth)\n",
    "    SRmulti = SRsingle * sqrt(bets)\n",
    "    \n",
    "    #IR is like Sharpe of excess return\n",
    "    information_ratio = mean(Alphap(t))/std(Alphap(t))\n",
    "    #IC(info coefficient) is correlation of forecasts to returns\n",
    "    #BR(Breadth) is number of trading opportunities per year\n",
    "    IR = IC * sqrt(BR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "# -Find minimum values of functions\n",
    "# -Build parametized models based on data\n",
    "# -Refine allocations to stocks in portfolios\n",
    "#   Use:\n",
    "#   -Provide function to minimize\n",
    "#   -Provide initial guess\n",
    "#   -Call optimizer\n",
    "\n",
    "def fit_line(data, error_func):\n",
    "    \"\"\"Fit a line to given data, using a supplied error function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: 2D array where each row is a point (X0, Y)\n",
    "    error_func: function that computes the error between a line and observed data\n",
    "    \n",
    "    Returns line that minimizes the error function.\n",
    "    \"\"\"\n",
    "    # Generate initial guess for line model \n",
    "    l = np.flot32([0, np.mean(data[:,1])]) # slope = 0, intercept = mean(y values)\n",
    "    \n",
    "    # Plot initial guess (optional)\n",
    "    x_ends = np.float32([-5, 5])\n",
    "    plt.plot(x_ends, l[0] * x_ends + l[1], 'm--', linewidth=2.0, label=\"Initial guess\")\n",
    "    \n",
    "    #Call optimizer to minimize error function\n",
    "    result = spo.minimize(error_func, l, args=(data,), method='SLSQP', options={'display': True})\n",
    "    return result.x\n",
    "\n",
    "def error(line, data) # error function\n",
    "    \"\"\"Compute error between given line model and observed data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    line: tuple/list/array (C0, C1) where C0 is slope and C1 is Y-intercept\n",
    "    data: 2D array where each row is a point (x,y)\n",
    "\n",
    "    Returns error as a single real value.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Metric: Sum of squared Y-axis differences\n",
    "    err = np.sum((data[:,1] - (line[0] * data[:,0] + line[1])) ** 2)\n",
    "    return err\n",
    "\n",
    "def test_run():\n",
    "    # Define original line \n",
    "    l_orig = np.float32([4,2])\n",
    "    print \"Original line: C0 = {}, C1 = {}\".format(l_orig[0],l_orig[1])\n",
    "    Xorig = np.linspace(0,10,21)\n",
    "    Yorig = l_orig[0] * Xorig + l_orig[1]\n",
    "    plt.plot(Xorig, Yorig, 'b--', linewidth=2.0, label=\"Original line\")\n",
    "\n",
    "    # Generate noisy data points\n",
    "    noise_sigma = 3.0\n",
    "    noise = np.random.normal(0, noise_sigma, Yorig.shape)\n",
    "    data = np.asarray([Xorig, Yorig + noise]).T\n",
    "    plt.plot(data[:,0], data[:,1], 'go', label=\"Data points\")\n",
    "    \n",
    "    # Try to fit a line to this data\n",
    "    l_fit = fit_line(data, error)\n",
    "    print \"Fitted line: C0 = {}, C1 = {}\".format(l_fit[0], l_fit[1])\n",
    "    plt.plot(data[:,0], l_fit[0] * data[:,0] + l_fit[1], 'r--', linewidth=2.0, label=\" \")\n",
    "\n",
    "\n",
    "#############################################\n",
    "# For Polynomials ##\n",
    "####################\n",
    "def error_poly(C, data):\n",
    "    \"\"\"Compute error between given polynomial observed data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    C: numpy.poly1d object or equivalent array representing polynomial coefficients\n",
    "    data: 2D array where each row is a point (x,y)\n",
    "    \n",
    "    Returns error as a single real value.\n",
    "    \"\"\"\n",
    "    # Metric: Sum of squared Y-axis differences\n",
    "    err = np.sum((data[:,1] - np.polyval(C, data[:,0]))**2)\n",
    "    return err\n",
    "    \n",
    "def fit_poly(data, error_func, degree=3):\n",
    "    \"\"\"Fit a polynomial to given data, using supplied error function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: 2D array where each row is a point (x,y)\n",
    "    error_func: function that computes the error between a polynomial and observed data\n",
    "    \n",
    "    Returns polynomial that minimizes the error function.\n",
    "    \"\"\"\n",
    "    # Generate initial guess for polynomial model (all coeffs = 1)\n",
    "    Cguess = np.poly1d(np.ones(degree + 1, dtype=np.float332))\n",
    "    \n",
    "    #Plot initial guess (optional)\n",
    "    x = np.linspace(-5, 5, 21)\n",
    "    plt.plot(x, np.polyval(Cguess, x), 'm--', linewidth=2.0, label=\"Initial guess\")\n",
    "    \n",
    "    #Call optimizer to minimize error function\n",
    "    resul = spo.minimize(error_func, Cguess, args=(data,), method='SLSQP', options={'display':True}\n",
    "    returns np.poly1d(result.x) #Convert optimal result into a poly1d object and return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeBollingerBands(adj_close_df):\n",
    "    \n",
    "    #Compute Bollinger Bands\n",
    "    # 1. Compute rolling mean\n",
    "    adj_close_df = adj_close_df.set_index(['Date'])\n",
    "    i = 0\n",
    "    for each in adj_close_df:\n",
    "        rm_SPY = get_rolling_mean(adj_close_df[each], window=20)\n",
    "        # 2. Compute rolling standard deviation\n",
    "        rstd_SPY = get_rolling_std(adj_close_df[each], window=20)\n",
    "        # 3. Compute upper and lower bands\n",
    "        upper_band, lower_band = get_bollinger_bands(rm_SPY, rstd_SPY)\n",
    "\n",
    "        if i == 0:\n",
    "            upper_band_df = pd.DataFrame(upper_band)\n",
    "            lower_band_df = pd.DataFrame(lower_band)\n",
    "            i = 1\n",
    "        else:\n",
    "            next_upper_df = pd.DataFrame(upper_band)\n",
    "            next_lower_df = pd.DataFrame(lower_band)\n",
    "            upper_band_df = pd.merge(upper_band_df, next_upper_df, left_index=True, right_index=True)\n",
    "            lower_band_df = pd.merge(lower_band_df, next_lower_df, left_index=True, right_index=True)\n",
    "    \n",
    "    upper_band_df = upper_band_df[20:]\n",
    "    lower_band_df = lower_band_df[20:]\n",
    "\n",
    "    return upper_band_df, lower_band_df\n",
    "\n",
    "def plotBollinger(adj_close_df):\n",
    "    \n",
    "    rm_SPY = get_rolling_mean(adj_close_df, window=20)\n",
    "    rstd_SPY = get_rolling_std(adj_close_df, window=20)\n",
    "    upper_band, lower_band = get_bollinger_bands(rm_SPY, rstd_SPY)\n",
    "    \n",
    "    # Plot raw SPY values, rolling mean and Bollinger Bands\n",
    "    ax = adj_close_df[20:160].plot(title=\"Bollinger Bands\", label='IBM')\n",
    "    rm_SPY[20:].plot(label='Rolling mean', ax=ax)\n",
    "    upper_band[20:].plot(label='upper band', ax=ax)\n",
    "    lower_band[20:].plot(label='lower band', ax=ax)\n",
    "    \n",
    "    # Add axis labels and legend\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()    \n",
    "    \n",
    "def computeAndPlotDailyReturns(adj_close_df):\n",
    "    #Compute daily returns\n",
    "    adj_close_df = adj_close_df.set_index(['Date'])\n",
    "    adj_close_df = adj_close_df\n",
    "    daily_returns = compute_daily_returns(adj_close_df)\n",
    "    plot_data(daily_returns, title=\"Daily returns\", ylabel=\"Daily returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adj_close_df, adj_vol_df = createAdjVolAndCloseDfs(dowJonesDict)\n",
    "upper_band_df, lower_band_df = computeBollingerBands(adj_close_df)\n",
    "\n",
    "plotBollinger(adj_close_df['Nike'][:160])\n",
    "computeAndPlotDailyReturns(adj_close_df[['Date','IBM','Nike','Visa']][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
