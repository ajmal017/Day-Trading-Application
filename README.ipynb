{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RealTimeNeuralNetworkTrading\n",
    "\n",
    "   ### Why this project was created:\n",
    "\n",
    "         This project was made as a final project for Udacity.com for there Machine Learning Engineer \n",
    "         program. This project uses a variety of techniques to create many well known indicators for \n",
    "         trading on the stock market, and utilize these within a deep learning setup that uses real time\n",
    "         recurrent learning. We use this neural network to predict stock returns for a companies of our\n",
    "         choice. \n",
    "         \n",
    "         Due to limitations on acquiring free intraday data, we're currently only able to predict\n",
    "         on roughly 50 stocks but if you chose to acquire paid data elsewhere, you could theoretically \n",
    "         predict for any amount of companies you wanted. This setup is more based for those who don't have\n",
    "         the money to buy lots of data though. \n",
    "         \n",
    "   ### How this package operates:\n",
    "         \n",
    "         The way this package works is first, you create your indicator data using some precalculated \n",
    "         dataframes containing high/low/close/typical values for the past several years that were adjusted\n",
    "         for dividends and splits and such. Once this is done, you can start training your neural network\n",
    "         using this indicator data. This project allows you to choose the indicator attributes of your \n",
    "         choice. For each indicator, which there are 12, you also have the ability to use 32 different \n",
    "         period lengths. The period length is how much data each indicator uses to calculate itself. So for\n",
    "         example, you might only choose to use the smallest period length of 6 minutes, or choose the longest\n",
    "         period length of 125 trading days. And you can choose many different options together to get both\n",
    "         short term and long term data combined. Each indicator has preferred period lengths that work best\n",
    "         generally but I encourage you to try to test as much as you can out yourself. \n",
    "         \n",
    "         You probably want to keep the amount of indicators you're using total less than about 250, as more\n",
    "         than that amount of attributes can quickly run up memory and cpu usage. For my machine, I ran on a\n",
    "         generally small amount of resources using 12GB of ram, with an Intel i7-4510U cpu. Much more than\n",
    "         than amount of attributes tended to kill my memory, and in the process, kill my cpu time. I tended\n",
    "         to train on 230 attributes, using roughly 25000 records at a time. I found this to be useful and\n",
    "         provided a good accuracy/limitation ratio. \n",
    "         \n",
    "         Once you've set up all of your indicator and neural network data and everything is\n",
    "         up to date, you can start using the real-time portion of the project. In particular, the \n",
    "         RealTimeCalculator notebook allows for calculating indicators in real-time using data from a \n",
    "         Google Finance server that provides us real-time stock data for the stocks of our choice. This \n",
    "         allowed us to then calculate highs/lows/closes/typical values which then allowed us to calculate\n",
    "         our indicators. Once the indicators had been calculated, our neural network function would be \n",
    "         called to make its prediction for us based on our indicators.\n",
    "         \n",
    "         This package is set up to train the neural network on the trading off-hours so that during the day\n",
    "         we could test only, rather than train and test which would use up a lot more resources. However, \n",
    "         eventually, an update will be provided that will give you the option to train on the data in \n",
    "         real-time so you could get more accurate predictions. \n",
    "         \n",
    "   ### For more information or questions/concerns:\n",
    "         Contact me at jbboltz123@gmail.com\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Installation\n",
    "      1. Ensure you have an IPython Notebook solution such as with \n",
    "         Anaconda which installs a variety of applications including\n",
    "         python, and Ipython solution, and several other helpful\n",
    "         modules such as Numpy, Pandas, and Pip.\n",
    "      \n",
    "      2. Retrieve the 4 python files in this repository and store them\n",
    "         in the same directory with all of your other repositories. \n",
    "        \n",
    "         For example, with Anaconda, the directory is stored in:\n",
    "            C:/path/to/user/Anaconda/Lib/site_packages/\n",
    "        \n",
    "         RealTimeNN.py, CalcInd.py, and NyseDatesPrds.py are stored as \n",
    "         standalone files, while the googlefinance init.py is stored in \n",
    "         a folder called googlefinance. The googlefinance is a slightly\n",
    "         altered version of the googlefinance package written by hongtaocai\n",
    "            \n",
    "      3. Install the other modules using pip. For example, cd to the \n",
    "         scripts directory at C:/path/to/user/Anaconda/scripts/ , then\n",
    "         type:\n",
    "            pip install yahoo_finance\n",
    "            pip install quandl\n",
    "            pip install matplotlib\n",
    "            pip install scipy\n",
    "            pip install pickle\n",
    "            pip install pandas\n",
    "            pip install numpy\n",
    "            \n",
    "      4. Once all of your modules have been set up, place the other ipynb\n",
    "         files from this repository into a directory called Trading/ and \n",
    "         place these 6 ipython files into this directory.\n",
    "            \n",
    "      5. Retrieve the HLC directory from the repository, within this is\n",
    "         20 pickled files containing premade dataframes with intraday\n",
    "         highs, lows, closes, and typical values at a minute by minute\n",
    "         level. These are provided so you don't have to create them yourself\n",
    "         using the online repository that was used to create them as it made\n",
    "         it so you would have to download individually one at a time and adjust\n",
    "         them yourself. \n",
    "            \n",
    "         This repository contains 14 stocks as well as 6 Exchange Traded Funds, \n",
    "         as well as Indexes that are used to help in the prediction process. \n",
    "         \n",
    "         If you choose, you can retrieve more stocks/funds/indexes directly from\n",
    "         the online server that was used to create these data sources. The site\n",
    "         is called http://thebonnotgang.com/tbg/historical-data/\n",
    "         \n",
    "         Store this repository within your Trading/ directory.\n",
    "                \n",
    "#### Given files, packages, and directory:\n",
    "        ProgramInfoAndCreation.ipynb\n",
    "        IndicatorCreation.ipynb\n",
    "        CalculateAndAddMissingData.ipynb\n",
    "        DividendAndSplitUpdate.ipynb\n",
    "        RealTimeCalculator.ipynb\n",
    "        RealTimeNeuralNetwork.ipynb\n",
    "        RealTimeNN.py\n",
    "        CalcInd.py\n",
    "        NyseDatesPrds.py\n",
    "        googlefinance package\n",
    "        HLC directory\n",
    "\n",
    "#### Imported packages:\n",
    "        yahoo_finance package\n",
    "        quandl package\n",
    "        matplotlib package\n",
    "        scipy package\n",
    "        pickle package\n",
    "        pandas package\n",
    "        numpy package\n",
    "        \n",
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Usage\n",
    "\n",
    "      1. First cd to your Trading/ directory, then first call:\n",
    "            ipython notebook ProgramInfoAndCreation.ipynb\n",
    "         \n",
    "         Further instructions on how to view information and create\n",
    "         your initial files are within this file.\n",
    "        \n",
    "      2. After everything is setup using that file, open:\n",
    "            DividendAndSplitUpdate.ipynb\n",
    "            \n",
    "         This file will allow you to add the data since the intraday data\n",
    "         was put up, and then adjust for any splits and/or dividends that \n",
    "         have happened since the hlc dictionary was put online. Follow the \n",
    "         instructions within this file for more information.\n",
    "        \n",
    "      3. After your hlc dictionary is updated for added data and dividend/\n",
    "         stock adjustments, you'll now create the indicators for each \n",
    "         company. To do this, open:\n",
    "            IndicatorCreation.ipynb\n",
    "            \n",
    "         For more information, look within the file.\n",
    "        \n",
    "      4. Now that your indicators and intraday data are up to date, you \n",
    "         can open:\n",
    "            RealTimeCalculor.ipynb\n",
    "            \n",
    "         This file has everything you need to acquire real-time stock data\n",
    "         so as to calculate real-time indicator values as well as use these\n",
    "         values to create you're predictions. For more information, look \n",
    "         within the file.\n",
    "            \n",
    "      5. Finally, you'll open:\n",
    "            RealTimeNeuralNetwork.ipynb\n",
    "        \n",
    "         This file is used to calculate the neural networks for any companies\n",
    "         that you choose. This file is typically run on trading off-hours because\n",
    "         it is processor and memory intensive, and it allows you to create/update\n",
    "         a neural network that once created/updated can be saved and then will be\n",
    "         used throughout the next trading day to make our predictions. Eventually \n",
    "         this will be set up to continuously update throughout the training day for\n",
    "         more accurate results, but for now, it's set up to give you a neural netwrk\n",
    "         that you will just use to predict and only update after the trading day is\n",
    "         done.\n",
    "            \n",
    "### Note:\n",
    "   #### If no dividends/splits since last update:\n",
    "         If for any reason, you miss some trading day's data by not using the \n",
    "         RealTimeCalculator.ipynb file, you can update everything back to normal by\n",
    "         opening:\n",
    "            CalculateAndAddMissingData.ipynb\n",
    "            \n",
    "         This file allows you to retrieve missed intraday data from our intraday \n",
    "         data source and update up to present. \n",
    "         \n",
    "   #### If dividends/splits since last update:   \n",
    "         Make sure there have been no dividends or stock splits on any of your stocks \n",
    "         since you last updated everything as if this did happen, rather than call the \n",
    "         above file, you'll instead open:\n",
    "            DividendAndSplitUpdate.ipynb\n",
    "         \n",
    "         where you'll update your intraday data dataframes for the div/splits. This will\n",
    "         leave you with a new pickle file called onlyupdatedintra.pickle, that contains \n",
    "         only the company highs/lows/closes/typicals that have been adjusted. Following\n",
    "         this adjustment, all of the indicators for these companies need to be reupdated, \n",
    "         rather than soley adding the indicator values since you last updated(which you'll\n",
    "         do for the other companies that don't need to be fully updated). Now open:\n",
    "            IndicatorCreation.ipynb\n",
    "            \n",
    "         And update the companies that recieved the dividend/split to reupdate all of the \n",
    "         indicators for those stocks. Then open:\n",
    "            CalculateAndAddMissingData.ipynb\n",
    "            \n",
    "         Where you'll add the missing indicator data for the companies that don't need to\n",
    "         be fully updated. This will just append the new data to your already created \n",
    "         indicator dataframes.\n",
    "         \n",
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Credits\n",
    "\n",
    "    1. The following functions are thanks to https://gist.github.com/jckantor/d100a028027c5a6b8340:\n",
    "          - NYSE_tradingdays()\n",
    "          - NYSE_holidays()\n",
    "          - NYSE_tradingdays2()\n",
    "          - NYSE_holidays2()\n",
    "       \n",
    "       This set of functions is used to calculate past and future trading days, making sure to adjust\n",
    "       for trading holidays and such. The first set of functions, NYSE_tradingdays() and NYSE_holidays()\n",
    "       is the original functions as was created entirely by jckantor, while the second set was altered by\n",
    "       me to adjust for a specific requirement I needed, but was based entirely off the original so thanks\n",
    "       to jckantor for providing this set of extremley helpful trading functions!!\n",
    "       \n",
    "    2. The following package was thanks to https://github.com/hongtaocai/googlefinance:\n",
    "          - googlefinance\n",
    "          \n",
    "       This package allowed for retrieving real-time stock data from Google's finance servers that allowed\n",
    "       this project to calculate real-time indicators. It also allowed for getting year's worth of news data\n",
    "       for those companies up to present. Thanks again, this project wouldn't exist if it weren't for them!\n",
    "       \n",
    "    3. The following package was thanks to https://github.com/lukaszbanasiak/yahoo-finance:\n",
    "          - yahoofinance\n",
    "          \n",
    "       This package allowed for providing information for each company when deciding which companies to \n",
    "       track. Thanks to lukaszbanasiak for making this package public!\n",
    "       \n",
    "    4. The following package was thanks to https://github.com/quandl/quandl-python:\n",
    "          - quandl\n",
    "          \n",
    "       Quandl provides all kinds of data that is both free and pay. They are one of the leading trading\n",
    "       data providers out there, so check them out if interested. For my portion of the project, I \n",
    "       utilize there adjusted closing prices for use if a company has a dividend or stock split you\n",
    "       need to adjust for. Thanks to them for providing that useful free data!\n",
    "       \n",
    "    5. The following functions are thanks to Dennis Atabay at https://pyrenn.readthedocs.io/en/latest/:\n",
    "          - create_neural_network()\n",
    "          - create_weight_vector()\n",
    "          - convert_matrices_to_vector()\n",
    "          - convert_vector_to_matrices()\n",
    "          - get_network_output()\n",
    "          - RTRL()\n",
    "          - prepare_data()\n",
    "          - train_LM()\n",
    "          - calc_error()\n",
    "          - NNOut()\n",
    "          \n",
    "       These functions allowed for utilizing real-time recurrent learning of neural nets. These were out of\n",
    "       a package called Pyrenn. There is a lot more functionality from that package so check it out. These \n",
    "       functions have been altered to use more descriptive naming of variables and functions, for both learning\n",
    "       purposes and for anyone checking out this package who wanted a little easier to follow group of functions.\n",
    "       \n",
    "       One major change was in RTRL(), the dictionaries deriv_layer_outputs_respect_weight_vect, and \n",
    "       sensitivity_matrix. These dictionaries started to cause issues when training on more than 10,000 data \n",
    "       records at a time. Due to the way they were set up, these functions would continuously add key/values to\n",
    "       there dictionaries after calculating those particular values. The issue arose because the function only\n",
    "       needed to keep enough to calculate up to the largest delay. What this meant was that rather than keeping\n",
    "       tens of thousands of data keys/values in a dictionary these dictionaries, we could just keep, for example,\n",
    "       the previous 5 key/value pairs that were needed for calculating with delays but no more. What resulted was\n",
    "       massive performance rewards in terms of memory consumption, and as a result of significantly less memory\n",
    "       consumption, computing time as well. That being said, this project wouldn't have been possible if not for\n",
    "       them, so thanks again!!\n",
    "       \n",
    "    6. Finally, thanks to everyone at http://thebonnotgang.com/tbg/ for providing FREE INTRADAY DATA!!!! This was\n",
    "       probably the most amazing find of this project. Prior to this, I was working on daily stock values, rather\n",
    "       than intraday, so when I found these guys, I couldn't have been happier. Please Please Please check out\n",
    "       there site, they provide apps, and all sorts of help. These guys were a lifesaver so show them some love!\n",
    "       They are the only guys I was able to find on here who provided free intraday data, so if you're poor like\n",
    "       me and ever need intraday data, check them out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
