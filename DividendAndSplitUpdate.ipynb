{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nyse_dates_prds import *\n",
    "from sys import stdout \n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import quandl\n",
    "import urllib\n",
    "\n",
    "print \"LOADED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_quandl_adjcloses(ticker_lst, intra):\n",
    "    \"\"\"\n",
    "    Pass in a list of tickers that we need updated, example: ['AAPL','BPOP'] or just ['AAPL'] etc.\n",
    "    \n",
    "    Use Quandl's servers to get daily adjusted closes for a company after that company has a \n",
    "    dividend or stock split. This will grab adjusted closes starting from the first day of\n",
    "    intraday data we have for that stock, to current day and store these in a data dictionary\n",
    "    to be used by a further function to update our highs/lows/closes/typicals for that company.\n",
    "    This also gets the date for each adjusted close value.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    # For every stock symbol besides these 3 indexes the retrieval symbol is the same with\n",
    "    # either the GOOG/NASDAQ_ or GOOG/NYSE_ prepended\n",
    "    other   = {'^IXIC':\"NASDAQOMX/COMP\",\n",
    "               '^GSPC':\"YAHOO/INDEX_GSPC\",\n",
    "               '^DJI':\"YAHOO/INDEX_DJI\"}\n",
    "    \n",
    "    \n",
    "    for key in ticker_lst:\n",
    "        new_intra[key] = intra[key]\n",
    "\n",
    "    for key in new_intra.keys():\n",
    "        # Date of our first record for each company, and the current day\n",
    "        start_date = str(new_intra[key].index[0])[:10]\n",
    "        end_date   = str(datetime.date.today())\n",
    "        \n",
    "        # If not one of the three indexes\n",
    "        if key not in other.keys():\n",
    "            # Try prepending GOOG/NASDAQ_, else its the other prepend name\n",
    "            # .4 stands for the column number, which is the closing value column.\n",
    "            # There's a lot of available data to retrieve from Quandl but we only\n",
    "            # need closing prices for our update\n",
    "            try:\n",
    "                data_dict[key] = quandl.get(\"GOOG/NASDAQ_\"+key+'.4', trim_start=start_date, \n",
    "                                            trim_end=end_date, authtoken=\"gEC9xAKi4avigPpoQPX1\",\n",
    "                                            returns='numpy')\n",
    "            except:\n",
    "                data_dict[key] = quandl.get(\"GOOG/NYSE_\"+key+'.4', trim_start=start_date,\n",
    "                                            trim_end=end_date, authtoken=\"gEC9xAKi4avigPpoQPX1\",\n",
    "                                            returns='numpy')\n",
    "                pass\n",
    "        # If its one of the indexes\n",
    "        else:\n",
    "            # The IXIC index has the closing values in the first column, the two others in the\n",
    "            # 6th column\n",
    "            if key == '^IXIC':\n",
    "                data_dict[key] = quandl.get(other[key]+'.1', trim_start=start_date,\n",
    "                                            trim_end=end_date, authtoken=\"gEC9xAKi4avigPpoQPX1\",\n",
    "                                            returns='numpy')\n",
    "            else:\n",
    "                data_dict[key] = quandl.get(other[key]+'.6', trim_start=start_date,\n",
    "                                            trim_end=end_date, authtoken=\"gEC9xAKi4avigPpoQPX1\",\n",
    "                                            returns='numpy')\n",
    "    return data_dict, new_intra\n",
    "\n",
    "def update_hlc_for_spldivs(data_dict, intra, ticker_lst, update=False):\n",
    "    \"\"\"\n",
    "    Take our highlowclose dictionary with the data dictionary containing daily adjusted closes,\n",
    "    and use these to update our highs/lows/closes/typicals. We do this by grabbing the date \n",
    "    accompanying each adjusted close value, call that date subset of our highlowclose dataframe\n",
    "    and multiply those values by the adjusted close divided by the undajusted close, and that \n",
    "    value is multiplied to that day's data. We then add this to a new dataframe, and keep \n",
    "    appending day by day. We do this for as many companies as we need, storing the new \n",
    "    dataframes in a new dictionary, that we pass back.\n",
    "    \n",
    "    Will save this new dictionary as a pickle file called 'updatehlcdict.pickle' that will be used\n",
    "    by the data creation file, in particular, the update_for_spldivs() function.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_intra = {}\n",
    "    cols = ['Highs','Lows','Closes','Typical']\n",
    "    \n",
    "    for key in intra.keys():\n",
    "        if key in ticker_lst:\n",
    "            # Create new empty dataframe with column names\n",
    "            new_df = pd.DataFrame(columns=[cols])\n",
    "        \n",
    "            # For each day in our company data dataframe, we adjust the values\n",
    "            # by taking that dates unadjusted closing day price and dividing \n",
    "            # the adjusted value retrieved from the Quandl server, and then\n",
    "            # multiply that ratio by all the days value.\n",
    "            for x in range(len(data_dict[key])):\n",
    "                try:\n",
    "                    adj_date  = str(data_dict[key][x][0])[:10]\n",
    "                    adj_close = data_dict[key][x][1]\n",
    "                    df        = intra[key][cols][adj_date]\n",
    "                    close     = df['Closes'].iloc[-1]\n",
    "                    adj_df    = df * (adj_close / close)\n",
    "\n",
    "                    # Then append the new adjusted days together\n",
    "                    new_df    = new_df.append(adj_df)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            new_intra[key] = new_df\n",
    "    \n",
    "    # If we need to adjust every companies data, we dump as the first, else the second\n",
    "    if update == False:\n",
    "        opp = open('Pickles/pickleadjustedintracomplete.pickle','wb')\n",
    "    else:\n",
    "        opp = open('Pickles/onlyupdateintra.pickle','wb')\n",
    "    pickle.dump(new_intra, opp)\n",
    "    opp.close()\n",
    "    return\n",
    "\n",
    "print \"LOADED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_new_data(intra_data):\n",
    "    \"\"\"\n",
    "    Get our new data, starting from the next trading day after our last trading day's data. We\n",
    "    call retrieve_bonnet_data function passing this next date, then adjust the highs and lows \n",
    "    to be the day's highs and lows, not just that minutes highs and lows by calling our \n",
    "    adjust_bonnet_high_lows function, passing the data that was retrieved from our \n",
    "    retrieve_bonnet_data call, and this returns our adjusted data. We then change the\n",
    "    index datetime strings to pandas timestamp indexes to help in our future calculations. \n",
    "    Finally we calculate the typical values for these new values and return the this new data as\n",
    "    well as the old data.\n",
    "    \"\"\"\n",
    "    # Get a companies stock symbol, doesn't matter which as long as the stocks have the same\n",
    "    # last update date\n",
    "    comp_key  = intra_data.keys()[0]\n",
    "    new_adj   = {}\n",
    "    # Previous date is the last day that we updated our highlowclose dictionary since present\n",
    "    prev_date = str((intra_data[comp_key].index)[-1])[:10]\n",
    "    # End date is just set as a year from the last update, just for simple way for future date\n",
    "    end_date  = str(int(prev_date[:4])+1) + prev_date[4:]\n",
    "    start     = datetime.datetime.strptime(prev_date, '%Y-%m-%d').date()\n",
    "    end       = datetime.datetime.strptime(end_date, '%Y-%m-%d').date()\n",
    "    rs2       = NYSE_tradingdays2(start, end)\n",
    "    # From date will be next trading day after our last update\n",
    "    from_date = str(rs2[1])[:10]\n",
    "    # Grab today's date to then send it to our today_func\n",
    "    today     = str(datetime.date.today())\n",
    "    \n",
    "    # Get at least an extra trading day into the future because if not done, you won't get\n",
    "    # the current days data\n",
    "    to_date     = today_func(today, rs2)\n",
    "    # Retrieve our data from our data source\n",
    "    data,yh_tks = retrieve_bonnet_data(from_date, to_date, intra_data)\n",
    "    # Adjust our highs and lows to be day highs/lows rather than minute highs/lows\n",
    "    adj         = adjust_bonnet_high_lows(data, yh_tks)\n",
    "    \n",
    "    # Convert from string timestamps to pandas timestamps\n",
    "    for key, value in adj.iteritems():\n",
    "        new_indx = []\n",
    "        \n",
    "        for each in value.index:\n",
    "            new_indx.append(pd.Timestamp(each))\n",
    "        \n",
    "        # Create our typical values columns for each company\n",
    "        value.index      = new_indx\n",
    "        value['Typical'] = (value['Highs'] + value['Lows'] + value['Closes']) / 3.\n",
    "        new_adj[key]     = value\n",
    "\n",
    "    return intra_data, new_adj\n",
    "\n",
    "def today_func(today, rs2):\n",
    "    \"\"\"\n",
    "    Calculate the next trading day so that when you grab data it gets you today's\n",
    "    data as well, because if you plug today's date into that url grab, it will only\n",
    "    grab up until the end of yesterday's data.\n",
    "    \"\"\"\n",
    "    to_date   = 'None'\n",
    "    while to_date == 'None':\n",
    "        for x in range(len(rs2[:])):\n",
    "            if str(rs2[x])[:10] == today:\n",
    "                to_date = str(rs2[x+1])[:10]\n",
    "                break\n",
    "            \n",
    "        if to_date == 'None':\n",
    "            if int(today[len(today)-2:]) < 9:\n",
    "                tomor = '0' + str(int(today[len(today)-2:])+1)\n",
    "            elif int(today[len(today)-2:]) > 28:\n",
    "                print \"TO_DATE FAIL\"\n",
    "                return\n",
    "            else:\n",
    "                tomor = str(int(today[len(today)-2:])+1)\n",
    "            today = today[:len(today)-2]+tomor\n",
    "    return to_date\n",
    "\n",
    "def retrieve_bonnet_data(fromd, today, hlc):\n",
    "    \"\"\"\n",
    "    This function retrieves our new intraday trading data from our data source thanks to\n",
    "    The Bonnot Gang site, that gives us free intraday data, which the have available from\n",
    "    mid 2011 to present, but we just grab the data we need.\n",
    "    \n",
    "    We grab each of our companies we're calculating for's data, and convert the .csv format to\n",
    "    our dataframe format.\n",
    "    \"\"\"\n",
    "    pages          = {}\n",
    "    yahoo_tickers  = {'^DJI':'DJI', '^GSPC':'GSPC', '^IXIC':'IXIC'}\n",
    "    \n",
    "    for name in hlc.keys():\n",
    "        # If not the 3 indexes, else use the key value name\n",
    "        if name in yahoo_tickers.keys():\n",
    "            name2 = yahoo_tickers[name]\n",
    "        else:\n",
    "            name2 = name\n",
    "        # set page to be our source link and then grab the data and store each companies\n",
    "        # data in its own dictionary key/value pair\n",
    "        page = 'http://www.thebonnotgang.com/quotes/q.php?timeframe=1m&dayFrom='+fromd+\\\n",
    "               '&dayTo='+today+'&symbol='+name2\n",
    "        pages[name] = urllib.urlopen(page).read()\n",
    "\n",
    "    # Then take the steps to convert data from strings containing data we don't \n",
    "    # need to just the data we need in the format we need it. Floats for highs,\n",
    "    # lows, and closes as well as the dates for each entries\n",
    "    complete_list = []\n",
    "    for each in yahoo_tickers:\n",
    "        current = pages[each]\n",
    "        start   = current.find('2016')\n",
    "        end     = len(current)\n",
    "        test    = True\n",
    "        df_list = []\n",
    "\n",
    "        while test == True:\n",
    "            date_end = current.find(';',start)\n",
    "            open_end = current.find(';',date_end+1)\n",
    "            high_end = current.find(';',open_end+1)\n",
    "            low_end  = current.find(';',high_end+1)\n",
    "            close_end = current.find(';',low_end+1)\n",
    "\n",
    "            date  = current[start:date_end]\n",
    "            try:\n",
    "                high  = float(current[open_end+1:high_end].replace(',','.'))\n",
    "            except:\n",
    "                print each\n",
    "                raise\n",
    "            low   = float(current[high_end+1:low_end].replace(',','.'))\n",
    "            close = float(current[low_end+1:close_end].replace(',','.'))\n",
    "\n",
    "            t = int(date[11:13])-4\n",
    "            if t < 10:\n",
    "                t = '0'+str(t)\n",
    "            else:\n",
    "                t = str(t)\n",
    "            date = date[0:11]+t+date[13:]\n",
    "\n",
    "            day = [date, high, low, close]\n",
    "            df_list.append(day)\n",
    "\n",
    "            start = current.find('2016-', close_end)\n",
    "            if start == -1:\n",
    "                break\n",
    "\n",
    "        # Put all these values into a dataframe renaming the columns\n",
    "        # Set the Time column to be the index\n",
    "        df = pd.DataFrame(df_list, columns=['Time','Highs','Lows','Closes'])\n",
    "        df = df.set_index('Time')\n",
    "\n",
    "        # Append each dataframe to our list, then return that list with the list of names\n",
    "        complete_list.append(df)\n",
    "    return complete_list, yahoo_tickers\n",
    "\n",
    "def adjust_bonnet_high_lows(adjusted_intra, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    We need to convert our days high and low values for each day to be the day high and low rather\n",
    "    than the minute high and low values.\n",
    "    \"\"\"\n",
    "    new_adjusted_intra = {}\n",
    "    \n",
    "    z = 0\n",
    "    for df in adjusted_intra:\n",
    "        # Adjust our higs/lows to day highs/lows instead of minute highs/lows and combine into\n",
    "        # new dataframe with closes and our index\n",
    "        highs  = df['Highs'].values.tolist()\n",
    "        lows   = df['Lows'].values.tolist()\n",
    "        closes = df['Closes'].values.tolist()\n",
    "        index  = df.index\n",
    "        prev   = 0\n",
    "\n",
    "        for x in xrange(1,len(highs)):\n",
    "            if index[x][8:10] == index[x-1][8:10]:\n",
    "                highs[x] = max(highs[prev:x+1])\n",
    "                lows[x]  = min(lows[prev:x+1])\n",
    "            else:\n",
    "                prev = x\n",
    "\n",
    "        df         = pd.DataFrame([index,highs,lows,closes]).T\n",
    "        df.columns = ['Time','Highs','Lows','Closes']\n",
    "        df         = df.set_index(['Time'])\n",
    "\n",
    "        # Create our dictionary with our dataframes containing all of our new data\n",
    "        new_adjusted_intra[yahoo_tickers[z]] = df\n",
    "        z += 1\n",
    "    return new_adjusted_intra\n",
    "\n",
    "def resample_intraday(hlc):\n",
    "    \"\"\"\n",
    "    Make the indexes the same for each company, meaning we resample the times to be at the \n",
    "    beginning of each minute, rather than sometime during that minute.\n",
    "    \"\"\"\n",
    "    new_hlc, count = {}, 0\n",
    "    for key, value in hlc.iteritems():\n",
    "        new_df = pd.DataFrame()\n",
    "        \n",
    "        # Ensure we don't have duplicate rows that curiously occurred several times\n",
    "        value  = value.reset_index().drop_duplicates(subset='index', \n",
    "                                                     keep='last').set_index('index')\n",
    "        # Take our index from our dataframe and convert the first and last timestamps\n",
    "        # to yyyy-mm-dd format getting rid of the time after the date\n",
    "        index  = value.index\n",
    "        start  = datetime.datetime.strptime((str(index[0])[:10]), '%Y-%m-%d').date()\n",
    "        end    = datetime.datetime.strptime((str(index[-1])[:10]), '%Y-%m-%d').date()\n",
    "        # Call our trading days function that will give us a list of trading days \n",
    "        # between our two given dates we feed it.\n",
    "        rs2    = NYSE_tradingdays2(start, end)\n",
    "        # How many trading days between the two dates\n",
    "        length = len(rs2[:])\n",
    "\n",
    "        for x in range(length):\n",
    "            # For each trading timestamp, first convert to date only in str format instead\n",
    "            # of both date and time which is given as 00:00:00\n",
    "            date   = str(rs2[x])[:10]\n",
    "            # Retrieve that date's values from our dataframe\n",
    "            day    = value[date]\n",
    "            # Resample each day, setting the time value to be the top of every minute\n",
    "            # This was done to match datetimes since dataframes usually were a second \n",
    "            # or two off between companies which meant it was harder to call a datetime\n",
    "            # for one or more companies at once.\n",
    "            reday  = day.resample('T').pad().fillna(method='bfill')\n",
    "            # Series are mutable, so we need to create a new dataframe with this new series\n",
    "            new_df = new_df.append(reday)  \n",
    "\n",
    "        new_hlc[key] = new_df\n",
    "        stdout.write(\"\\r%d\" % count)\n",
    "        stdout.flush() \n",
    "        count += 1\n",
    "    return new_hlc\n",
    "\n",
    "print \"LOADED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_hlc(intra, resampled_adj):\n",
    "    \"\"\"\n",
    "    Calculate indicator values. Then return these indicators for use in updating our files.\n",
    "    Adx_d3 is a precalculated dictionary with dataframes that needed to be put together\n",
    "    due to several factors that may eventually be seperated like the others but currently\n",
    "    isn't. The others are used in the ML portion of the algorithm only.\n",
    "    \"\"\"\n",
    "    rs            = NYSE_tradingdays()\n",
    "    short         = str(rs[0])[:10]\n",
    "    hlc_cols      = ['Highs','Lows','Closes','Typical']\n",
    "\n",
    "    # Add our new data to our old data and drop any duplicate rows\n",
    "    for key,value in intra.iteritems():\n",
    "        intra[key] = intra[key][hlc_cols].append(resampled_adj[key][hlc_cols])\n",
    "        intra[key] = intra[key].reset_index().drop_duplicates(subset='index',\n",
    "                                                        keep='last').set_index('index')\n",
    "\n",
    "    return intra\n",
    "\n",
    "print \"LOADED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Call these functions to update your high/low/close/typical dictionary\n",
    "\"\"\"\n",
    "old_intra, adj = add_new_data(new_hlc)\n",
    "resampled_adj  = resample_intraday(adj)\n",
    "intra          = update_hlc(old_intra, resampled_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If this is for the initial creation of your indicators:\n",
    "  Use the created ticker list with all of your hlc dictionaries, to ensure you're \n",
    "  up to date and ajusted for all your stocks/funds. \n",
    "\n",
    "If just updating one or more stocks: \n",
    "  Uncomment the first ticker list, get_quandl call, and update_hlc call, \n",
    "  and input the stock tickers in a list format for the stocks you need updated only. \n",
    "  Then comment out the second ticker list, quandl, and hlc call.\n",
    "\"\"\"\n",
    "#ticker_lst = ['ONLY UPDATED LIST',]\n",
    "#data_dict, intra = get_quandl_adjcloses(ticker_lst, intra)\n",
    "#update_hlc_for_spldivs(data_dict, intra, ticker_lst, update=True)\n",
    "ticker_lst = ['^IXIC','^GSPC','^DJI','USO','GLD','SPY','AAPL','AMD',\n",
    "              'BP','BRCD','F','GOOG','GS','HBAN','LMT','LYG','RF',\n",
    "              'S','SIRI','WIN']\n",
    "data_dict, intra = get_quandl_adjcloses(ticker_lst, intra)\n",
    "update_hlc_for_spldivs(data_dict, intra, ticker_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
