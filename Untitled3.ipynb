{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from googlefinance import getQuotes, getNews\n",
    "from yahoo_finance import Share\n",
    "from dateutil import rrule  \n",
    "from sys import stdout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import urllib\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def NYSE_holidays(a=datetime.date.today()-datetime.timedelta(days=1), b=datetime.date.today()+datetime.timedelta(days=365)): \n",
    "    # Credit to https://gist.github.com/jckantor/d100a028027c5a6b8340 for this trading date function\n",
    "    # Generate ruleset for holiday observances on the NYSE \n",
    "    rs = rrule.rruleset()\n",
    "    # Include all potential holiday observances \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=12, bymonthday=31, byweekday=rrule.FR)) # New Years Day   \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 1, bymonthday= 1))                     # New Years Day   \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 1, bymonthday= 2, byweekday=rrule.MO)) # New Years Day     \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 1, byweekday= rrule.MO(3)))            # Martin Luther King Day    \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 2, byweekday= rrule.MO(3)))            # Washington's Birthday \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, byeaster= -2))                                  # Good Friday \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 5, byweekday= rrule.MO(-1)))           # Memorial Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 7, bymonthday= 3, byweekday=rrule.FR)) # Independence Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 7, bymonthday= 4))                     # Independence Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 7, bymonthday= 5, byweekday=rrule.MO)) # Independence Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 9, byweekday= rrule.MO(1)))            # Labor Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=11, byweekday= rrule.TH(4)))            # Thanksgiving Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=12, bymonthday=24, byweekday=rrule.FR)) # Christmas   \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=12, bymonthday=25))                     # Christmas   \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=12, bymonthday=26, byweekday=rrule.MO)) # Christmas  \n",
    "    # Exclude potential holidays that fall on weekends \n",
    "    rs.exrule(rrule.rrule(rrule.WEEKLY, dtstart=a, until=b, byweekday=(rrule.SA,rrule.SU))) \n",
    "    return rs \n",
    "def NYSE_tradingdays(a=datetime.date.today()-datetime.timedelta(days=1), b=datetime.date.today()+datetime.timedelta(days=365)): \n",
    "    # Credit to https://gist.github.com/jckantor/d100a028027c5a6b8340 for this trading date function\n",
    "    # Generate ruleset for NYSE trading days \n",
    "    rs = rrule.rruleset() \n",
    "    rs.rrule(rrule.rrule(rrule.DAILY, dtstart=a, until=b)) \n",
    "    # Exclude weekends and holidays \n",
    "    rs.exrule(rrule.rrule(rrule.WEEKLY, dtstart=a, byweekday=(rrule.SA,rrule.SU))) \n",
    "    rs.exrule(NYSE_holidays(a,b)) \n",
    "    return rs \n",
    "def highlowcloselist_create(yahoo_data, yahoo_tickers):\n",
    "    highlowcloselist = {}\n",
    "    for each in yahoo_tickers:\n",
    "        low, high, close = [], [], []\n",
    "        typical_price, date = [], []\n",
    "        for x in xrange(0,len(yahoo_data[each])):\n",
    "            high.append(float(yahoo_data[each][x]['High'].replace(',','')))\n",
    "            low.append(float(yahoo_data[each][x]['Low'].replace(',','')))\n",
    "            close.append(float(yahoo_data[each][x]['Adj_Close'].replace(',','')))\n",
    "            typical_price.append((float(yahoo_data[each][x]['High'].replace(',','')) + \n",
    "                                  float(yahoo_data[each][x]['Low'].replace(',','')) + \n",
    "                                  float(yahoo_data[each][x]['Adj_Close'].replace(',',''))) / 3.)\n",
    "            date.append(yahoo_data[each][x]['Date'])\n",
    "        highlowcloselist[each] = [high, low, close, typical_price, date]\n",
    "    return highlowcloselist\n",
    "def kd_ratio_create(highlowcloselist, yahoo_tickers):  \n",
    "    kd_ratio_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        ratio, k, d = [], [], []\n",
    "        for y in xrange(0, len(highlowcloselist[each][0])):\n",
    "            if y > 3:\n",
    "                find_5_min = min(highlowcloselist[each][1][y-4 : y+1])\n",
    "                find_5_max = max(highlowcloselist[each][0][y-4 : y+1])\n",
    "                cl = highlowcloselist[each][2][y] - find_5_min\n",
    "                hl = find_5_max - find_5_min\n",
    "                if hl != 0:\n",
    "                    k.append((cl / hl) * 100)\n",
    "                else:\n",
    "                    k.append(0)\n",
    "                if y > 5:\n",
    "                    d.append(np.mean(k[y-2 : y+1]))\n",
    "                    ratio.append(k[y] / d[y])\n",
    "                else:\n",
    "                    d.append(0)\n",
    "                    ratio.append(0)\n",
    "            else:\n",
    "                ratio.append(0)\n",
    "                k.append(0)\n",
    "                d.append(0)\n",
    "        kd_ratio_dict[each] = [k, d, ratio]\n",
    "    return kd_ratio_dict\n",
    "def cci_create(highlowclose, yahoo_tickers):\n",
    "    cci_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        cci, sum_abs_val = [], 0\n",
    "        constant = 0.015\n",
    "        for y in xrange(0, len(highlowclose[each][0])):\n",
    "            if y > 18:\n",
    "                mean = np.mean(highlowclose[each][3][y-19 : y+1])\n",
    "                for z in xrange(19, -1, -1):\n",
    "                    abs_val = abs(highlowclose[each][3][y-z] - mean)\n",
    "                    sum_abs_val += abs_val\n",
    "                mean_deviation = sum_abs_val / 20.\n",
    "                cci.append((highlowclose[each][3][y] - np.mean(highlowclose[each][3][y-19 : y+1])) / (constant * mean_deviation))\n",
    "            else:\n",
    "                cci.append(0)\n",
    "        cci_dict[each] = cci\n",
    "    return cci_dict\n",
    "def volatility_create(highlowcloselist, yahoo_tickers):\n",
    "    vol_dict = {}\n",
    "    for each2 in yahoo_tickers:\n",
    "        total, volatility = 0, []\n",
    "        for y in xrange(0, len(highlowcloselist[each2][0])):\n",
    "            if y > 28:\n",
    "                try:\n",
    "                    voli_closing = highlowcloselist[each2][2][y-29 : y+1]\n",
    "                except:\n",
    "                    print each, y\n",
    "                    raise\n",
    "                mean = np.mean(voli_closing)\n",
    "                for each in voli_closing:\n",
    "                    sqr_dev = (each - mean)**2\n",
    "                    total += sqr_dev\n",
    "                volatility.append(total / 30.)\n",
    "            else:\n",
    "                volatility.append(0)\n",
    "        vol_dict[each2] = volatility\n",
    "    return vol_dict\n",
    "def aroon_create(highlowcloselist, yahoo_tickers):\n",
    "    aroon_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        aroon_index = []\n",
    "        for y in xrange(0, len(highlowcloselist[each][0])):\n",
    "            if y > 23:\n",
    "                new_closing = highlowcloselist[each][2][y-24 : y+1]\n",
    "                aroon_up   = ((25 - new_closing.index(max(new_closing))) / 25.) * 100\n",
    "                aroon_down = ((25 - new_closing.index(min(new_closing))) / 25.) * 100\n",
    "                aroon_index.append(aroon_up / aroon_down)\n",
    "            else:\n",
    "                aroon_index.append(0)\n",
    "        aroon_dict[each] = aroon_index\n",
    "    return aroon_dict\n",
    "def macd_create(highlowcloselist, yahoo_tickers):\n",
    "    macd_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        n, m, close = 12, 26, highlowcloselist[each][2]\n",
    "        first_12_ema = np.mean(close[0:12])\n",
    "        first_26_ema = np.mean(close[0:26])\n",
    "        multiplier_12 = (2. / (n + 1.))\n",
    "        multiplier_26 = (2. / (m + 1.))\n",
    "        ema_12_list, ema_26_list, macd = [], [], []\n",
    "        for y in xrange(0, len(close)):\n",
    "            if y > 10:\n",
    "                each_12_ema = (close[y] - first_12_ema) * multiplier_12 + first_12_ema\n",
    "                ema_12_list.append(each_12_ema)\n",
    "                first_12_ema = each_12_ema\n",
    "                if y > 24:\n",
    "                    each_26_ema = (close[y] - first_26_ema) * multiplier_26 + first_26_ema\n",
    "                    ema_26_list.append(each_26_ema)\n",
    "                    first_26_ema = each_26_ema\n",
    "                    macd.append(each_12_ema - each_26_ema)\n",
    "                else:\n",
    "                    ema_26_list.append(0)\n",
    "                    macd.append(0)\n",
    "            else:\n",
    "                ema_12_list.append(0)\n",
    "                ema_26_list.append(0)\n",
    "                macd.append(0)\n",
    "        macd_dict[each] = [ema_12_list, ema_26_list, macd]\n",
    "    return macd_dict\n",
    "def rsi_create(highlowcloselist, yahoo_tickers):\n",
    "    rsi_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        close = highlowcloselist[each][2]\n",
    "        n, up_move, down_move, rsi = 14, [], [], []\n",
    "        for y in xrange(0, len(highlowcloselist[each][0])):\n",
    "            if y > 0:\n",
    "                current = close[y]\n",
    "                previous = close[y-1]\n",
    "                test = current-previous\n",
    "                if test >= 0:\n",
    "                    up_move.append(test)\n",
    "                    down_move.append(0.)\n",
    "                else:\n",
    "                    up_move.append(0.)\n",
    "                    down_move.append(abs(test))\n",
    "            else:\n",
    "                up_move.append(0)\n",
    "                down_move.append(0)\n",
    "        for y in xrange(0, len(up_move)):\n",
    "            first_14_up   = np.mean(up_move[0:14])\n",
    "            first_14_down = np.mean(down_move[0:14])\n",
    "            multiplier_14 = (2. / (n + 1.))\n",
    "            if y > 12:\n",
    "                ema_up        = up_move[y] * multiplier_14 + first_14_up * (1. - multiplier_14)\n",
    "                ema_down      = down_move[y] * multiplier_14 + first_14_down * (1. - multiplier_14)\n",
    "                rs            = ema_up / ema_down\n",
    "                first_14_up   = ema_up\n",
    "                first_14_down = ema_down\n",
    "                rsi.append(100. - (100. / ( 1. + rs)))\n",
    "            else:\n",
    "                rsi.append(0)\n",
    "        rsi_dict[each] = [up_move, down_move, rsi]\n",
    "    return rsi_dict\n",
    "def adx_create(highlowcloselist, yahoo_tickers):\n",
    "    adx_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        true_range, plus_dm, minus_dm, tr14_list, dx14_list = [], [], [], [], [] \n",
    "        pos_dm14_list, neg_dm14_list, adx14_list = [], [], []\n",
    "        for y in xrange(0, len(highlowcloselist[each][0])):\n",
    "            if y > 1:\n",
    "                high = highlowcloselist[each][0]\n",
    "                low = highlowcloselist[each][1]\n",
    "                close = highlowcloselist[each][2]\n",
    "                true_range.append(max((high[y] - low[y]), abs(high[y] - close[y-1]), abs(low[y] - close[y-1])))\n",
    "                plus_dm.append(high[y]  - high[y-1])\n",
    "                minus_dm.append(low[y-1] - low[y])\n",
    "                if plus_dm < 0:\n",
    "                    plus_dm = 0\n",
    "                if minus_dm < 0:\n",
    "                    minus_dm = 0\n",
    "            else:\n",
    "                true_range.append(0)\n",
    "                plus_dm.append(0)\n",
    "                minus_dm.append(0)    \n",
    "        first_tr14     = sum(true_range[0:14])\n",
    "        first_pos_dm14 = sum(plus_dm[0:14])\n",
    "        first_neg_dm14 = sum(minus_dm[0:14])\n",
    "        for y in xrange(0, len(true_range)):\n",
    "            if y > 12:\n",
    "                tr14      = first_tr14     - (first_tr14     / 14.) + true_range[y]\n",
    "                pos_dm14  = first_pos_dm14 - (first_pos_dm14 / 14.) + plus_dm[y]\n",
    "                neg_dm14  = first_neg_dm14 - (first_neg_dm14 / 14.) + minus_dm[y]\n",
    "                pos_di14  = (pos_dm14 / tr14) * 100.\n",
    "                neg_di14  = (neg_dm14 / tr14) * 100.\n",
    "                if (pos_di14 + neg_di14) != 0:\n",
    "                    dx14 = (pos_di14 - neg_di14) / (pos_di14 + neg_di14) \n",
    "                else:\n",
    "                    dx14 = 0       \n",
    "                tr14_list.append(tr14)\n",
    "                dx14_list.append(dx14)\n",
    "                pos_dm14_list.append(pos_dm14)\n",
    "                neg_dm14_list.append(neg_dm14)\n",
    "                first_tr14     = tr14\n",
    "                first_pos_dm14 = pos_dm14\n",
    "                first_neg_dm14 = neg_dm14\n",
    "            else:\n",
    "                tr14_list.append(0)\n",
    "                dx14_list.append(0)\n",
    "                pos_dm14_list.append(0)\n",
    "                neg_dm14_list.append(0)\n",
    "        first_adx14 = sum(dx14_list[0:28])\n",
    "        for y in xrange(0, len(dx14_list)):\n",
    "            if y > 26:\n",
    "                adx14 = ((first_adx14 * 13.) + dx14_list[y]) / 14.\n",
    "                adx14_list.append(adx14)\n",
    "                first_adx14 = adx14\n",
    "            else:\n",
    "                adx14_list.append(0)\n",
    "        adx_dict[each] = [true_range, plus_dm, minus_dm, tr14_list, dx14_list, pos_dm14_list, neg_dm14_list, adx14_list]\n",
    "    return adx_dict\n",
    "\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def company_news(newstickers):\n",
    "    tickernewslist = {}\n",
    "    \n",
    "    for each in newstickers:\n",
    "        tickernewslist[each] = getNews(each)  \n",
    "    return tickernewslist\n",
    "\n",
    "def stock_splits(stock_split_dates):\n",
    "    splitup        = urllib.urlopen(stock_split_dates).read()\n",
    "    companies      = splitup.find('Announced')\n",
    "    stop           = splitup.find('th_No_BG', companies)\n",
    "    company_splits = []\n",
    "    \n",
    "    while True:\n",
    "        done      = splitup.find(')</a>',stop)+1\n",
    "        next_stop = splitup.rfind('(', stop, done)\n",
    "        ratio_s   = splitup.find('<td>',done)+4\n",
    "        ratio_e   = splitup.find('<',ratio_s)\n",
    "        payment_e = splitup.find('2016',done)+4\n",
    "        payment_s = splitup.rfind('<td>',stop,payment_e)+4\n",
    "        exdate_s  = splitup.find('<td>',payment_e)+4\n",
    "        exdate_e  = splitup.find('</td>',exdate_s)\n",
    "        \n",
    "        company_splits.append([splitup[next_stop+1:done-1],\n",
    "                               splitup[exdate_s:exdate_e],\n",
    "                               splitup[ratio_s:ratio_e],\n",
    "                               splitup[payment_s:payment_e]])\n",
    "        \n",
    "        tbody = splitup.find('</table>',done)\n",
    "        test  = splitup.find('(',done)\n",
    "        \n",
    "        if tbody < test:\n",
    "            break\n",
    "        stop = done\n",
    "    return company_splits\n",
    "\n",
    "def dividend_find(dividend_dates): \n",
    "    company_dividends = []\n",
    "    for x in xrange(0,2):\n",
    "        if x != 0:\n",
    "            dividends      = urllib.urlopen(dividend_dates).read()  \n",
    "            end            = dividends.find('Next')-2\n",
    "            start          = dividends.rfind('href=',0,end)+6\n",
    "            next_day       = dividends[start:end]\n",
    "            dividend_dates = 'http://www.nasdaq.com/dividend-stocks/'+next_day \n",
    "            \n",
    "        dividends = urllib.urlopen(dividend_dates).read()  \n",
    "        start     = dividends.find('Payment Date')\n",
    "        \n",
    "        while True:\n",
    "            start      = dividends.find('&#40;',start)+5\n",
    "            end        = dividends.find('&#41;',start)\n",
    "            ex_date_e  = dividends.find('2016',end)+4\n",
    "            ex_date_s  = dividends.rfind('>',end,ex_date_e)+1\n",
    "            div_e      = dividends.find('</',ex_date_e+1)\n",
    "            div_s      = dividends.rfind('>',ex_date_e,div_e)+1\n",
    "            rec_date_e = dividends.find('2016',div_e)+4\n",
    "            rec_date_s = dividends.rfind('>',div_e,rec_date_e)+1\n",
    "            proceed    = dividends.find('2016',rec_date_e)+4\n",
    "            pay_date_e = dividends.find('2016',proceed)+4\n",
    "            pay_date_s = dividends.rfind('>',proceed,pay_date_e)+1\n",
    "            \n",
    "            company_dividends.append([dividends[start:end],\n",
    "                                    dividends[ex_date_s:ex_date_e],\n",
    "                                    dividends[div_s:div_e],\n",
    "                                    dividends[rec_date_s:rec_date_e],\n",
    "                                    dividends[pay_date_s:pay_date_e]])\n",
    "            \n",
    "            test = dividends.find('&#40;',start)\n",
    "            if test == -1:\n",
    "                break\n",
    "            start = end      \n",
    "    return company_dividends\n",
    "\n",
    "def yahoo_backup():\n",
    "    test_array = []\n",
    "    yahoo      = 'http://finance.yahoo.com/q?s='\n",
    "    tickers    = ['LGF', 'AMAG', 'CYH', 'HA', 'HPQ', 'ENDP', 'VRX', \n",
    "                  'SVU', 'FBR', 'IMGN', 'UIS', 'NSM', 'YRCW', 'BZH', \n",
    "                  'SWN', 'ATW', 'EXAS', 'TK', 'PBR', 'ITUB', 'LSCC', \n",
    "                  'MBI', 'SBS', 'AG', 'STLD', 'ATSG', 'HR', 'WTW', \n",
    "                  'GGAL', 'NJR', 'ITG', 'AEIS', 'NEM', 'ANF', 'INT', \n",
    "                  'COH', 'TREX', 'CSH', 'NTGR', 'BRKR', 'EDE', 'CCOI', \n",
    "                  'HRL', 'AEM', 'GVA', 'NVDA', 'CBT', 'CSGS',\n",
    "                  '%5EIXIC','%5EDJI','^RUT','^GSPC','^NYA']\n",
    "    \n",
    "    for each in tickers:\n",
    "        stock       = yahoo + each\n",
    "        page        = urllib.urlopen(stock).read()\n",
    "        price       = page.find('time_rtq_ticker')\n",
    "        price_stop  = page.find('</span>',price)\n",
    "        price_start = page.rfind('>',price_stop-10,price_stop)+1\n",
    "        \n",
    "        test_array.append(page[price_start:price_stop])\n",
    "    return test_array\n",
    "\n",
    "def get_prev_10d1min_intraday():\n",
    "    tickers          = ['LGF', 'AMAG', 'CYH', 'HA', 'HPQ', 'ENDP', 'VRX', \n",
    "                          'SVU', 'FBR', 'IMGN', 'UIS', 'NSM', 'YRCW', 'BZH', \n",
    "                          'SWN', 'ATW', 'EXAS', 'TK', 'PBR', 'ITUB', 'LSCC', \n",
    "                          'MBI', 'SBS', 'AG', 'STLD', 'ATSG', 'HR', 'WTW', \n",
    "                          'GGAL', 'NJR', 'ITG', 'AEIS', 'NEM', 'ANF', 'INT', \n",
    "                          'COH', 'TREX', 'CSH', 'NTGR', 'BRKR', 'EDE', 'CCOI', \n",
    "                          'HRL', 'AEM', 'GVA', 'NVDA', 'CBT', 'CSGS',\n",
    "                      'IXIC','.DJI','RUT','.INX','NYA',\n",
    "                       'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "    pages = {}\n",
    "    for each in tickers:\n",
    "        page = 'http://www.google.com/finance/getprices?i=60&p=10d&f=d,c&df=cpct&q='+each\n",
    "        pages[each] = urllib.urlopen(page).read()\n",
    "    complete_list = []\n",
    "    day_list = []\n",
    "    for each in tickers:\n",
    "        current = pages[each]\n",
    "        start = current.find('\\na')+2\n",
    "        end = len(current)\n",
    "        test = True\n",
    "        df_list = []\n",
    "        while test == True:\n",
    "            date = current.find(',',start)\n",
    "            price = current.find('\\n',date)\n",
    "            df_list.append(float(current[date+1:price]))\n",
    "\n",
    "            if price != end-1:\n",
    "                if current[price+1] == 'a':\n",
    "                    day_list.append(df_list)\n",
    "                    df_list = []\n",
    "                start = price+2    \n",
    "            else:\n",
    "                test = False\n",
    "                complete_list.append(day_list)\n",
    "                day_list = []        \n",
    "    return complete_list\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def real_time_quotes(tickers, new_codes, closings, outlist, yesterday, attributes):\n",
    "    tickerlist  = [[] for i in range(60)]\n",
    "    dailylist   = [[] for i in range(60)]\n",
    "    first_close = [[] for i in range(60)]\n",
    "    last_close  = [[] for i in range(60)]\n",
    "    mylist      = [[] for i in range(60)]\n",
    "    daily       = [[] for i in range(60)]\n",
    "\n",
    "    start, new_array = True, []\n",
    "    seconds, minutes, hours, i, z  = 60, 60, 6.5, 0, True\n",
    "    \n",
    "    t_end = time.time() + seconds * minutes * hours\n",
    "    while time.time() < t_end:\n",
    "        try:\n",
    "            try:\n",
    "                next_quotes = getQuotes(tickers)  \n",
    "            except:\n",
    "                print \"QUOTES ERROR\"\n",
    "                pass\n",
    "            for x in xrange(0,len(next_quotes)):\n",
    "                tickerlist[x].append(next_quotes[x])\n",
    "                \n",
    "                if start == True:\n",
    "                    first_close[x] = float(next_quotes[x]['LastTradePrice'].replace(',',''))\n",
    "                    seconds_return = 0.0\n",
    "                else:\n",
    "                    last_close[x]  = float(next_quotes[x]['LastTradePrice'].replace(',',''))\n",
    "                    seconds_return = last_close[x] / first_close[x] - 1.\n",
    "                    first_close[x] = last_close[x] \n",
    "                    \n",
    "                dailylist[x].append(seconds_return)\n",
    "                \n",
    "            \n",
    "            stdout.write(\"\\r%d\" % i)\n",
    "            stdout.flush()\n",
    "            time.sleep(10)\n",
    "                \n",
    "            if i > 0:\n",
    "                combined, z, mylist = calculate_attributes(closings, tickers, last_close, \n",
    "                                                            mylist, z, attributes)  \n",
    "                #for u in xrange(0,len(tickerlist)):\n",
    "                #    if len(tickerlist[u]) <= len(yesterday[u]):\n",
    "                #        daily[u].append((float(tickerlist[u][i]['LastTradePrice'].replace(',','')) / \n",
    "                #                         float(yesterday[u][i]['LastTradePrice'].replace(',',''))) - 1)\n",
    "                #    else:\n",
    "                #        break\n",
    " \n",
    "            i     += 1\n",
    "            start  = False \n",
    "        \n",
    "        except:\n",
    "            next_quotes = yahoo_backup()\n",
    "            for x in xrange(0,len(next_quotes)):\n",
    "                tickerlist[x].append(next_quotes[x])\n",
    "                \n",
    "                if i == 0:\n",
    "                    first_close[x] = float(next_quotes[x].replace(',',''))\n",
    "                    seconds_return = 0.0\n",
    "                else:\n",
    "                    last_close[x]  = float(next_quotes[x].replace(',',''))\n",
    "                    seconds_return = last_close[x] / first_close[x] - 1.\n",
    "                    first_close[x] = last_close[x]\n",
    "                    \n",
    "                dailylist[x].append(seconds_return)\n",
    "                \n",
    "            print \"PRIMARY FAIL\", i\n",
    "            i += 1\n",
    "            pass\n",
    "\n",
    "    return tickerlist, dailylist, combined, daily, last_close\n",
    "\n",
    "def calculate_attributes(closings, tickers, last_close, mylist, z, attributes):\n",
    "    company_combined = [[] for i in range(60)]\n",
    "    highlowcloselist = attributes[0] \n",
    "    adx_dict         = attributes[1]\n",
    "    rsi_dict         = attributes[2]\n",
    "    macd_dict        = attributes[3]\n",
    "    kd_dict          = attributes[4]\n",
    "    \n",
    "    if z == True:\n",
    "        mylist = make_year_list(closings,mylist,last_close,rsi_dict,tickers)\n",
    "\n",
    "    for x, name in zip(xrange(0,48), tickers[:48]):\n",
    "        latest = last_close[x]\n",
    "        \n",
    "        if (latest < day_low[x]) or (latest > day_high[x]):\n",
    "            if latest < day_low[x]:\n",
    "                day_low[x] = latest\n",
    "            else:\n",
    "                day_high[x] = latest\n",
    "                \n",
    "        mylist[x].loc[252] = last_close[x]\n",
    "        sma                = mylist[x][203:253].rolling(window=50,center=False).mean()\n",
    "        rm                 = mylist[x][233:253].rolling(window=20,center=False).mean()\n",
    "        rstd               = mylist[x][233:253].rolling(window=20,center=False).std()\n",
    "        upper_band         = rm + rstd * 2\n",
    "        lower_band         = rm - rstd * 2\n",
    "\n",
    "        volat, aroon, macd, cci, adx, kd, rsi = calculate_extra_attributes(\n",
    "                                                        mylist, highlowcloselist,\n",
    "                                                        adx_dict, rsi_dict, macd_dict,\n",
    "                                                        kd_dict, x, name)\n",
    "        \n",
    "        boll       = (mylist[x].loc[252,0] - rm.loc[252,0]) / (upper_band.loc[252,0] - rm.loc[252,0])\n",
    "        sma        =  sma.loc[252,0]\n",
    "        mom        = (mylist[x].loc[252,0] /  mylist[x].loc[242,0])-1\n",
    "        pe         =  mylist[x].loc[252,0] / (mylist[x].loc[252,0] - mylist[x].loc[0,0])\n",
    "        combined   = [boll, sma, mom, pe, rsi, cci, macd, aroon, volat, adx, kd]\n",
    "\n",
    "        for y in xrange(48,len(mylist)):\n",
    "            combined.append(last_close[y] / mylist[y].loc[251,0]-1)   \n",
    "        company_combined[x] = combined\n",
    "            \n",
    "    z = False\n",
    "    return company_combined, z, mylist\n",
    "\n",
    "def calculate_extra_attributes(mylist, highlowcloselist, adx_dict, rsi_dict, macd_dict, kd_dict, x, name):\n",
    "    # Setup variables\n",
    "    total              = 0.\n",
    "    sum_abs_val        = 0.\n",
    "    constant           = 0.015\n",
    "    length             = len(mylist[x])\n",
    "    len_high           = len(highlowcloselist[name][0])\n",
    "    aroon_closing      = mylist[x][length - 25 : length]\n",
    "    voli_closing       = mylist[x][length - 10 : length]\n",
    "    macd_12_df         = mylist[x][length - 12 : length]\n",
    "    macd_26_df         = mylist[x][length - 26 : length]\n",
    "    first_typical      = highlowcloselist[name][3][len_high - 19 : len_high]\n",
    "    high_4             = highlowcloselist[name][0][len_high - 4  : len_high]\n",
    "    low_4              = highlowcloselist[name][1][len_high - 4  : len_high]\n",
    "    first_12_ema       = macd_dict[name][0][-1]\n",
    "    first_26_ema       = macd_dict[name][1][-1]\n",
    "    voli_list          = voli_closing[0].values.tolist()\n",
    "    macd_12_multiplier = (2. / (12. + 1.))\n",
    "    macd_26_multiplier = (2. / (26. + 1.))\n",
    "    rsi_14_multiplier  = (2. / (14. + 1.))\n",
    "    \n",
    "    low_4.append(day_low[x])\n",
    "    high_4.append(day_high[x])\n",
    "    low_5  = low_4\n",
    "    high_5 = high_4\n",
    "    \n",
    "    # Macd\n",
    "    macd_12_ema = (macd_12_df.loc[252,0] - first_12_ema) * macd_12_multiplier + first_12_ema\n",
    "    macd_26_ema = (macd_26_df.loc[252,0] - first_26_ema) * macd_26_multiplier + first_26_ema\n",
    "    macd        = macd_12_ema - macd_26_ema\n",
    "    \n",
    "    # Aroon\n",
    "    aroon_up    = ((25. - (252 - aroon_closing[0].idxmax())) / 25.) * 100\n",
    "    aroon_down  = ((25. - (252 - aroon_closing[0].idxmin())) / 25.) * 100\n",
    "    aroon_index = aroon_up - aroon_down\n",
    "    \n",
    "    # Volatility\n",
    "    mean = np.mean(voli_list)\n",
    "    for each_close in voli_list:\n",
    "        sqr_dev  = (each_close - mean)**2\n",
    "        total   += sqr_dev\n",
    "    avg_dev      = total / 10.\n",
    "    volatility   = avg_dev**(1/2.0)\n",
    "    \n",
    "    # CCI: over +100 reflect strong price action and can signal uptrend, under -100 is opposite   \n",
    "    new_typical_price = (day_low[x] + day_high[x] + mylist[x].loc[252,0]) / 3.\n",
    "    typical_mean      = (sum(first_typical) + new_typical_price) / 20.\n",
    "    for y in xrange(18,-1,-1):\n",
    "        abs_val      = abs(highlowcloselist[name][3][(len_high-1) - y] - typical_mean)\n",
    "        sum_abs_val += abs_val\n",
    "    new_abs_val      = abs(new_typical_price - typical_mean)\n",
    "    sum_abs_val     += new_abs_val\n",
    "    mean_deviation   = sum_abs_val / 20.\n",
    "    cci              = (new_typical_price - typical_mean) / (constant * mean_deviation)\n",
    "    \n",
    "    # RSI: 0-100, overbought over 70, undersold below 30\n",
    "    if mylist[x].loc[252,0] != mylist[x].loc[251,0]:\n",
    "        last_difference = mylist[x].loc[252,0] - mylist[x].loc[251,0]\n",
    "        \n",
    "        if last_difference >= 0:\n",
    "            rsi_dict[name][0][len_high - 1] = last_difference \n",
    "            rsi_dict[name][1][len_high - 1] = 0.0\n",
    "        else:\n",
    "            rsi_dict[name][0][len_high - 1] = 0.0 \n",
    "            rsi_dict[name][1][len_high - 1] = abs(last_difference)  \n",
    "            \n",
    "        first_14_up      = np.mean(rsi_dict[name][0][len_high - 14 : len_high])\n",
    "        first_14_down    = np.mean(rsi_dict[name][1][len_high - 14 : len_high])\n",
    "        ema_up           = rsi_dict[name][0][len_high - 1] * rsi_14_multiplier + first_14_up   * (1. - rsi_14_multiplier)\n",
    "        ema_down         = rsi_dict[name][1][len_high - 1] * rsi_14_multiplier + first_14_down * (1. - rsi_14_multiplier)\n",
    "        rs               = ema_up / ema_down\n",
    "        rsi              = (100. - (100. / ( 1. + rs)))\n",
    "        prev_rsi[x]      = rsi\n",
    "    else:\n",
    "        rsi              = prev_rsi[x]\n",
    "    \n",
    "    # ADX: trend when above 25 and no trend when below 20  \n",
    "    true_range_new = max(   (day_high[x]-day_low[x]),\n",
    "                         abs(day_high[x]-mylist[x].loc[251,0]),\n",
    "                         abs(day_low[x]-mylist[x].loc[251,0]))\n",
    "    \n",
    "    plus_DM_new    = day_high[x] - highlowcloselist[name][0][-1] \n",
    "    minus_DM_new   = day_low[x]  - highlowcloselist[name][1][-1]\n",
    "    if plus_DM_new < 0:\n",
    "        plus_DM_new  = 0\n",
    "    if minus_DM_new < 0:\n",
    "        minus_DM_new = 0\n",
    "        \n",
    "    tr14     = adx_dict[name][3][-1] - (adx_dict[name][3][-1] / 14.) + true_range_new\n",
    "    pos_dm14 = adx_dict[name][5][-1] - (adx_dict[name][5][-1] / 14.) + plus_DM_new\n",
    "    neg_dm14 = adx_dict[name][6][-1] - (adx_dict[name][6][-1] / 14.) + minus_DM_new \n",
    "    pos_DI14 = (pos_dm14 / tr14) * 100. \n",
    "    neg_DI14 = (neg_dm14 / tr14) * 100.\n",
    "    dx14     = (pos_DI14 - neg_DI14) / (pos_DI14 + neg_DI14)\n",
    "    adx14    = ((adx_dict[name][7][-1] * 13.) + dx14) / 14.\n",
    "    \n",
    "    # Stochastic Oscillator: Ranges from 0-100, 80 overbough, 20 undersold\n",
    "    prev_5_min = min(low_5)\n",
    "    prev_5_max = max(high_5)\n",
    "    cl         = mylist[x].loc[252,0] - prev_5_min\n",
    "    hl         = prev_5_max - prev_5_min\n",
    "    new_k      = (cl / hl) * 100.\n",
    "    new_d      = (kd_dict[name][0][-1] + kd_dict[name][0][len_high - 2] + new_k) / 3.\n",
    "    kd_ratio   = new_d #previously was new_k / new_d\n",
    "    \n",
    "    return volatility, aroon_index, macd, cci, adx14, kd_ratio, rsi\n",
    "\n",
    "def make_year_list(closings, mylist, last_close, rsi_dict, tickers):\n",
    "    global day_low\n",
    "    global day_high\n",
    "    global prev_rsi\n",
    "    day_low  = [[] for i in range(60)]\n",
    "    day_high = [[] for i in range(60)]\n",
    "    prev_rsi = [[] for i in range(60)]\n",
    "    \n",
    "    y = 0\n",
    "    for yahoo in tickers[:48]:\n",
    "        prev_rsi[y] = rsi_dict[yahoo][2][-1]\n",
    "        y          += 1\n",
    "    \n",
    "    y = 0\n",
    "    for each in tickers:\n",
    "        day_low[y]  = last_close[y]\n",
    "        day_high[y] = last_close[y]\n",
    "        df          = closings[each][len(closings[each]) - 252 : len(closings[each])]\n",
    "        mylist[y]   = pd.DataFrame(df[0].values.tolist())\n",
    "        y          += 1  \n",
    "    return mylist\n",
    "\n",
    "def day_end_operations(tickers, combined, last_close):\n",
    "    cl       = open('smallcompanyclosingslist.pickle','rb')\n",
    "    fe       = open('smallcompanyfeatureslist.pickle','rb')\n",
    "    closings = pickle.load(cl)\n",
    "    stats    = pickle.load(fe)\n",
    "    cl.close()\n",
    "    fe.close()\n",
    "    \n",
    "    try:\n",
    "        i = 0\n",
    "        for each in tickers:\n",
    "\n",
    "            date           = datetime.date.today()\n",
    "\n",
    "            day_end_close  = last_close[i]\n",
    "            last_stats     = combined[i]\n",
    "\n",
    "            close_df       = pd.DataFrame([day_end_close], index=[date])\n",
    "            stats_df       = pd.DataFrame(last_stats, index=[date])\n",
    "\n",
    "            closings[each] = closings[each].append(close_df)  \n",
    "            stats[each]    = stats[each].append(stats_df)\n",
    "\n",
    "            i += 1  \n",
    "\n",
    "        cl2 = open('smallcompanyclosingslist.pickle','wb')\n",
    "        fe2 = open('smallcompanyfeatureslist.pickle','wb')\n",
    "        pickle.dump(closings,cl2)\n",
    "        pickle.dump(stats,fe2)\n",
    "        cl2.close()\n",
    "        fe2.close()\n",
    "    \n",
    "    except:\n",
    "            print each\n",
    "            raise \n",
    "            \n",
    "    return closings, stats\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def get_data_ready():\n",
    "    rs                = NYSE_tradingdays()\n",
    "    yesterday_trading = str(rs[0])[:10]\n",
    "    today_trading     = str(rs[1])[:10]\n",
    "    tomorrow_trading  = str(rs[2])[:10]\n",
    "    yesterday_file    = yesterday_trading+'dayendtickerlist.pickle'\n",
    "    \n",
    "    cl          = open('smallcompanyclosingslist.pickle','rb')\n",
    "    ye          = open(yesterday_file, 'rb')\n",
    "    yahoo       = open('historicalyahoodata.pickle', 'rb')\n",
    "    closings    = pickle.load(cl)\n",
    "    yesterday   = pickle.load(ye)\n",
    "    yahoo_data  = pickle.load(yahoo)\n",
    "    cl.close()\n",
    "    ye.close()\n",
    "    yahoo.close()\n",
    "    \n",
    "    # Ticker symbols for both yahoo and google servers\n",
    "    yahoo_tickers  = ['LGF', 'AMAG', 'CYH', 'HA', 'HPQ', 'ENDP', 'VRX', \n",
    "                      'SVU', 'FBR', 'IMGN', 'UIS', 'NSM', 'YRCW', 'BZH', \n",
    "                      'SWN', 'ATW', 'EXAS', 'TK', 'PBR', 'ITUB', 'LSCC', \n",
    "                      'MBI', 'SBS', 'AG', 'STLD', 'ATSG', 'HR', 'WTW', \n",
    "                      'GGAL', 'NJR', 'ITG', 'AEIS', 'NEM', 'ANF', 'INT', \n",
    "                      'COH', 'TREX', 'CSH', 'NTGR', 'BRKR', 'EDE', 'CCOI', \n",
    "                      'HRL', 'AEM', 'GVA', 'NVDA', 'CBT', 'CSGS',\n",
    "                      '%5EIXIC','%5EDJI','^RUT','^GSPC','^NYA',\n",
    "                      'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "    tickers        = ['LGF', 'AMAG', 'CYH', 'HA', 'HPQ', 'ENDP', 'VRX', \n",
    "                      'SVU', 'FBR', 'IMGN', 'UIS', 'NSM', 'YRCW', 'BZH', \n",
    "                      'SWN', 'ATW', 'EXAS', 'TK', 'PBR', 'ITUB', 'LSCC', \n",
    "                      'MBI', 'SBS', 'AG', 'STLD', 'ATSG', 'HR', 'WTW', \n",
    "                      'GGAL', 'NJR', 'ITG', 'AEIS', 'NEM', 'ANF', 'INT', \n",
    "                      'COH', 'TREX', 'CSH', 'NTGR', 'BRKR', 'EDE', 'CCOI', \n",
    "                      'HRL', 'AEM', 'GVA', 'NVDA', 'CBT', 'CSGS',\n",
    "                      'INDEXNASDAQ:.IXIC','INDEXDJX:.DJI','RUT','INDEXSP:.INX','INDEXNYSEGIS:NYA',\n",
    "                      'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "    \n",
    "    # Setup attribute dictionaries\n",
    "    highlowcloselist = highlowcloselist_create(yahoo_data, yahoo_tickers)\n",
    "    adx_dict         = adx_create(highlowcloselist, yahoo_tickers)\n",
    "    rsi_dict         = rsi_create(highlowcloselist, yahoo_tickers)\n",
    "    macd_dict        = macd_create(highlowcloselist, yahoo_tickers)\n",
    "    aroon_dict       = aroon_create(highlowcloselist, yahoo_tickers)\n",
    "    vol_dict         = volatility_create(highlowcloselist, yahoo_tickers)\n",
    "    cci_dict         = cci_create(highlowcloselist, yahoo_tickers)\n",
    "    kd_ratio_dict    = kd_ratio_create(highlowcloselist, yahoo_tickers)\n",
    "    attributes       = [highlowcloselist, adx_dict, rsi_dict, macd_dict, kd_ratio_dict]\n",
    "    \n",
    "    # Find companies with upcoming dividends\n",
    "    dividend_dates       = 'http://www.nasdaq.com/dividend-stocks/dividend-calendar.aspx'\n",
    "    today_next_dividends = pd.DataFrame(dividend_find(dividend_dates),   \n",
    "                                        columns=['Symbol','ExDiv','Div','RecDate','PayDate'])\n",
    "    divs                 = today_next_dividends['Symbol'].values\n",
    "    \n",
    "    # Find company with upcoming stock splits\n",
    "    stock_split_dates    = 'http://www.nasdaq.com/markets/upcoming-splits.aspx'\n",
    "    upcoming_splits      = pd.DataFrame(stock_splits(stock_split_dates), \n",
    "                                        columns=['Symbol','ExDate','Ratio','Payable'])   \n",
    "    splits               = upcoming_splits['Symbol'].values\n",
    "    \n",
    "    # Print out which companies have stock splits and dividends upcoming, if any\n",
    "    outlist = []\n",
    "    for each in divs:\n",
    "        if each in tickers:\n",
    "            print each, \"DIV\"\n",
    "    for each2 in splits:\n",
    "        if each2 in tickers:\n",
    "            print each2, \"SPLITS\"\n",
    "            outlist.append(each2)\n",
    "            \n",
    "    todays_news  = company_news(tickers)\n",
    "    new_codes    = pd.read_csv(\"C:/Users/JohnSmith2/Downloads/nasdaq.csv\",usecols=['Symbol'])\n",
    "    new_codes2   = pd.read_csv(\"C:/Users/JohnSmith2/Downloads/nyse.csv\",usecols=['Symbol'])\n",
    "    new_codes    = new_codes.append(new_codes2, ignore_index=True)\n",
    "    new_codes    = np.array(new_codes['Symbol'].values)\n",
    "    \n",
    "    news_file = today_trading+'daynews.pickle'\n",
    "    tn = open(news_file, 'wb')\n",
    "    pickle.dump(todays_news, tn)\n",
    "    tn.close()\n",
    "    \n",
    "    return tickers, new_codes, closings, outlist, yesterday, attributes#, todays_news\n",
    "\n",
    "def run_program():\n",
    "    rs               = NYSE_tradingdays()\n",
    "    tomorrow_trading = str(rs[2])[:10]\n",
    "    tomorrow         = str(datetime.date.today() + datetime.timedelta(days=1))\n",
    "\n",
    "    if tomorrow_trading == tomorrow:\n",
    "        while True:\n",
    "            now = datetime.datetime.now()\n",
    "            now_time = now.time()\n",
    "            if now_time >= datetime.time(9,27) and now_time <= datetime.time(9,28):\n",
    "                break\n",
    "\n",
    "        tickers, new_codes, closings, outlist, yesterday, attributes = get_data_ready()\n",
    "        tickerlist, dailylist, combined, daily, last_close = \\\n",
    "            real_time_quotes(tickers, new_codes, closings, outlist, yesterday, attributes)\n",
    "        print \"DONE\"\n",
    "    else:\n",
    "        \"NO TRADING DAY TOMORROW\"\n",
    "        return\n",
    "        \n",
    "    return tickerlist, dailylist, combined, daily, closings\n",
    "    \n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tickerlist, dailylist, combined, daily, closings = run_program()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yahoo             = open('historicalyahoodata.pickle', 'rb')\n",
    "yahoo_data        = pickle.load(yahoo)\n",
    "yahoo.close()\n",
    "yahoo_tickers  = ['LGF', 'AMAG', 'CYH', 'HA', 'HPQ', 'ENDP', 'VRX', \n",
    "                      'SVU', 'FBR', 'IMGN', 'UIS', 'NSM', 'YRCW', 'BZH', \n",
    "                      'SWN', 'ATW', 'EXAS', 'TK', 'PBR', 'ITUB', 'LSCC', \n",
    "                      'MBI', 'SBS', 'AG', 'STLD', 'ATSG', 'HR', 'WTW', \n",
    "                      'GGAL', 'NJR', 'ITG', 'AEIS', 'NEM', 'ANF', 'INT', \n",
    "                      'COH', 'TREX', 'CSH', 'NTGR', 'BRKR', 'EDE', 'CCOI', \n",
    "                      'HRL', 'AEM', 'GVA', 'NVDA', 'CBT', 'CSGS',\n",
    "                      '%5EIXIC','%5EDJI','^RUT','^GSPC','^NYA',\n",
    "                      'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "for each2 in yahoo_tickers:\n",
    "    test = Share(each2)\n",
    "    historical = test.get_historical('2016-06-01','2016-06-10')\n",
    "    historical.reverse()\n",
    "    for each3 in historical:\n",
    "        yahoo_data[each2].insert(0,each3)\n",
    "    yahoo_data[each2].reverse() \n",
    "print yahoo_data['LGF'][0]\n",
    "print \" \"\n",
    "print yahoo_data['LGF'][5]\n",
    "print \" \"\n",
    "print yahoo_data['LGF'][len(yahoo_data['LGF'])]\n",
    "print \" \"\n",
    "print \" \"\n",
    "print yahoo_data['XLI'][0]\n",
    "print \" \"\n",
    "print yahoo_data['XLI'][5]\n",
    "print \" \"\n",
    "print yahoo_data['XLI'][len(yahoo_data['XLI'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yahoo = open('historicalyahoodata.pickle', 'wb')\n",
    "pickle.dump(yahoo_data, yahoo)\n",
    "yahoo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rolling_mean(values, window):\n",
    "    return pd.rolling_mean(values, window=window)\n",
    "def get_rolling_std(values, window):\n",
    "    return pd.rolling_std(values, window=window)\n",
    "def get_bollinger_bands(rm, rstd):\n",
    "    upper_band = rm + rstd * 2\n",
    "    lower_band = rm - rstd * 2\n",
    "    return upper_band, lower_band\n",
    "def compute_daily_returns(df):\n",
    "    daily_returns = (df / df.shift(1)) - 1\n",
    "    daily_returns = daily_returns.replace([np.inf,-np.inf], 0)\n",
    "    return daily_returns\n",
    "tl         = open('smallcompanyclosingslist2.pickle','rb')\n",
    "yahoo      = open('historicalyahoodata.pickle', 'rb')\n",
    "new_closes = pickle.load(tl)\n",
    "yahoo_data = pickle.load(yahoo)\n",
    "tl.close()\n",
    "yahoo.close()\n",
    "tickers        = ['LGF', 'AMAG', 'CYH', 'HA', 'HPQ', 'ENDP', 'VRX', \n",
    "                      'SVU', 'FBR', 'IMGN', 'UIS', 'NSM', 'YRCW', 'BZH', \n",
    "                      'SWN', 'ATW', 'EXAS', 'TK', 'PBR', 'ITUB', 'LSCC', \n",
    "                      'MBI', 'SBS', 'AG', 'STLD', 'ATSG', 'HR', 'WTW', \n",
    "                      'GGAL', 'NJR', 'ITG', 'AEIS', 'NEM', 'ANF', 'INT', \n",
    "                      'COH', 'TREX', 'CSH', 'NTGR', 'BRKR', 'EDE', 'CCOI', \n",
    "                      'HRL', 'AEM', 'GVA', 'NVDA', 'CBT', 'CSGS',\n",
    "                      'INDEXNASDAQ:.IXIC','INDEXDJX:.DJI','RUT','INDEXSP:.INX','INDEXNYSEGIS:NYA',\n",
    "                      'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "yahoo_tickers  = ['LGF', 'AMAG', 'CYH', 'HA', 'HPQ', 'ENDP', 'VRX', \n",
    "                      'SVU', 'FBR', 'IMGN', 'UIS', 'NSM', 'YRCW', 'BZH', \n",
    "                      'SWN', 'ATW', 'EXAS', 'TK', 'PBR', 'ITUB', 'LSCC', \n",
    "                      'MBI', 'SBS', 'AG', 'STLD', 'ATSG', 'HR', 'WTW', \n",
    "                      'GGAL', 'NJR', 'ITG', 'AEIS', 'NEM', 'ANF', 'INT', \n",
    "                      'COH', 'TREX', 'CSH', 'NTGR', 'BRKR', 'EDE', 'CCOI', \n",
    "                      'HRL', 'AEM', 'GVA', 'NVDA', 'CBT', 'CSGS',\n",
    "                      '%5EIXIC','%5EDJI','^RUT','^GSPC','^NYA',\n",
    "                      'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "highlowcloselist = highlowcloselist_create(yahoo_data, yahoo_tickers)\n",
    "adx_dict         = adx_create(highlowcloselist, yahoo_tickers)\n",
    "rsi_dict         = rsi_create(highlowcloselist, yahoo_tickers)\n",
    "macd_dict        = macd_create(highlowcloselist, yahoo_tickers)\n",
    "aroon_dict       = aroon_create(highlowcloselist, yahoo_tickers)\n",
    "vol_dict         = volatility_create(highlowcloselist, yahoo_tickers)\n",
    "cci_dict         = cci_create(highlowcloselist, yahoo_tickers)\n",
    "kd_dict          = kd_ratio_create(highlowcloselist, yahoo_tickers)\n",
    "combined, indexes, x = {}, {}, 0\n",
    "for each, yahoo_each in zip(tickers,yahoo_tickers):\n",
    "    if x < 48:\n",
    "        value = new_closes[each].copy(deep=True)\n",
    "        daily = compute_daily_returns(value)\n",
    "        sma = get_rolling_mean(value, 50)\n",
    "        mom = (value / value.shift(10))- 1.\n",
    "        mom = mom.replace([np.inf,-np.inf], 0)\n",
    "        rm_company = get_rolling_mean(value, 20)\n",
    "        rstd_company = get_rolling_std(value, 20)\n",
    "        upper_band, lower_band = get_bollinger_bands(rm_company, rstd_company)\n",
    "        df = (value-rm_company)/(upper_band-rm_company)\n",
    "        df = df.replace([np.inf,-np.inf], 0)\n",
    "        pe = value / (value - value.shift(252))\n",
    "        pe = pe.replace([np.inf,-np.inf], 0)\n",
    "        adx   = adx_dict[yahoo_each]\n",
    "        rsi   = rsi_dict[yahoo_each]\n",
    "        macd  = macd_dict[yahoo_each]\n",
    "        aroon = aroon_dict[yahoo_each]\n",
    "        vol   = vol_dict[yahoo_each]\n",
    "        cci   = cci_dict[yahoo_each]\n",
    "        kd    = kd_dict[yahoo_each]\n",
    "        result = pd.concat([daily, sma, mom, df, pe, adx, rsi, macd, aroon, vol, cci, kd], axis=1, join='inner')\n",
    "        result.columns = ['DailyRet','SMA','Momentum','Bolling','PE/Ratio','ADX','RSI','MACD','Aroon','Volatil',\n",
    "                          'CCI','Stochast']\n",
    "        combined[each] = result\n",
    "    else:\n",
    "        value = new_closes[each].copy(deep=True)\n",
    "        indexes[each] = compute_daily_returns(value)\n",
    "    x += 1       \n",
    "extras = ['INDEXNASDAQ:.IXIC','INDEXDJX:.DJI','RUT','INDEXSP:.INX',\n",
    "          'INDEXNYSEGIS:NYA','XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "nas  = indexes[extras[0]]\n",
    "dow  = indexes[extras[1]]\n",
    "rus  = indexes[extras[2]]\n",
    "sp   = indexes[extras[3]]\n",
    "nyse = indexes[extras[4]]\n",
    "disc = indexes[extras[5]]\n",
    "stap = indexes[extras[6]]\n",
    "ener = indexes[extras[7]]\n",
    "fin  = indexes[extras[8]]\n",
    "heal = indexes[extras[9]]\n",
    "indu = indexes[extras[10]]\n",
    "tech = indexes[extras[11]]\n",
    "index = pd.concat([nas,dow,rus,sp,nyse,disc,stap,ener,fin,heal,indu,tech],axis=1,join='inner')\n",
    "index.columns = ['nasdDaily','DowDaily','RussDaily','SPDaily','NyseDaily','DiscrSpending',\n",
    "                 'Staples','Energy','Finance','Healthcare','Industry','Tech']\n",
    "finalDict = {}\n",
    "for key,value in combined.iteritems():\n",
    "    value = pd.concat([value,index],axis=1,join='inner')\n",
    "    finalDict[key] = value\n",
    "print len(finalDict)\n",
    "for key,value in finalDict.iteritems():\n",
    "    print key\n",
    "    print value[252:275]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fe2 = open('smallcompanyfeatureslist.pickle','wb')\n",
    "pickle.dump(finalDict,fe2)\n",
    "fe2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
