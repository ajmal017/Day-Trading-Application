{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from googlefinance import getQuotes, getNews\n",
    "from sys import stdout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import urllib\n",
    "import time\n",
    "import pickle\n",
    "import sched\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def get_attributes(value):\n",
    "    sma = pd.rolling_mean(value, 50)\n",
    "    rm = pd.rolling_mean(value, 20)\n",
    "    rstd = pd.rolling_std(value, 20)\n",
    "    upper_band = rm + rstd * 2\n",
    "    #lower_band = rm - rstd * 2\n",
    "    bol = (value.loc[252,0]-rm.loc[252,0])/(upper_band.loc[252,0]-rm.loc[252,0])\n",
    "    sma = sma.loc[252,0]\n",
    "    return bol, sma\n",
    "def get_normalized(value):\n",
    "    df_norm = (value - value.mean()) / (value.max() - value.min())\n",
    "    return df_norm\n",
    "def compute_daily_returns(value):\n",
    "    daily_returns = (value / value.shift(1)) - 1\n",
    "    daily_returns = daily_returns.replace([np.inf,-np.inf], 0)\n",
    "    return daily_returns\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def company_news(newstickers):\n",
    "    tickernewslist = {}\n",
    "    for each in newstickers:\n",
    "        news = getNews(each)\n",
    "        tickernewslist[each] = news   \n",
    "    return tickernewslist\n",
    "def stock_splits(stock_split_dates):\n",
    "    splitup = urllib.urlopen(stock_split_dates).read()\n",
    "    companies = splitup.find('Announced')\n",
    "    stop = splitup.find('th_No_BG',companies)\n",
    "    company_splits = []\n",
    "    while True:\n",
    "        done = splitup.find(')</a>',stop)+1\n",
    "        next_stop = splitup.rfind('(', stop, done)\n",
    "        ratio_s = splitup.find('<td>',done)+4\n",
    "        ratio_e = splitup.find('<',ratio_s)\n",
    "        payment_e = splitup.find('2016',done)+4\n",
    "        payment_s = splitup.rfind('<td>',stop,payment_e)+4\n",
    "        exdate_s = splitup.find('<td>',payment_e)+4\n",
    "        exdate_e = splitup.find('</td>',exdate_s)\n",
    "        company_splits.append([splitup[next_stop+1:done-1],\n",
    "                               splitup[exdate_s:exdate_e],\n",
    "                               splitup[ratio_s:ratio_e],\n",
    "                               splitup[payment_s:payment_e]])\n",
    "        tbody = splitup.find('</table>',done)\n",
    "        test = splitup.find('(',done)\n",
    "        if tbody < test:\n",
    "            break\n",
    "        stop = done\n",
    "    return company_splits\n",
    "def dividend_find(dividend_dates): \n",
    "    company_dividends = []\n",
    "    for x in xrange(0,2):\n",
    "        if x != 0:\n",
    "            dividends = urllib.urlopen(dividend_dates).read()  \n",
    "            end = dividends.find('Next')-2\n",
    "            start = dividends.rfind('href=',0,end)+6\n",
    "            next_day = dividends[start:end]\n",
    "            dividend_dates = 'http://www.nasdaq.com/dividend-stocks/'+next_day  \n",
    "        dividends = urllib.urlopen(dividend_dates).read()  \n",
    "        start = dividends.find('Payment Date')\n",
    "        while True:\n",
    "            start = dividends.find('&#40;',start)+5\n",
    "            end = dividends.find('&#41;',start)\n",
    "            ex_date_e = dividends.find('2016',end)+4\n",
    "            ex_date_s = dividends.rfind('>',end,ex_date_e)+1\n",
    "            div_e = dividends.find('</',ex_date_e+1)\n",
    "            div_s = dividends.rfind('>',ex_date_e,div_e)+1\n",
    "            rec_date_e = dividends.find('2016',div_e)+4\n",
    "            rec_date_s = dividends.rfind('>',div_e,rec_date_e)+1\n",
    "            proceed = dividends.find('2016',rec_date_e)+4\n",
    "            pay_date_e = dividends.find('2016',proceed)+4\n",
    "            pay_date_s = dividends.rfind('>',proceed,pay_date_e)+1\n",
    "            company_dividends.append([dividends[start:end],\n",
    "                                    dividends[ex_date_s:ex_date_e],\n",
    "                                    dividends[div_s:div_e],\n",
    "                                    dividends[rec_date_s:rec_date_e],\n",
    "                                    dividends[pay_date_s:pay_date_e]])\n",
    "            test = dividends.find('&#40;',start)\n",
    "            if test == -1:\n",
    "                break\n",
    "            start = end      \n",
    "    return company_dividends\n",
    "def yahoo_backup():\n",
    "    test_array = []\n",
    "    tickers = ['LGF', 'AMAG', 'CYH', 'HA', 'HPQ', 'ENDP', 'VRX', \n",
    "            'SVU', 'FBR', 'IMGN', 'UIS', 'NSM', 'YRCW', 'BZH', \n",
    "            'SWN', 'ATW', 'EXAS', 'TK', 'PBR', 'ITUB', 'LSCC', \n",
    "            'MBI', 'SBS', 'AG', 'STLD', 'ATSG', 'HR', 'WTW', \n",
    "            'GGAL', 'NJR', 'ITG', 'AEIS', 'NEM', 'ANF', 'INT', \n",
    "            'COH', 'TREX', 'CSH', 'NTGR', 'BRKR', 'EDE', 'CCOI', \n",
    "            'HRL', 'AEM', 'GVA', 'NVDA', 'CBT', 'CSGS',\n",
    "           '%5EIXIC','%5EDJI','^RUT','^GSPC','^NYA']\n",
    "    yahoo = 'http://finance.yahoo.com/q?s='\n",
    "    for each in tickers:\n",
    "        stock = yahoo + each\n",
    "        page = urllib.urlopen(stock).read()\n",
    "        price = page.find('time_rtq_ticker')\n",
    "        price_stop = page.find('</span>',price)\n",
    "        price_start = page.rfind('>',price_stop-10,price_stop)+1\n",
    "        test_array.append(page[price_start:price_stop])\n",
    "    return test_array\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def total_stock_movements(new_codes):\n",
    "    i,y = 0,0\n",
    "    new_new = []\n",
    "    for each in new_codes:\n",
    "        if ' ' not in each:\n",
    "            new_new.append(each)\n",
    "    for x in xrange(0,6365,95):\n",
    "        if x != 6270:\n",
    "            new_test = new_new[x:x+95]\n",
    "        else:\n",
    "            new_test = new_new[x:]\n",
    "        try:\n",
    "            test = getQuotes(new_test)\n",
    "        except:\n",
    "            return \"FAIL\"\n",
    "            pass\n",
    "        for each in test:\n",
    "            if each['ChangePercent'] != '':\n",
    "                if each['ChangePercent'][0] == '+':\n",
    "                    i += 1\n",
    "                if each['ChangePercent'][0] == '-':\n",
    "                    y += 1\n",
    "    movement = i - y\n",
    "    return movement\n",
    "def real_time_quotes(tickers, new_codes, closings):\n",
    "    start = True   \n",
    "    tickerlist = [[] for i in range(53)]\n",
    "    dailylist = [[] for i in range(53)]\n",
    "    first_close = [[] for i in range(53)]\n",
    "    last_close = [[] for i in range(53)]\n",
    "    new_array = []\n",
    "    market_movement = []\n",
    "    seconds, minutes, hours = 60, 60, 7\n",
    "    t_end = time.time() + seconds * minutes * hours\n",
    "    i,z = 0,True\n",
    "    while time.time() < t_end:\n",
    "        try:\n",
    "            next_quotes = getQuotes(tickers)          \n",
    "            for x in xrange(0,len(next_quotes)):\n",
    "                tickerlist[x].append(next_quotes[x])\n",
    "                if start == True:\n",
    "                    first_close[x] = float(next_quotes[x]['LastTradePrice'].replace(',',''))\n",
    "                    seconds_return = 0.0\n",
    "                else:\n",
    "                    last_close[x] = float(next_quotes[x]['LastTradePrice'].replace(',',''))\n",
    "                    seconds_return = last_close[x] / first_close[x] - 1.\n",
    "                    first_close[x] = last_close[x]        \n",
    "                dailylist[x].append(seconds_return)\n",
    "            if (i % 30) == 0 or i == 0:\n",
    "                movement = total_stock_movements(new_codes)\n",
    "                market_movement.append(movement)\n",
    "                start = False\n",
    "                stdout.write(\"\\r%d\" % i)\n",
    "                stdout.flush()\n",
    "                i += 1\n",
    "            else:\n",
    "                start = False\n",
    "                stdout.write(\"\\r%d\" % i)\n",
    "                stdout.flush()\n",
    "                i += 1\n",
    "                time.sleep(10)               \n",
    "            combined, z = calculate_attributes(closings, tickers, last_close, z)          \n",
    "        except:\n",
    "            next_quotes = yahoo_backup()\n",
    "            for x in xrange(0,len(next_quotes)):\n",
    "                tickerlist[x].append(next_quotes[x])\n",
    "                if i == 0:\n",
    "                    first_close[x] = float(next_quotes[x].replace(',',''))\n",
    "                    seconds_return = 0.0\n",
    "                else:\n",
    "                    last_close[x] = float(next_quotes[x].replace(',',''))\n",
    "                    seconds_return = last_close[x] / first_close[x] - 1.\n",
    "                    first_close[x] = last_close[x]\n",
    "                dailylist[x].append(seconds_return)\n",
    "            print \"PRIMARY FAIL\", i\n",
    "            i += 1\n",
    "            pass  \n",
    "    closings = day_end_operations(tickers,real_time,closings) \n",
    "    return tickerlist, dailylist, market_movement, closings\n",
    "def calculate_attributes(closings,tickers,last_close,market_movement,z):\n",
    "    if z == True:\n",
    "        mylist = make_year_list(closings,tickers)\n",
    "    else:\n",
    "        for x in xrange(0,49):\n",
    "            mylist[x].loc[252] = last_close[x]\n",
    "            boll,sma = get_attributes(mylist[x])\n",
    "            mom = (mylist[x].loc[252,0] /  mylist[x].loc[242,0])-1\n",
    "            pe  =  mylist[x].loc[252,0] / (mylist[x].loc[252,0] - mylist[x].loc[0,0])\n",
    "            combined = [boll,sma,mom,pe,market_movement[-1]]\n",
    "            for y in xrange(49,len(mylist)):\n",
    "                combined.append(last_close[y]/mylist[y][-1])\n",
    "            company_combined[x] = combined\n",
    "    z == False\n",
    "    return company_combined, z\n",
    "def make_year_list(closings,tickers):\n",
    "    z = 0\n",
    "    mylist = [[] for i in range(53)]\n",
    "    for each in tickers:\n",
    "        df = closings[each][len(closings[each])-251:len(closings[each])]\n",
    "        mylist[z] = df[0].values.tolist()\n",
    "        z += 1\n",
    "    return mylist\n",
    "def day_end_operations(tickers,real_time,closings):\n",
    "    i = 0\n",
    "    for each in tickers:\n",
    "        try:\n",
    "            num = float(real_time[i][-1]['LastTradePrice'].replace(',',''))\n",
    "            test = pd.DataFrame([num])\n",
    "            closings[each] = closings[each].append(test)\n",
    "        except:\n",
    "            print each\n",
    "            raise\n",
    "        i += 1     \n",
    "    cl2 = open('smallcompanyclosingslist.pickle','wb')\n",
    "    pickle.dump(closings,cl2)\n",
    "    cl2.close()\n",
    "    return closings\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITG DIV\n",
      "719"
     ]
    }
   ],
   "source": [
    "def get_data_ready():\n",
    "    tickers = ['LGF', 'AMAG', 'CYH', 'HA', 'HPQ', 'ENDP', 'VRX', \n",
    "                'SVU', 'FBR', 'IMGN', 'UIS', 'NSM', 'YRCW', 'BZH', \n",
    "                'SWN', 'ATW', 'EXAS', 'TK', 'PBR', 'ITUB', 'LSCC', \n",
    "                'MBI', 'SBS', 'AG', 'STLD', 'ATSG', 'HR', 'WTW', \n",
    "                'GGAL', 'NJR', 'ITG', 'AEIS', 'NEM', 'ANF', 'INT', \n",
    "                'COH', 'TREX', 'CSH', 'NTGR', 'BRKR', 'EDE', 'CCOI', \n",
    "                'HRL', 'AEM', 'GVA', 'NVDA', 'CBT', 'CSGS',\n",
    "                'INDEXNASDAQ:.IXIC','INDEXDJX:.DJI','RUT','INDEXSP:.INX','INDEXNYSEGIS:NYA']\n",
    "    stock_split_dates = 'http://www.nasdaq.com/markets/upcoming-splits.aspx'\n",
    "    dividend_dates = 'http://www.nasdaq.com/dividend-stocks/dividend-calendar.aspx'\n",
    "    cl = open('smallcompanyclosingslist.pickle','rb')\n",
    "    closings = pickle.load(cl)\n",
    "    cl.close()\n",
    "    today_next_dividends = pd.DataFrame(dividend_find(dividend_dates), columns=['Symbol','ExDiv','Div','RecDate','PayDate'])\n",
    "    upcoming_splits = pd.DataFrame(stock_splits(stock_split_dates), columns=['Symbol','ExDate','Ratio','Payable'])\n",
    "    divs = today_next_dividends['Symbol'].values\n",
    "    splits = upcoming_splits['Symbol'].values\n",
    "    for each in divs:\n",
    "        if each in tickers:\n",
    "            print each, \"DIV\"\n",
    "    for each2 in splits:\n",
    "        if each2 in tickers:\n",
    "            print each2, \"SPLITS\"\n",
    "    #todays_news = company_news(tickers)\n",
    "    new_codes = pd.read_csv(\"C:/Users/JohnSmith2/Downloads/nasdaq.csv\",usecols=['Symbol'])\n",
    "    new_codes2 = pd.read_csv(\"C:/Users/JohnSmith2/Downloads/nyse.csv\",usecols=['Symbol'])\n",
    "    new_codes = new_codes.append(new_codes2, ignore_index=True)\n",
    "    new_codes = np.array(new_codes['Symbol'].values)\n",
    "    #print len(todays_news.keys())\n",
    "    return tickers, new_codes\n",
    "scheduler = sched.scheduler(time.time, time.sleep)\n",
    "def execute_code():\n",
    "    tickers, new_codes = get_data_ready()\n",
    "    real_time, daily_list, market_movement, closings = real_time_quotes(tickers, new_codes, closings)\n",
    "    return real_time, daily_list, market_movement, closings\n",
    "def scheduler_reddit():\n",
    "    time.sleep(25200)\n",
    "    scheduler.enter(0, 1, execute_code, ())\n",
    "    real_time, daily_list, market_movement, closings = scheduler.run()\n",
    "    return real_time, daily_list, market_movement, closings    \n",
    "real_time, daily_list, market_movement, closings = scheduler_reddit()\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfd = open('combinedafter04featuredf.pickle','rb')\n",
    "dfd2 = open('historicallist.pickle','rb')\n",
    "feats = pickle.load(dfd)\n",
    "historicals = pickle.load(dfd2)\n",
    "dfd.close()\n",
    "dfd2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
