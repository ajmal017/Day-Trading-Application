{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from googlefinance import getQuotes, getNews\n",
    "from yahoo_finance import Share\n",
    "from dateutil import rrule  \n",
    "from sys import stdout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import urllib\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#### # Credit to https://gist.github.com/jckantor/d100a028027c5a6b8340 for these next two trading date functions\n",
    "def NYSE_holidays(a=datetime.date.today()-datetime.timedelta(days=1), b=datetime.date.today()+datetime.timedelta(days=365)): \n",
    "    # Generate ruleset for holiday observances on the NYSE \n",
    "    rs = rrule.rruleset()\n",
    "    # Include all potential holiday observances \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=12, bymonthday=31, byweekday=rrule.FR)) # New Years Day   \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 1, bymonthday= 1))                     # New Years Day   \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 1, bymonthday= 2, byweekday=rrule.MO)) # New Years Day     \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 1, byweekday= rrule.MO(3)))            # Martin Luther King Day    \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 2, byweekday= rrule.MO(3)))            # Washington's Birthday \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, byeaster= -2))                                  # Good Friday \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 5, byweekday= rrule.MO(-1)))           # Memorial Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 7, bymonthday= 3, byweekday=rrule.FR)) # Independence Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 7, bymonthday= 4))                     # Independence Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 7, bymonthday= 5, byweekday=rrule.MO)) # Independence Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 9, byweekday= rrule.MO(1)))            # Labor Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=11, byweekday= rrule.TH(4)))            # Thanksgiving Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=12, bymonthday=24, byweekday=rrule.FR)) # Christmas   \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=12, bymonthday=25))                     # Christmas   \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=12, bymonthday=26, byweekday=rrule.MO)) # Christmas  \n",
    "    # Exclude potential holidays that fall on weekends \n",
    "    rs.exrule(rrule.rrule(rrule.WEEKLY, dtstart=a, until=b, byweekday=(rrule.SA,rrule.SU))) \n",
    "    return rs \n",
    "def NYSE_tradingdays(a=datetime.date.today()-datetime.timedelta(days=1), b=datetime.date.today()+datetime.timedelta(days=365)): \n",
    "    # Generate ruleset for NYSE trading days \n",
    "    rs = rrule.rruleset() \n",
    "    rs.rrule(rrule.rrule(rrule.DAILY, dtstart=a, until=b)) \n",
    "    # Exclude weekends and holidays \n",
    "    rs.exrule(rrule.rrule(rrule.WEEKLY, dtstart=a, byweekday=(rrule.SA,rrule.SU))) \n",
    "    rs.exrule(NYSE_holidays(a,b)) \n",
    "    return rs \n",
    "#######################################\n",
    "\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def highlowcloselist_create(yahoo_data, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    Take a pickled data file that has trading info for each day in a list of dictionaries, one \n",
    "    dictionary per day and formed together to make a companies trading data for a certain period\n",
    "    of time. This function then takes that data, as well as a list of the company tickers, and creates\n",
    "    a single dictionary with 48 companies, 5 stock indexes, and 6 sector indexes and makes a list of \n",
    "    day's high, low, and closing prices, as well as the date, and the typical price, which is calculated.\n",
    "    It returns these 5 lists in a single list, which is then used by calling the company ticker key from \n",
    "    the dictionary.\n",
    "    \"\"\"\n",
    "    highlowcloselist = {}\n",
    "    # List through each company ticker symbol\n",
    "    for each in yahoo_tickers:\n",
    "        low, high, close = [], [], []\n",
    "        typical_price, date = [], []\n",
    "        \n",
    "        # List through each day of each companies data, appending to the list of the \n",
    "        # high, low, close, and date, as well as calculating the typical price.\n",
    "        for x in xrange(0,len(yahoo_data[each])):\n",
    "            high.append(float(yahoo_data[each][x]['High'].replace(',','')))\n",
    "            low.append(float(yahoo_data[each][x]['Low'].replace(',','')))\n",
    "            close.append(float(yahoo_data[each][x]['Adj_Close'].replace(',','')))\n",
    "            typical_price.append((float(yahoo_data[each][x]['High'].replace(',','')) + \n",
    "                                  float(yahoo_data[each][x]['Low'].replace(',','')) + \n",
    "                                  float(yahoo_data[each][x]['Adj_Close'].replace(',',''))) / 3.)\n",
    "            date.append(yahoo_data[each][x]['Date'])\n",
    "        \n",
    "        df = pd.DataFrame([high, low, close, typical_price, date])\n",
    "        df = df.set_index(4)\n",
    "        \n",
    "        # Set company ticker symbol as the key to the list holding all these lists\n",
    "        highlowcloselist[each] = df\n",
    "    return highlowcloselist\n",
    "\n",
    "def kd_ratio_create(highlowcloselist, yahoo_tickers):  \n",
    "    \"\"\"\n",
    "    Take the highlowcloselist dictionary that was created by the highlowcloselist_create function \n",
    "    and the yahoo ticker list, and create a dictionary that contains the stochastic oscillator \n",
    "    calculations that this function makes and it will eventually be used in the deep learning function\n",
    "    \"\"\"\n",
    "    kd_ratio_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        window, mean_window = 5, 3\n",
    "        \n",
    "        high  = highlowcloselist[each][0]\n",
    "        low   = highlowcloselist[each][1]\n",
    "        close = highlowcloselist[each][2]\n",
    "        \n",
    "        prev_max  = high.rolling(window = window, center = False).max()\n",
    "        prev_min  = low.rolling(window = window, center = False).min()\n",
    "        \n",
    "        cl  = close - prev_max\n",
    "        hl  = prev_max - prev_min\n",
    "        k   = ((cl / hl) * 100.).fillna(0)\n",
    "        k   = k.replace([np.inf,-np.inf], 0)\n",
    "        d   = (k.rolling(window = mean_window, center = False).mean()).fillna(0)\n",
    "        \n",
    "        kd_df    = k\n",
    "        kd_df[1] = d\n",
    "        \n",
    "        kd_ratio_dict[each] = kd_df\n",
    "    return kd_ratio_dict\n",
    "\n",
    "def cci_create(highlowclose, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    This function takes the highlowclose dictionary and yahoo ticker list and calculates the \n",
    "    commodity channel index for each company.\n",
    "    \"\"\"\n",
    "    cci_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        # These variable values are market standards but can be adjusted\n",
    "        constant, window, mean_window = 0.015, 14, 20\n",
    "        \n",
    "        typ            = highlowclose[each][3]\n",
    "        typ_mad        = typ.rolling(window = window, center = False).mad()\n",
    "        typ_mean       = typ.rolling(window = mean_window, center = False).mean()\n",
    "        \n",
    "        cci            = (typ - typ_mean) / (constant* typ_mad)\n",
    "        cci            = cci.replace([np.inf,-np.inf], 0)\n",
    "        \n",
    "        cci_dict[each] = cci\n",
    "    return cci_dict\n",
    "\n",
    "def volatility_create(highlowcloselist, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    Take the highlowclose dictionary and yahoo ticker list, and create a volatility index for each\n",
    "    company.\n",
    "    \"\"\"\n",
    "    vol_dict = {}\n",
    "    for each2 in yahoo_tickers:\n",
    "        close, window   = highlowcloselist[each2][2], 30\n",
    "        returns         = close / close.shift(1) - 1  \n",
    "        \n",
    "        vol_dict[each2] = returns.rolling(window = window, center=False).std() * np.sqrt(252) \n",
    "    return vol_dict\n",
    "\n",
    "def aroon_create(highlowcloselist, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    Calculate aroon index for each company, another indicator that will be used in \n",
    "    prediction process.\n",
    "    \"\"\"\n",
    "    aroon_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        aroon_index = []\n",
    "        \n",
    "        for y in xrange(0, len(highlowcloselist[each][0])):\n",
    "            # Window length is 25\n",
    "            if y > 23:\n",
    "                new_closing = highlowcloselist[each][2][y-24 : y+1]\n",
    "                aroon_up    = ((25. - (252. - new_closing[0].idxmax())) / 25.) * 100\n",
    "                aroon_down  = ((25. - (252. - new_closing[0].idxmin())) / 25.) * 100\n",
    "                \n",
    "                # Finally, subtract the upper from the lower calculation\n",
    "                aroon_index.append(aroon_up - aroon_down)\n",
    "            else:\n",
    "                aroon_index.append(0)\n",
    "              \n",
    "        aroon_dict[each] = pd.DataFrame(aroon_index)\n",
    "    return aroon_dict\n",
    "\n",
    "def macd_create(highlowcloselist, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    Calculate the Moving Average Converge Divergence index, an indicator used a lot in stock\n",
    "    market prediction.\n",
    "    \"\"\"\n",
    "    macd_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        # n and m represent the period lengths, can be changed if better results are capable\n",
    "        n, m, close = 12, 26, highlowcloselist[each][2]\n",
    "        \n",
    "        macd_df         = close / close.ewm(ignore_na=False, span=n, min_periods=0, adjust=True).mean() - 1\n",
    "        macd_df[1]      = close / close.ewm(ignore_na=False, span=m, min_periods=0, adjust=True).mean() - 1\n",
    "        macd_df[2]      = ema_12 - ema_26\n",
    "        \n",
    "        macd_dict[each] = macd_df\n",
    "    return macd_dict\n",
    "\n",
    "def rsi_create(highlowcloselist, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    Calculate the relative strength index used as another indicator for the prediction process.\n",
    "    \"\"\" \n",
    "    rsi_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        close, window  = highlowcloselist[each][2], 14\n",
    "        deltas         = (close - close.shift(1)).fillna(0)\n",
    "        \n",
    "        avg_gains  =  deltas[1:window+1][deltas > 0].sum() / window\n",
    "        avg_losses = -deltas[1:window+1][deltas < 0].sum() / window\n",
    "\n",
    "        # Set up pd.Series container for RSI values\n",
    "        rsi_series = pd.Series(0.0, deltas.index)\n",
    "\n",
    "        # Now calculate RSI using the Wilder smoothing method, starting with n+1 delta.\n",
    "        up   = lambda x:  x if x > 0 else 0\n",
    "        down = lambda x: -x if x < 0 else 0\n",
    "        \n",
    "        i = window + 1\n",
    "        for d in deltas[window+1:]:\n",
    "            avg_gains  = ((avg_gains  * (window - 1.)) + up(d))   / window\n",
    "            avg_losses = ((avg_losses * (window - 1.)) + down(d)) / window\n",
    "            \n",
    "            if avg_of_losses != 0:\n",
    "                rs = avg_gains / avg_losses\n",
    "                rsi_series[i] = 100. - (100. / (1. + rs))\n",
    "            else:\n",
    "                rsi_series[i] = 100.\n",
    "            i += 1\n",
    "        \n",
    "        rsi_list = [avg_gains, avg_losses, rsi_series]\n",
    "    return rsi_list\n",
    "\n",
    "def adx_create(highlowcloselist, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    Calculate the Average Directional Index for each company, an indicator used to help in the prediction\n",
    "    process.\n",
    "    \"\"\"\n",
    "    adx_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        # True range is the max value of one of three operations.\n",
    "        # plus_dm is the positive directional moving list, minus_dm the negative.\n",
    "        # tr14_list is the 14 day mean of the previous 14 days worth of true ranges\n",
    "        # dx14_list is the directional index 14 day mean\n",
    "        # adx14_list is the where the final average directional index calculations go. \n",
    "        high  = highlowcloselist[each][0]\n",
    "        low   = highlowcloselist[each][1]\n",
    "        close = highlowcloselist[each][2]\n",
    "        \n",
    "        plus_df  = (high - high.shift(1)).fillna(0)\n",
    "        minus_dm = (low.shift(1) - low).fillna(0)\n",
    "        plus_dm[plus_dm < 0]   = 0\n",
    "        minus_dm[minus_dm < 0] = 0\n",
    "        \n",
    "        tr_df     = (high - low)\n",
    "        tr_df[1]  = (high - close.shift(1)).fillna(0)\n",
    "        tr_df[2]  = (low - close.shift(1)).fillna(0)\n",
    "        tr_max_df = tr_df.max(axis=1)\n",
    "        \n",
    "        # Find the starting 14 day sums for true range, pos directional moving and negative\n",
    "        tr14           = sum(tr_max_df[0][1:window+1])\n",
    "        pos_dm14       = sum(plus_dm[0][1:window+1])\n",
    "        neg_dm14       = sum(minus_dm[0][1:window+1])\n",
    "        tr14_series    = pd.Series(0.0, tr_df.index)\n",
    "        posdm14_series = pd.Series(0.0, plus_dm.index)\n",
    "        negdm14_series = pd.Series(0.0, minus_dm.index)\n",
    "        dx14_series    = pd.Series(0.0, tr_df.index)\n",
    "        \n",
    "        i = window + 1\n",
    "        for y in xrange(window+1, len(tr_max_df)):\n",
    "            # Moving averages calculated\n",
    "            tr14      = tr14     - (tr14     / float(window)) + tr_max_df[0].ix[y]\n",
    "            pos_dm14  = pos_dm14 - (pos_dm14 / float(window)) + plus_dm[0].ix[y]\n",
    "            neg_dm14  = neg_dm14 - (neg_dm14 / float(window)) + minus_dm[0].ix[y]\n",
    "                \n",
    "            # Positive and negative 14 day directional indexes\n",
    "            pos_di14  = (pos_dm14 / tr14) * 100.\n",
    "            neg_di14  = (neg_dm14 / tr14) * 100.\n",
    "                \n",
    "            # Sum of pos and neg directional index can't be 0\n",
    "            if (pos_di14 + neg_di14) != 0:\n",
    "                dx14 = (pos_di14 - neg_di14) / (pos_di14 + neg_di14) \n",
    "            else:\n",
    "                dx14 = None    \n",
    "                    \n",
    "            tr14_series[i]    = tr14\n",
    "            dx14_series[i]    = dx14\n",
    "            posdm14_series[i] = pos_dm14\n",
    "            negdm14_series[i] = neg_dm14\n",
    "            i += 1\n",
    "        \n",
    "        # Starting adx calculated by summing the previous 14 days worth of dx14_list calcs\n",
    "        adx14      = sum(dx14_series[0][window+1:window+window+1])\n",
    "        adx_series = pd.Series(0.0, dx14_series.index)\n",
    "        \n",
    "        i = window + 1\n",
    "        for y in xrange(0, len(dx_df)):\n",
    "            # Calc adx\n",
    "            adx14         = ((adx14 * 13.) + dx14_series[0].ix[y]) / float(window)\n",
    "            adx_series[i] = adx14\n",
    "            i += 1\n",
    "\n",
    "        adx_df    = tr14_series\n",
    "        adx_df[2] = posdm14_series\n",
    "        adx_df[3] = negdm14_series\n",
    "        adx_df[4] = adx_series\n",
    "        \n",
    "        adx_dict[each] = adx_df\n",
    "    return adx_dict\n",
    "\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def company_news(newstickers):\n",
    "    \"\"\"\n",
    "    Use Google's server and use https://github.com/hongtaocai/googlefinance module to retrieve\n",
    "    the real-time stock news data for each company stock symbol fed to it.\n",
    "    \"\"\"\n",
    "    tickernewslist = {}\n",
    "    \n",
    "    for each in newstickers:\n",
    "        tickernewslist[each] = getNews(each)  \n",
    "    return tickernewslist\n",
    "\n",
    "def stock_splits(stock_split_dates):\n",
    "    \"\"\"\n",
    "    Read in the stock split site data to discover if any of our watched companies have \n",
    "    stock splits in the near future so the data can be adjusted for it. Return which \n",
    "    companies if any are discovered on it.\n",
    "    \"\"\"\n",
    "    splitup        = urllib.urlopen(stock_split_dates).read()\n",
    "    companies      = splitup.find('Announced')\n",
    "    stop           = splitup.find('th_No_BG', companies)\n",
    "    company_splits = []\n",
    "    \n",
    "    # Find which companies are listed along with the stock split ratio,\n",
    "    #  the ex-date, and the payment date.\n",
    "    while True:\n",
    "        done      = splitup.find(')</a>',stop)+1\n",
    "        next_stop = splitup.rfind('(', stop, done)\n",
    "        ratio_s   = splitup.find('<td>',done)+4\n",
    "        ratio_e   = splitup.find('<',ratio_s)\n",
    "        payment_e = splitup.find('2016',done)+4\n",
    "        payment_s = splitup.rfind('<td>',stop,payment_e)+4\n",
    "        exdate_s  = splitup.find('<td>',payment_e)+4\n",
    "        exdate_e  = splitup.find('</td>',exdate_s)\n",
    "        \n",
    "        company_splits.append([splitup[next_stop+1:done-1],\n",
    "                               splitup[exdate_s:exdate_e],\n",
    "                               splitup[ratio_s:ratio_e],\n",
    "                               splitup[payment_s:payment_e]])\n",
    "        \n",
    "        tbody = splitup.find('</table>',done)\n",
    "        test  = splitup.find('(',done)\n",
    "        \n",
    "        if tbody < test:\n",
    "            break\n",
    "        stop = done\n",
    "    return company_splits\n",
    "\n",
    "def dividend_find(dividend_dates): \n",
    "    \"\"\"\n",
    "    Like the stock_splits() function, searches a site to find if any of our companies have\n",
    "    an upcoming dividend so as to adjust for it. Return a list of companies, if any.\n",
    "    \"\"\"\n",
    "    company_dividends = []\n",
    "    for x in xrange(0,2):\n",
    "        if x != 0:\n",
    "            dividends      = urllib.urlopen(dividend_dates).read()  \n",
    "            end            = dividends.find('Next')-2\n",
    "            start          = dividends.rfind('href=',0,end)+6\n",
    "            next_day       = dividends[start:end]\n",
    "            dividend_dates = 'http://www.nasdaq.com/dividend-stocks/'+next_day \n",
    "            \n",
    "        dividends = urllib.urlopen(dividend_dates).read()  \n",
    "        start     = dividends.find('Payment Date')\n",
    "        \n",
    "        while True:\n",
    "            start      = dividends.find('&#40;',start)+5\n",
    "            end        = dividends.find('&#41;',start)\n",
    "            ex_date_e  = dividends.find('2016',end)+4\n",
    "            ex_date_s  = dividends.rfind('>',end,ex_date_e)+1\n",
    "            div_e      = dividends.find('</',ex_date_e+1)\n",
    "            div_s      = dividends.rfind('>',ex_date_e,div_e)+1\n",
    "            rec_date_e = dividends.find('2016',div_e)+4\n",
    "            rec_date_s = dividends.rfind('>',div_e,rec_date_e)+1\n",
    "            proceed    = dividends.find('2016',rec_date_e)+4\n",
    "            pay_date_e = dividends.find('2016',proceed)+4\n",
    "            pay_date_s = dividends.rfind('>',proceed,pay_date_e)+1\n",
    "            \n",
    "            company_dividends.append([dividends[start:end],\n",
    "                                    dividends[ex_date_s:ex_date_e],\n",
    "                                    dividends[div_s:div_e],\n",
    "                                    dividends[rec_date_s:rec_date_e],\n",
    "                                    dividends[pay_date_s:pay_date_e]])\n",
    "            \n",
    "            test = dividends.find('&#40;',start)\n",
    "            if test == -1:\n",
    "                break\n",
    "            start = end      \n",
    "    return company_dividends\n",
    "\n",
    "def yahoo_backup():\n",
    "    \"\"\"\n",
    "    Due to Google occasionally blocking our google server api, a yahoo backup is \n",
    "    set up to retrieve stock info from google finance's page. It is far slower so\n",
    "    it's to be avoided if at all possible. Increasing latency between each call can\n",
    "    help Google from your blocking.\n",
    "    \"\"\"\n",
    "    test_array = []\n",
    "    yahoo      = 'http://finance.yahoo.com/q?s='\n",
    "    tickers    = yahoo_tickers  = ['BPOP','FITB','HBAN','CMCSA','EBAY','NWSA',\n",
    "                      'AAPL','AMAT','BRCD','CSCO','DELL','GOOG','INTC',\n",
    "                      'LVLT','MSFT','MU','NVDA','ORCL','QCOM','RIMM',\n",
    "                      'SIRI','SNDK','WIN','YHOO','BHP','BP',\n",
    "                      'RIO','XOM','GE','F','MO','XRX','GS','HBC','JPM',\n",
    "                      'LYG','MS','RF','UBS','USB','WFC','MRK','PFE','LMT',\n",
    "                      'MGM','AMD','EMC','GLW','HPQ','S','T',\n",
    "                      'UNG', 'USO', 'GLD', 'SPY',\n",
    "                      '%5EDJI', '^GSPC', '%5EIXIC', \n",
    "                      'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "    \n",
    "    # Retrieve the stock price for each company\n",
    "    for each in tickers:\n",
    "        stock       = yahoo + each\n",
    "        page        = urllib.urlopen(stock).read()\n",
    "        price       = page.find('time_rtq_ticker')\n",
    "        price_stop  = page.find('</span>',price)\n",
    "        price_start = page.rfind('>',price_stop-10,price_stop)+1\n",
    "        \n",
    "        test_array.append(page[price_start:price_stop])\n",
    "    return test_array\n",
    "\n",
    "def get_prev_10d1min_intraday():\n",
    "    \"\"\"\n",
    "    Added to retrieve the previous 10 days worth of intraday trading data with 5 minute\n",
    "    intervals.\n",
    "    \"\"\"\n",
    "    tickers          = ['LGF', 'AMAG', 'CYH', 'HA', 'HPQ', 'ENDP', 'VRX', \n",
    "                          'SVU', 'FBR', 'IMGN', 'UIS', 'NSM', 'YRCW', 'BZH', \n",
    "                          'SWN', 'ATW', 'EXAS', 'TK', 'PBR', 'ITUB', 'LSCC', \n",
    "                          'MBI', 'SBS', 'AG', 'STLD', 'ATSG', 'HR', 'WTW', \n",
    "                          'GGAL', 'NJR', 'ITG', 'AEIS', 'NEM', 'ANF', 'INT', \n",
    "                          'COH', 'TREX', 'CSH', 'NTGR', 'BRKR', 'EDE', 'CCOI', \n",
    "                          'HRL', 'AEM', 'GVA', 'NVDA', 'CBT', 'CSGS',\n",
    "                      'IXIC','.DJI','RUT','.INX','NYA',\n",
    "                       'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "    pages = {}\n",
    "    for each in tickers:\n",
    "        page = 'http://www.google.com/finance/getprices?i=60&p=10d&f=d,c&df=cpct&q='+each\n",
    "        pages[each] = urllib.urlopen(page).read()\n",
    "    complete_list = []\n",
    "    day_list = []\n",
    "    \n",
    "    for each in tickers:\n",
    "        current = pages[each]\n",
    "        start = current.find('\\na')+2\n",
    "        end = len(current)\n",
    "        test = True\n",
    "        df_list = []\n",
    "        \n",
    "        while test == True:\n",
    "            date = current.find(',',start)\n",
    "            price = current.find('\\n',date)\n",
    "            df_list.append(float(current[date+1:price]))\n",
    "\n",
    "            if price != end-1:\n",
    "                if current[price+1] == 'a':\n",
    "                    day_list.append(df_list)\n",
    "                    df_list = []\n",
    "                start = price+2    \n",
    "            else:\n",
    "                test = False\n",
    "                complete_list.append(day_list)\n",
    "                day_list = []        \n",
    "    return complete_list\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def real_time_quotes(tickers, closings, outlist, yesterday, attributes):\n",
    "    \"\"\"\n",
    "    As the function name implies, it retrieves stock data in real time. It will be started at\n",
    "    the beginning of the trading day(9:30AM Eastern) and ends at the end of the trading day\n",
    "    (4:00PM Eastern). It retrieves the data from Google's server by calling getQuotes which uses\n",
    "    the same program used to retrieve stock news. Credit goes to https://github.com/hongtaocai/googlefinance\n",
    "    for creating the program to retrieve the data.\n",
    "    \n",
    "    Once the data is retrieved, it's returned in a list of dictionaries, one for each company. We'll\n",
    "    take this info, convert the price to a float from a string. Then that data is taken and used to create\n",
    "    our indicators in real time. Half are calculated in the function calculate_attributes() which is \n",
    "    called here, the other half is called from that function and calls calculate_extra_attributes().\n",
    "    \n",
    "    The daily list will make a daily return using the prior trading day's data at that specific interval to\n",
    "    make an accurate daily return.\n",
    "    \n",
    "    If the Google server blocks our retrieval process, we call our yahoo_backup() function which retrieves\n",
    "    the data straight from the yahoo finance's website. This is considerably slower so it's always better to\n",
    "    increase the sleep time between each retrieval to slow down how often we're retrieving data as this has\n",
    "    proved to be effective in combatting being blocked in the first place.\n",
    "    \n",
    "    Returns 5 dictionaries: \n",
    "        -tickerlist = Just the a list of dictionaries for each day for the whole trading day for each company.\n",
    "                      Each company can be called with its stock ticker symbol and that retrieves the list of \n",
    "                      dictionaries.\n",
    "        -dailylist  = The differences in price between each call for each call for each company as a list for\n",
    "                      each company that can be called by its stock ticker symbol\n",
    "        -combined   = Lists the latest indicator list. There are 24 indicators ranging from bollinger bands, \n",
    "                      to PE/Ratios, to Volatilities, etc.. as well as daily returns from the top 5 major indexes\n",
    "                      including the S&P, NYSE, etc. Also the daily returns for the top 7 major sectors, such as\n",
    "                      technology, healthcare, etc.\n",
    "        -daily      = Daily return value for each company, using the previous day's intraday trading data. Takes \n",
    "                      the price at the same interval the previous trading day to get an accurate daily return \n",
    "                      rather than using the prior day's closing price as that doesn't take into account the intra-\n",
    "                      day trading.\n",
    "        -last_close = The most current closing price for each company, this will be used to update the day-end \n",
    "                      closing price that's placed in the closing price dictionary. This closing price dictionary\n",
    "                      is a pickled file to increase speed and has the closing prices of the stocks since going\n",
    "                      public.\n",
    "    \"\"\"\n",
    "    tickerlist     = [[] for i in range(65)]\n",
    "    dailylist      = [[] for i in range(65)]\n",
    "    first_close    = [[] for i in range(65)]\n",
    "    last_close     = [[] for i in range(65)]\n",
    "    mylist         = [[] for i in range(65)]\n",
    "    daily          = [[] for i in range(65)]\n",
    "\n",
    "    start, new_array = True, []\n",
    "    # Use the python time module to time how long to retrieve stock data for. A normal\n",
    "    #  trading day means 6.5 hours of trading data.\n",
    "    seconds, minutes, hours, i, z  = 60, 60, 6.5, 0, True\n",
    "    \n",
    "    t_end = time.time() + seconds * minutes * hours\n",
    "    while time.time() < t_end:\n",
    "        try:\n",
    "            # Try to retrieve the quotes from the Google server, if it doesn't work,\n",
    "            #  print that we have a quotes error and continue which will cause it to \n",
    "            #  call the yahoo_backup() function to retrieve the data from yahoo finances\n",
    "            #  website instead of the google server for that call. Try to increase the \n",
    "            #  time.sleep() time if being blocked often as it can reduce the chance of an\n",
    "            #  error.\n",
    "            try:\n",
    "                next_quotes = getQuotes(new_tickers)  \n",
    "            except:\n",
    "                print \"QUOTES ERROR\"\n",
    "                pass\n",
    "                \n",
    "            # Append each companies interval data to the list entry list\n",
    "            for x in xrange(0,len(next_quotes)):\n",
    "                tickerlist[x].append(next_quotes[x])\n",
    "                \n",
    "                # If this is the start of the day, set the price to first_close for each\n",
    "                #  company so after the next loop, you can retrieve the seconds_return which\n",
    "                #  is the price difference between calls that will be appended to the dailylist\n",
    "                #  for each company.\n",
    "                if start == True:\n",
    "                    first_close[x] = float(next_quotes[x]['LastTradePrice'].replace(',',''))\n",
    "                    seconds_return = 0.0\n",
    "                else:\n",
    "                    last_close[x]  = float(next_quotes[x]['LastTradePrice'].replace(',',''))\n",
    "                    seconds_return = last_close[x] / first_close[x] - 1.\n",
    "                    first_close[x] = last_close[x] \n",
    "                    \n",
    "                dailylist[x].append(seconds_return)\n",
    "                \n",
    "            # Print what loop number we are on, then sleep for 10 seconds before continuing\n",
    "            #  so Google server is unlikely to block our retrieval attemps as a bot.\n",
    "            stdout.write(\"\\r%d\" % i)\n",
    "            stdout.flush()\n",
    "            time.sleep(59)\n",
    "            \n",
    "            # If we are past the first loop, call the attributes function which calculates our\n",
    "            #  list of 24 indicators in real time which will be used to feed to the real-time\n",
    "            #  recurrent neural network for prediction purposes. Z is used simply to tell if it's\n",
    "            #  our first call to calculate_attributes as it sets mylist the first time as well as \n",
    "            #  some global variables needed to set up the process. Z set to false after the first \n",
    "            #  call and stays false the rest of the day. mylist is a list with the day's previous\n",
    "            #  252 trading day's(1 year of trading data) closing prices as it's needed to calculate\n",
    "            #  many of the indicators such as simple moving average, and bollinger bands.\n",
    "            if i > 0:\n",
    "                combined, z, mylist = calculate_attributes(closings, tickers, last_close, \n",
    "                                                            mylist, z, attributes)  \n",
    "                \n",
    "                # Find the daily return using the previous day's interval price using a pickled file\n",
    "                #  with the previous day's data. If we end up with a few more intervals in a day for\n",
    "                #  one reason or another, only use up to the number of the list with the fewest to \n",
    "                #  avoid any issues.\n",
    "                #for u in xrange(0,len(tickerlist)):\n",
    "                #    if len(tickerlist[u]) <= len(yesterday[u]):\n",
    "                #        daily[u].append((float(tickerlist[u][i]['LastTradePrice'].replace(',','')) / \n",
    "                #                         float(yesterday[u][i]['LastTradePrice'].replace(',',''))) - 1)\n",
    "                #    else:\n",
    "                #        break\n",
    "            \n",
    "            i     += 1\n",
    "            start  = False \n",
    "        \n",
    "        except:\n",
    "            # If Google's server denies our retrieval, call yahoo_backup()\n",
    "            next_quotes = yahoo_backup()\n",
    "            #for x in xrange(0,len(next_quotes)):\n",
    "            #    tickerlist[x].append(next_quotes[x])\n",
    "                \n",
    "            #    if i == 0:\n",
    "            #        first_close[x] = float(next_quotes[x].replace(',',''))\n",
    "            #        seconds_return = 0.0\n",
    "            #    else:\n",
    "            #        last_close[x]  = float(next_quotes[x].replace(',',''))\n",
    "            #        seconds_return = last_close[x] / first_close[x] - 1.\n",
    "            #        first_close[x] = last_close[x]\n",
    "                    \n",
    "            #    dailylist[x].append(seconds_return)\n",
    "                \n",
    "            print \"PRIMARY FAIL\", i\n",
    "            i += 1\n",
    "            pass\n",
    "\n",
    "    return tickerlist, dailylist, combined, last_close\n",
    "\n",
    "def calculate_attributes(closings, tickers, last_close, mylist, z, attributes):\n",
    "    \"\"\"\n",
    "    Used to calculate the indicators needed for the prediction process, first third of the \n",
    "    indicators are calculated within this function while the second third is calculated\n",
    "    in our calculate_extra_attributes() function which is called from here and returned as\n",
    "    a list of extra indicators. \n",
    "    \n",
    "    These indicators are placed together in a list and finally the last third are calculated\n",
    "    as the daily returns for the 5 major stock indexes(S&P, NYSE, Nasdaq, Russel2000, DowJones),\n",
    "    as well as the 7 major sectors(Technology, Industrial, Discretionary Spending, Consumer Staples,\n",
    "    Energy, Financial, and Health Care). All of these indicators are combined in one list. This list\n",
    "    is then passed to our real time function. This function is called every time step, so each time \n",
    "    step will calculate it's indicators and this will eventually be used for our recurrent network\n",
    "    that will use online learning to process the indicators and predict stock prices for us.\n",
    "    \n",
    "    Indicators calculated:\n",
    "        -vol   = Volatility Index:\n",
    "                    -Degree of variation of a trading price series over time as measured by the \n",
    "                     standard deviation of returns.\n",
    "                     \n",
    "        -aroon = Aroon Index:\n",
    "                    -Determines whether a stock is trending or not and how strong the trend is.\n",
    "                    \n",
    "        -macd  = Moving Average Convergence Divergence:\n",
    "                    -Trend following momentum indicator that shows the relationship between \n",
    "                     two moving averages of prices.\n",
    "                     \n",
    "        -cci   = Commodity Channel Index:\n",
    "                    -Identifying cyclical trends not only in commodities, but also equities \n",
    "                     and currencies.\n",
    "                     \n",
    "        -adx   = Average Directional Index:\n",
    "                    -Measures trend strength without regard to trend direction.\n",
    "                    \n",
    "        -kd    = Stochastic Oscillator Index:\n",
    "                    -Momentum indicator that uses support and resistance levels.\n",
    "                    \n",
    "        -rsi   = Relative Strength Index:\n",
    "                    -Chart the current and historical strength or weakness of a stock or market \n",
    "                     based on the closing prices of a recent trading period.\n",
    "                     \n",
    "        -boll  = Bollinger Bands:\n",
    "                    -Measure the \"highness\" or \"lowness\" of the price relative to previous trades.\n",
    "                    \n",
    "        -sma   = Simple Moving Average:\n",
    "                    -Average stock price over a certain period of time.\n",
    "                    \n",
    "        -mom   = Momentum:\n",
    "                    -Rate of acceleration of a security's price or volume.\n",
    "                    \n",
    "        -pe    = Price/Earnings Ratio:\n",
    "                    -Ratio for valuing a company that measures its current share price relative to \n",
    "                     its per-share earnings.\n",
    "        \n",
    "        -Intra-Day Daily Returns For: (Return generated by a stock during regular trading hours, based \n",
    "                                       on its price change from the opening of a trading day to its close)\n",
    "            -S&P 500 Exchange\n",
    "            -New York Stock Exchange\n",
    "            -Nasdaq Exchange\n",
    "            -Russel 2000 Exchange\n",
    "            -Dow Jones Exchange\n",
    "            -Technology Sector\n",
    "            -Discretionary Spending Sector\n",
    "            -Consumer Staples Sector\n",
    "            -Energy Sector\n",
    "            -Financial Sector\n",
    "            -Health Care Sector\n",
    "    \"\"\"\n",
    "    company_combined = [[] for i in range(65)]\n",
    "    # The attributes are a list of lists for each company that contained the previous indicator\n",
    "    #  data for historical stock prices and this data is used in conjunction with the new data\n",
    "    #  to form the new real-time indicators.\n",
    "    highlowcloselist = attributes[0] \n",
    "    adx_dict         = attributes[1]\n",
    "    rsi_dict         = attributes[2]\n",
    "    macd_dict        = attributes[3]\n",
    "    kd_dict          = attributes[4]\n",
    "    \n",
    "    # If this is the first time being called, setup the variable that will be used to hold the\n",
    "    #  previous year's worth of closing prices for each company as historical data is needed in\n",
    "    #  conjunction with our new data to calculate the current indicator values.\n",
    "    if z == True:\n",
    "        mylist = make_year_list(closings,mylist,last_close,rsi_dict,tickers)\n",
    "    \n",
    "    # First 48 stock tickers represent the companies, while the remaining 12 represent the indexes\n",
    "    #  and sectors. We only calculate the indicators for the companies, not the indexes and sectors.\n",
    "    for x, name in zip(xrange(0,51), tickers[:51]):\n",
    "        latest = last_close[x]\n",
    "        \n",
    "        # If the latest stock price is a day low or day high, set that price as the day low or high.\n",
    "        if (latest < day_low[x]) or (latest > day_high[x]):\n",
    "            if latest < day_low[x]:\n",
    "                day_low[x] = latest\n",
    "            else:\n",
    "                day_high[x] = latest\n",
    "        \n",
    "        # Set the current stock price as the latest day in our year's worth of closing prices.\n",
    "        #  Then calculate several indicators.\n",
    "        mylist[x].loc[252] = last_close[x]\n",
    "        sma                = mylist[x][203:253].rolling(window=50,center=False).mean()\n",
    "        rm                 = mylist[x][233:253].rolling(window=20,center=False).mean()\n",
    "        rstd               = mylist[x][233:253].rolling(window=20,center=False).std()\n",
    "        upper_band         = rm + rstd * 2\n",
    "        lower_band         = rm - rstd * 2\n",
    "        \n",
    "        # The second third of the indicators is calculated in the called function and \n",
    "        #  returned as 7 different lists and this is called for each company\n",
    "        volat, aroon, macd, cci, adx, kd, rsi = calculate_extra_attributes(\n",
    "                                                        mylist, highlowcloselist,\n",
    "                                                        adx_dict, rsi_dict, macd_dict,\n",
    "                                                        kd_dict, x, name)\n",
    "        \n",
    "        # The first 2/3 of the attributes are combined in the combined list and then the remaining\n",
    "        #  indicators are appended to that list.\n",
    "        boll       = (mylist[x].loc[252,0] - rm.loc[252,0]) / (upper_band.loc[252,0] - rm.loc[252,0])\n",
    "        sma        =  sma.loc[252,0]\n",
    "        mom        = (mylist[x].loc[252,0] /  mylist[x].loc[242,0])-1\n",
    "        pe         =  mylist[x].loc[252,0] / (mylist[x].loc[252,0] - mylist[x].loc[0,0])\n",
    "        combined   = [boll, sma, mom, pe, rsi, cci, macd, aroon, volat, adx, kd]\n",
    "        \n",
    "        # Calculate the daily return values for each index and sector and append to the indicator list\n",
    "        for y in xrange(48,len(mylist)):\n",
    "            combined.append(last_close[y] / mylist[y].loc[251,0]-1)   \n",
    "        company_combined[x] = combined\n",
    "    \n",
    "    # Set z to false to indicate that this function has now been called at least once so mylist is\n",
    "    #  already setup. Return the indicator list, z as false, and mylist which is the previous year's\n",
    "    #  closing prices.\n",
    "    z = False\n",
    "    return company_combined, z, mylist\n",
    "\n",
    "def calculate_extra_attributes(mylist, highlowcloselist, adx_dict, rsi_dict, macd_dict, kd_dict, x, name):\n",
    "    \"\"\"\n",
    "    Part two of the indicators, calculates volatility, aroon index, moving average convergence divergence, \n",
    "    commodity channel index, average directional index, stochastic oscillator ratio, and relative strength\n",
    "    index. \n",
    "    \n",
    "    This function will first setup several variables that are used for the calculations. The period lengths\n",
    "    are setup as the indicator standards but they can be adjusted for optimal performance.\n",
    "    \n",
    "    Returns the 7 indicator variables.\n",
    "    \"\"\"\n",
    "    # Setup variables\n",
    "    # Length of each companies mylist length as well as the length of the\n",
    "    #  list of high prices for the stock over the course of its existence\n",
    "    length             = len(mylist[x])\n",
    "    len_high           = len(highlowcloselist[name])\n",
    "    # Period lengths for each indicator. Can adjust for optimal performance.\n",
    "    aroon_period       = 25\n",
    "    voli_period        = 10\n",
    "    macd_small_period  = 12\n",
    "    macd_large_period  = 26\n",
    "    cci_period         = 20\n",
    "    rsi_period         = 14\n",
    "    adx_period         = 14\n",
    "    kd_period          = 5\n",
    "    # Constant variable for the cci calculation\n",
    "    constant           = 0.015\n",
    "    # Set the dataframes to the latest period worth of closing prices\n",
    "    aroon_closing      = mylist[x][length - aroon_period      : length]\n",
    "    voli_closing       = mylist[x][length - voli_period+1     : length]\n",
    "    macd_12_df         = mylist[x][length - macd_small_period : length]\n",
    "    macd_26_df         = mylist[x][length - macd_large_period : length]\n",
    "    # Same as above but for latest period worth of typical prices, day lows, and highs\n",
    "    #  less one which will be calculated and tacked onto these lists for the current value\n",
    "    typical            = highlowcloselist[name][3][len_high - (cci_period - 1) : len_high]\n",
    "    high_5             = highlowcloselist[name][0][len_high - (kd_period - 1)  : len_high]\n",
    "    low_5              = highlowcloselist[name][1][len_high - (kd_period - 1)  : len_high]\n",
    "    # These multipliers are used to calculate the EMA(Expected Moving Average) which\n",
    "    #  is part of the calculation of the indicators.\n",
    "    macd_12_multiplier = (2. / (macd_small_period + 1.))\n",
    "    macd_26_multiplier = (2. / (macd_large_period + 1.))\n",
    "    # Append our global variables day_low and day_high which contain our current day\n",
    "    #  highs and lows and append it the the lists to make the previous 5 days worth of data\n",
    "    low_5.append(day_low[x])\n",
    "    high_5.append(day_high[x])\n",
    "    \n",
    "\n",
    "    # Macd: Take the latest closing price, subtract by the previous, then multiply by the\n",
    "    #       multiplier, and finally add the previous. Finally subtract from one another to\n",
    "    #       get the final macd number.\n",
    "    first_12_ema = macd_dict[name][0].ix[len(macd_dict[name])-1]\n",
    "    first_26_ema = macd_dict[name][1].ix[len(macd_dict[name])-1]\n",
    "    macd_12_ema  = (macd_12_df.loc[252,0] - first_12_ema) * macd_12_multiplier + first_12_ema\n",
    "    macd_26_ema  = (macd_26_df.loc[252,0] - first_26_ema) * macd_26_multiplier + first_26_ema\n",
    "    macd         = macd_12_ema - macd_26_ema\n",
    "    \n",
    "    # Aroon: \n",
    "    aroon_up    = ((float(aroon_period) - (float(length) - aroon_closing[0].idxmax())) / float(aroon_period)) * 100.\n",
    "    aroon_down  = ((float(aroon_period) - (float(length) - aroon_closing[0].idxmin())) / float(aroon_period)) * 100.\n",
    "    aroon_index = aroon_up - aroon_down\n",
    "    \n",
    "    # Volatility: \n",
    "    returns    = voli_closing / voli_closing.shift(1) - 1 \n",
    "    volatility = returns[1:].std() * np.sqrt(voli_period) \n",
    "    \n",
    "    # CCI: Over +100 reflect strong price action and can signal uptrend, under -100 is opposite. \n",
    "    new_typical_price = (day_low[x] + day_high[x] + mylist[x].loc[252,0]) / 3.\n",
    "    typical           = typical.append(new_typical_price)\n",
    "    typical_mad       = typical.mad()\n",
    "    typical_mean      = typical.mean()\n",
    "    cci               = (new_typical_price - typical_mean) / (constant * typical_mad)\n",
    "    \n",
    "    # RSI: 0-100, overbought over 70, undersold below 30.\n",
    "    if mylist[x].loc[252,0] != mylist[x].loc[251,0]:\n",
    "        last_difference = mylist[x].loc[252,0] - mylist[x].loc[251,0]\n",
    "        \n",
    "        if last_difference >= 0:\n",
    "            up   = last_difference \n",
    "            down = 0.0\n",
    "        else:\n",
    "            up   = 0.0 \n",
    "            down = abs(last_difference) \n",
    "            \n",
    "        avg_gains  = ((rsi_dict[each][0] * (rsi_period - 1.)) + up)   / float(rsi_period)\n",
    "        avg_losses = ((rsi_dict[each][1] * (rsi_period - 1.)) + down) / float(rsi_period)\n",
    "            \n",
    "        if avg_of_losses != 0:\n",
    "            rs = avg_gains / avg_losses\n",
    "            rsi = 100. - (100. / (1. + rs))\n",
    "        else:\n",
    "            rsi = 100.\n",
    "            \n",
    "        prev_rsi[x] = rsi\n",
    "    else:\n",
    "        rsi = prev_rsi[x]\n",
    "    \n",
    "    # ADX: Trend when above 25 and no trend when below 20. Find the new true range value which\n",
    "    #      is the max value of one of three values. Read function adx_create() information to\n",
    "    #      understand the calculations occurring here.\n",
    "    true_range_new = max(   (day_high[x]-day_low[x]),\n",
    "                         abs(day_high[x]-mylist[x].loc[251,0]),\n",
    "                         abs(day_low[x]-mylist[x].loc[251,0]))\n",
    "    plus_DM_new    = day_high[x] - highlowcloselist[name][0].ix[len_high-1] \n",
    "    minus_DM_new   = day_low[x]  - highlowcloselist[name][1].ix[len_high-1]\n",
    "    \n",
    "    if plus_DM_new < 0:\n",
    "        plus_DM_new  = 0\n",
    "    if minus_DM_new < 0:\n",
    "        minus_DM_new = 0\n",
    "    len_adx = len(adx_dict)-1\n",
    "        \n",
    "    tr14     = adx_dict[name][0].ix[len_adx] - (adx_dict[name][0].ix[len_adx] / float(adx_period)) + true_range_new\n",
    "    pos_dm14 = adx_dict[name][1].ix[len_adx] - (adx_dict[name][1].ix[len_adx] / float(adx_period)) + plus_DM_new\n",
    "    neg_dm14 = adx_dict[name][2].ix[len_adx] - (adx_dict[name][2].ix[len_adx] / float(adx_period)) + minus_DM_new \n",
    "    pos_DI14 = (pos_dm14 / tr14) * 100. \n",
    "    neg_DI14 = (neg_dm14 / tr14) * 100.\n",
    "    dx14     = (pos_DI14 - neg_DI14) / (pos_DI14 + neg_DI14)\n",
    "    adx14    = ((adx_dict[name][3].ix[len_adx] * 13.) + dx14) / float(adx_period)\n",
    "    \n",
    "    # Stochastic Oscillator: Ranges from 0-100, 80 overbough, 20 undersold. Read the function\n",
    "    #                        information from the kd_ratio_create() function for more info on\n",
    "    #                        what's happening in this function.\n",
    "    prev_5_min = min(low_5)\n",
    "    prev_5_max = max(high_5)\n",
    "    cl         = mylist[x].loc[252,0] - prev_5_min\n",
    "    hl         = prev_5_max - prev_5_min\n",
    "    new_k      = (cl / hl) * 100.\n",
    "    new_d      = (kd_dict[name][0].ix[len_high - 1] + kd_dict[name][0].ix[len_high - 2] + new_k) / 3.\n",
    "    kd_ratio   = new_d\n",
    "    \n",
    "    return volatility, aroon_index, macd, cci, adx14, kd_ratio, rsi\n",
    "\n",
    "def make_year_list(closings, mylist, last_close, rsi_dict, tickers):\n",
    "    \"\"\"\n",
    "    Function is called the first time calculate_attributes() is called, and it sets up several\n",
    "    different variables. It will return the mylist list which is a list of lists, and the previous\n",
    "    year's worth of closing prices is placed in the list for each company.\n",
    "    \n",
    "    The 3 global variables set up are day low, which is simply the day's low price, the day high\n",
    "    variable, and the previous rsi value which is used in case the current closing price is the \n",
    "    same price as the previous call, and in that case, it returns the previous rsi value instead.\n",
    "    \"\"\"\n",
    "    global day_low\n",
    "    global day_high\n",
    "    global prev_rsi\n",
    "    day_low  = [[] for i in range(65)]\n",
    "    day_high = [[] for i in range(65)]\n",
    "    prev_rsi = [[] for i in range(65)]\n",
    "    \n",
    "    # Get the most recent rsi values for each company to be the initial\n",
    "    #  previous rsi value in case of same closing prices.\n",
    "    y = 0\n",
    "    for yahoo in tickers[:51]:\n",
    "        prev_rsi[y] = rsi_dict[yahoo][2][-1]\n",
    "        y          += 1\n",
    "    \n",
    "    # Set the initial day low and high as the closing price fed in. Set up\n",
    "    #  mylist closing prices, then return that list.\n",
    "    y = 0\n",
    "    for each in tickers:\n",
    "        day_low[y]  = last_close[y]\n",
    "        day_high[y] = last_close[y]\n",
    "        df          = closings[each][len(closings[each]) - 252 : len(closings[each])]\n",
    "        mylist[y]   = pd.DataFrame(df[0].values.tolist())\n",
    "        y          += 1  \n",
    "    return mylist\n",
    "\n",
    "def day_end_operations(tickers, combined, last_close):\n",
    "    \"\"\"\n",
    "    An end of day function called once the trading day is over to update our pickled\n",
    "    files filled with daily closing prices and indicator values.\n",
    "    \n",
    "    Open our pickled files, read them in, and add our latest closing prices and \n",
    "    indicator values to them to show the day end values.\n",
    "    \n",
    "    Finally once new values are appending, write the files back to disk.\n",
    "    \"\"\"\n",
    "    \n",
    "    # closings represents our dictionary filled with each companies daily closing\n",
    "    #  prices for its entirety trading.\n",
    "    # stats represents our calculated daily indicator values since the all indexes\n",
    "    #  were available which is about since 2004.\n",
    "    cl       = open('smallcompanyclosingslist.pickle','rb')\n",
    "    fe       = open('smallcompanyfeatureslist.pickle','rb')\n",
    "    closings = pickle.load(cl)\n",
    "    stats    = pickle.load(fe)\n",
    "    cl.close()\n",
    "    fe.close()\n",
    "    \n",
    "    try:\n",
    "        i = 0\n",
    "        for each in tickers:\n",
    "\n",
    "            date           = datetime.date.today()\n",
    "\n",
    "            day_end_close  = last_close[i]\n",
    "            last_stats     = combined[i]\n",
    "\n",
    "            close_df       = pd.DataFrame([day_end_close], index=[date])\n",
    "            stats_df       = pd.DataFrame(last_stats, index=[date])\n",
    "\n",
    "            closings[each] = closings[each].append(close_df)  \n",
    "            stats[each]    = stats[each].append(stats_df)\n",
    "\n",
    "            i += 1  \n",
    "\n",
    "        cl2 = open('smallcompanyclosingslist.pickle','wb')\n",
    "        fe2 = open('smallcompanyfeatureslist.pickle','wb')\n",
    "        pickle.dump(closings,cl2)\n",
    "        pickle.dump(stats,fe2)\n",
    "        cl2.close()\n",
    "        fe2.close()\n",
    "    \n",
    "    except:\n",
    "            print each\n",
    "            raise \n",
    "    \n",
    "    return closings, stats\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def get_data_ready():\n",
    "    \"\"\"\n",
    "    First function called at the beginning of the trading day. It first figures out what day\n",
    "    it is, the previous trading day and the next trading day. It opens the previous days datafile\n",
    "    that will be used to calculate intra-day daily return values.\n",
    "    \n",
    "    Setup the stock ticker symbols for both the Google and Yahoo servers, the Google for real-time\n",
    "    stock data, and the yahoo for previous high/low values. Then call the setup function to create\n",
    "    the dictionaries for several of the indicators getting the previous data for these indicators\n",
    "    by using the historical stock data brought in from the pickled file called yahoo. Then put all\n",
    "    these newly created dictionaries in a list called attributes.\n",
    "    \n",
    "    Then find the companies with upcoming stock splits and dividends and compare them to our list\n",
    "    to see if we have any companies with upcoming dates so we can adjust for them. As of right now\n",
    "    (2016-06-11), the function to adjust has not been created but will be in the future.\n",
    "    \n",
    "    Finally call the company_news() function to retrieve info for each company and index/sector for\n",
    "    new articles on them. As of right now the function to automatically read the data, and convert the\n",
    "    data to extra information to help in prediction, has not been created but will be created soon. It\n",
    "    will utilize a neural network to comprehend the data, possible using Google's new Parsy McParseFace\n",
    "    module just released that is built for NLP(Natural Language Processing).\n",
    "    \"\"\"\n",
    "    \n",
    "    cl          = open('smallcompanyclosingslist.pickle','rb')\n",
    "    ye          = open('2016-06-09dayendtickerlist.pickle', 'rb')\n",
    "    yahoo       = open('historicalyahoodata.pickle', 'rb')\n",
    "    closings    = pickle.load(cl)\n",
    "    yesterday   = pickle.load(ye)\n",
    "    yahoo_data  = pickle.load(yahoo)\n",
    "    cl.close()\n",
    "    ye.close()\n",
    "    yahoo.close()\n",
    "    \n",
    "    # Ticker symbols for both yahoo and google servers\n",
    "    new_tickers    = ['BPOP','FITB','HBAN','CMCSA','EBAY','NWSA',\n",
    "                      'AAPL','AMAT','BRCD','CSCO','DELL','GOOG','INTC',\n",
    "                      'LVLT','MSFT','MU','NVDA','ORCL','QCOM','RIMM',\n",
    "                      'SIRI','SNDK','WIN','YHOO','BHP','BP',\n",
    "                      'RIO','XOM','GE','F','MO','XRX','GS','HBC','JPM',\n",
    "                      'LYG','MS','RF','UBS','USB','WFC','MRK','PFE','NYSE:LMT',\n",
    "                      'MGM','AMD','EMC','GLW','HPQ','S','T',\n",
    "                      'NYSEARCA:UNG','NYSEARCA:USO','NYSEARCA:GLD','NYSEARCA:SPY',\n",
    "                      'INDEXDJX:.DJI','INDEXSP:.INX','INDEXNASDAQ:.IXIC',\n",
    "                      'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "    yahoo_tickers  = ['BPOP','FITB','HBAN','CMCSA','EBAY','NWSA',\n",
    "                      'AAPL','AMAT','BRCD','CSCO','DELL','GOOG','INTC',\n",
    "                      'LVLT','MSFT','MU','NVDA','ORCL','QCOM','RIMM',\n",
    "                      'SIRI','SNDK','WIN','YHOO','BHP','BP',\n",
    "                      'RIO','XOM','GE','F','MO','XRX','GS','HBC','JPM',\n",
    "                      'LYG','MS','RF','UBS','USB','WFC','MRK','PFE','LMT',\n",
    "                      'MGM','AMD','EMC','GLW','HPQ','S','T',\n",
    "                      'UNG', 'USO', 'GLD', 'SPY',\n",
    "                      '%5EDJI', '^GSPC', '%5EIXIC', \n",
    "                      'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "    \n",
    "    # Setup attribute dictionaries\n",
    "    highlowcloselist = highlowcloselist_create(yahoo_data, yahoo_tickers)\n",
    "    adx_dict         = adx_create(highlowcloselist, yahoo_tickers)\n",
    "    rsi_dict         = rsi_create(highlowcloselist, yahoo_tickers)\n",
    "    macd_dict        = macd_create(highlowcloselist, yahoo_tickers)\n",
    "    aroon_dict       = aroon_create(highlowcloselist, yahoo_tickers)\n",
    "    vol_dict         = volatility_create(highlowcloselist, yahoo_tickers)\n",
    "    cci_dict         = cci_create(highlowcloselist, yahoo_tickers)\n",
    "    kd_ratio_dict    = kd_ratio_create(highlowcloselist, yahoo_tickers)\n",
    "    attributes       = [highlowcloselist, adx_dict, rsi_dict, macd_dict, kd_ratio_dict]\n",
    "    \n",
    "    # Find companies with upcoming dividends and stock splits\n",
    "    div_dates   = 'http://www.nasdaq.com/dividend-stocks/dividend-calendar.aspx'\n",
    "    split_dates = 'http://www.nasdaq.com/markets/upcoming-splits.aspx'\n",
    "    dividends   = pd.DataFrame(dividend_find(div_dates), columns=['Symbol','ExDiv','Div','RecDate','PayDate'])\n",
    "    splits      = pd.DataFrame(stock_splits(split_dates),columns=['Symbol','ExDate','Ratio','Payable'])\n",
    "    divs        = dividends['Symbol'].values\n",
    "    spls        = splits['Symbol'].values\n",
    "    \n",
    "    # Print out which companies have stock splits and dividends upcoming, if any\n",
    "    for each in divs:\n",
    "        if each in new_tickers:\n",
    "            print each, \"DIV\"\n",
    "    for each2 in spls:\n",
    "        if each2 in new_tickers:\n",
    "            print each2, \"SPLITS\"\n",
    "            \n",
    "    #todays_news  = company_news(tickers)\n",
    "    #news_file = today_trading+'daynews.pickle'\n",
    "    #tn = open(news_file, 'wb')\n",
    "    #pickle.dump(todays_news, tn)\n",
    "    #tn.close()\n",
    "    return new_tickers, closings, outlist, yesterday, attributes#, todays_news\n",
    "\n",
    "def run_program():\n",
    "    \"\"\"\n",
    "    Function will wait until the start of the training day(9:30AM) and start the\n",
    "    process about 2 minute before start by calling get_data_ready() which takes roughly\n",
    "    2 minutes to process everything so it starts recording and calculating in real-time\n",
    "    at about 9:30.\n",
    "    \n",
    "    Until the time is between 9:28 and 9:30, it will check if we're in that range, else\n",
    "    it sleeps for 60 seconds and does this until its called.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        time.sleep(60)\n",
    "        now      = datetime.datetime.now()\n",
    "        now_time = now.time()\n",
    "        \n",
    "        if now_time >= datetime.time(9,28) and now_time <= datetime.time(9,30):\n",
    "            ts, cls, olist, yest, attrs     = get_data_ready()\n",
    "            tlist, dlist, combined, last_cl = real_time_quotes(ts, cls, olist, yest, attrs)\n",
    "            break\n",
    "\n",
    "    return tlist, dlist, combined, last_cl\n",
    "    \n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tickerlist, dailylist, combined, closings = run_program()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yahoo_tickers  = ['BPOP','FITB','HBAN','CMCSA','EBAY','NWSA',\n",
    "                      'AAPL','AMAT','BRCD','CSCO','DELL','GOOG','INTC',\n",
    "                      'LVLT','MSFT','MU','NVDA','ORCL','QCOM','RIMM',\n",
    "                      'SIRI','SNDK','WIN','YHOO','BHP','BP',\n",
    "                      'RIO','XOM','GE','F','MO','XRX','GS','HBC','JPM',\n",
    "                      'LYG','MS','RF','UBS','USB','WFC','MRK','PFE','LMT',\n",
    "                      'MGM','AMD','EMC','GLW','HPQ','S','T',\n",
    "                      'UNG', 'USO', 'GLD', 'SPY',\n",
    "                      '^DJI', '^GSPC', '^IXIC', \n",
    "                      'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "\n",
    "def yahoo_historical_retrieval(yahoo_tickers):\n",
    "    historical, b = {}, 0\n",
    "    \n",
    "    for each in yahoo_tickers:\n",
    "        try:\n",
    "            test = Share(each)\n",
    "            history = test.get_historical('2011-07-01','2016-06-18')\n",
    "            historical[each] = history\n",
    "        except:\n",
    "            print each\n",
    "            raise\n",
    "    \n",
    "    stdout.write(\"\\r%d\" % b)\n",
    "    stdout.flush()\n",
    "    b += 1\n",
    "\n",
    "    return historical\n",
    "\n",
    "def adjust_yahoo(historical, yahoo_tickers):\n",
    "    adj_historical = {}\n",
    "    for each in yahoo_tickers:\n",
    "        date, adj_high, adj_low, adj_close = [], [], [], []\n",
    "\n",
    "        for x in xrange(0, len(historical[each])):\n",
    "\n",
    "            date.append(historical[each][x]['Date'])\n",
    "\n",
    "            adj_high.append((float(historical[each][x]['High'].replace(',','')) * \n",
    "                            (float(historical[each][x]['Adj_Close'].replace(',','')) / \n",
    "                             float(historical[each][x]['Close'].replace(',','')))))\n",
    "\n",
    "            adj_low.append((float(historical[each][x]['Low'].replace(',','')) * \n",
    "                           (float(historical[each][x]['Adj_Close'].replace(',','')) / \n",
    "                            float(historical[each][x]['Close'].replace(',','')))))\n",
    "\n",
    "            adj_close.append(float(historical[each][x]['Adj_Close'].replace(',','')))\n",
    "\n",
    "        df = pd.DataFrame([adj_high, adj_low, adj_close, date]).T \n",
    "        df.columns = ['Adj_High', 'Adj_Low', 'Adj_Close', 'Date']\n",
    "        df = df.set_index('Date')\n",
    "\n",
    "        adj_historical[each] = df\n",
    "        \n",
    "    return adj_historical\n",
    "\n",
    "def adj_intraday(adj_hist):\n",
    "    adj_intra = {}\n",
    "    for file in os.listdir(\"C:/Users/JohnSmith2/version-control/Projects/projects/trading/intraday\"):\n",
    "        if file.endswith(\".csv\"):\n",
    "            adj_close, time   = [], []\n",
    "            highlist, lowlist = [], []\n",
    "\n",
    "            fname  = str(file)\n",
    "            direct = 'intraday/'\n",
    "            name   = direct+fname\n",
    "            intra  = pd.read_csv(name, sep=';', decimal=',')\n",
    "\n",
    "            for x in xrange(0, len(intra)):\n",
    "                times       = intra.ix[x]['timestamp']\n",
    "                close       = intra.ix[x]['close']\n",
    "                high        = intra.ix[x]['high']\n",
    "                low         = intra.ix[x]['low']\n",
    "                \n",
    "                yahoo_date  = times[:10]\n",
    "                yahoo_adj   = adj_hist[fname].loc[yahoo_date]['Adj_Close']\n",
    "                yahoo_close = adj_hist[fname].loc[yahoo_date]['Close']\n",
    "                \n",
    "                adj_high    = high  * (yahoo_adj / yahoo_close)\n",
    "                adj_low     = low   * (yahoo_adj / yahoo_close)\n",
    "                adj_cl      = close * (yahoo_adj / yahoo_close)\n",
    "                \n",
    "                if x == 0:\n",
    "                    high = adj_high\n",
    "                    low  = adj_low\n",
    "                else:\n",
    "                    new_high = adj_high\n",
    "                    new_low  = adj_low\n",
    "                    if new_high > high:\n",
    "                        high = new_high\n",
    "                    if new_low < low:\n",
    "                        low = new_low\n",
    "                        \n",
    "                lowlist.append(low)    \n",
    "                highlist.append(high)\n",
    "                adj_close.append(adj_cl)\n",
    "                time.append(times)\n",
    "\n",
    "            adj_df           = pd.DataFrame([adj_close, highlist, lowlist ,time]).T\n",
    "            adj_df.columns   = ['Adj_Close','Adj_High','Adj_Low','Time']\n",
    "            adj_df           = adj_df.set_index('Time')\n",
    "\n",
    "            adj_intra[fname] = adj_df\n",
    "    return adj_intra\n",
    "\n",
    "historical     = yahoo_historical_retrieval(yahoo_tickers)\n",
    "adj_historical = adjust_yahoo(historical, yahoo_tickers)\n",
    "adj_intra      = adj_intraday(adj_historical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
