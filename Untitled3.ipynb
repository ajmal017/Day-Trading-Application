{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from googlefinance import getQuotes, getNews\n",
    "from yahoo_finance import Share\n",
    "from dateutil import rrule  \n",
    "from sys import stdout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import urllib\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import requests\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#### # Credit to https://gist.github.com/jckantor/d100a028027c5a6b8340 for these next two trading date functions\n",
    "def NYSE_holidays(a=datetime.date.today()-datetime.timedelta(days=1), b=datetime.date.today()+datetime.timedelta(days=365)): \n",
    "    # Generate ruleset for holiday observances on the NYSE \n",
    "    rs = rrule.rruleset()\n",
    "    # Include all potential holiday observances \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=12, bymonthday=31, byweekday=rrule.FR)) # New Years Day   \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 1, bymonthday= 1))                     # New Years Day   \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 1, bymonthday= 2, byweekday=rrule.MO)) # New Years Day     \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 1, byweekday= rrule.MO(3)))            # Martin Luther King Day    \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 2, byweekday= rrule.MO(3)))            # Washington's Birthday \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, byeaster= -2))                                  # Good Friday \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 5, byweekday= rrule.MO(-1)))           # Memorial Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 7, bymonthday= 3, byweekday=rrule.FR)) # Independence Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 7, bymonthday= 4))                     # Independence Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 7, bymonthday= 5, byweekday=rrule.MO)) # Independence Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth= 9, byweekday= rrule.MO(1)))            # Labor Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=11, byweekday= rrule.TH(4)))            # Thanksgiving Day \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=12, bymonthday=24, byweekday=rrule.FR)) # Christmas   \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=12, bymonthday=25))                     # Christmas   \n",
    "    rs.rrule(rrule.rrule(rrule.YEARLY, dtstart=a, until=b, bymonth=12, bymonthday=26, byweekday=rrule.MO)) # Christmas  \n",
    "    # Exclude potential holidays that fall on weekends \n",
    "    rs.exrule(rrule.rrule(rrule.WEEKLY, dtstart=a, until=b, byweekday=(rrule.SA,rrule.SU))) \n",
    "    return rs \n",
    "def NYSE_tradingdays(a=datetime.date.today()-datetime.timedelta(days=1), b=datetime.date.today()+datetime.timedelta(days=365)): \n",
    "    # Generate ruleset for NYSE trading days \n",
    "    rs = rrule.rruleset() \n",
    "    rs.rrule(rrule.rrule(rrule.DAILY, dtstart=a, until=b)) \n",
    "    # Exclude weekends and holidays \n",
    "    rs.exrule(rrule.rrule(rrule.WEEKLY, dtstart=a, byweekday=(rrule.SA,rrule.SU))) \n",
    "    rs.exrule(NYSE_holidays(a,b)) \n",
    "    return rs \n",
    "#######################################\n",
    "\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def kd_ratio_create(highlowcloselist, yahoo_tickers, periods):  \n",
    "    \"\"\"\n",
    "    Take the highlowcloselist dictionary that was created by the highlowcloselist_create function \n",
    "    and the yahoo ticker list, and create a dictionary that contains the stochastic oscillator \n",
    "    calculations that this function makes and it will eventually be used in the deep learning function\n",
    "    \"\"\"\n",
    "    kd_ratio_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        one = [390]\n",
    "        periods = one + periods\n",
    "        \n",
    "        high  = highlowcloselist[each][0]\n",
    "        low   = highlowcloselist[each][1]\n",
    "        close = highlowcloselist[each][2]\n",
    "        \n",
    "        kd_list = []\n",
    "        for x in range(8):\n",
    "            kd_df     = pd.DataFrame()\n",
    "            prev_max  = high.rolling(window = periods[x+1], center = False).max()\n",
    "            prev_min  = low.rolling(window  = periods[x+1], center = False).min()\n",
    "        \n",
    "            cl  = close    - prev_max\n",
    "            hl  = prev_max - prev_min\n",
    "            k   = (((cl / hl) * 100.).fillna(0)).replace([np.inf,-np.inf], 0)\n",
    "            d   = (k.rolling(window = periods[x], center = False).mean()).fillna(0)\n",
    "\n",
    "            kd_df[0] = k\n",
    "            kd_df[1] = d\n",
    "            kd_list.append(kd_df)\n",
    "            \n",
    "        kd_ratio_dict[each] = kd_list\n",
    "    return kd_ratio_dict\n",
    "\n",
    "def cci_create(highlowclose, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    This function takes the highlowclose dictionary and yahoo ticker list and calculates the \n",
    "    commodity channel index for each company.\n",
    "    \"\"\"\n",
    "    cci_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        # These variable values are market standards but can be adjusted\n",
    "        constant    = 0.015\n",
    "        window      = (14 * 390)\n",
    "        mean_window = (20 * 390)\n",
    "        \n",
    "        typ            = highlowclose[each][3]\n",
    "        typ_mad        = (typ.rolling(window = window,      center = False).mad()).fillna(0)\n",
    "        typ_mean       = (typ.rolling(window = mean_window, center = False).mean()).fillna(0)\n",
    "        \n",
    "        cci_dict[each] = ((typ - typ_mean) / (constant * typ_mad)).replace([np.inf,-np.inf], 0)\n",
    "    return cci_dict\n",
    "\n",
    "def volatility_create(highlowcloselist, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    Take the highlowclose dictionary and yahoo ticker list, and create a volatility index for each\n",
    "    company.\n",
    "    \"\"\"\n",
    "    vol_dict = {}\n",
    "    for each2 in yahoo_tickers:\n",
    "        close  = highlowcloselist[each2][2]\n",
    "        window = (30 * 390)\n",
    "        \n",
    "        returns         = (close / close.shift(1) - 1).fillna(0)  \n",
    "        vol_dict[each2] = returns.rolling(window = window, center=False).std() * np.sqrt(window) \n",
    "    return vol_dict\n",
    "\n",
    "def aroon_create(highlowcloselist, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    Calculate aroon index for each company, another indicator that will be used in \n",
    "    prediction process.\n",
    "    \"\"\"\n",
    "    aroon_dict  = {}\n",
    "    window      = (25 * 390)\n",
    "    for each in yahoo_tickers:\n",
    "        i = window\n",
    "        for y in xrange(window, len(highlowcloselist[each][0])):\n",
    "            aroon_series    = pd.Series(0.0, highlowcloselist[each][0].index)\n",
    "            new_closing     = highlowcloselist[each][2][(y-(25*390-1)) : y+1]\n",
    "            \n",
    "            aroon_up        = ((float(window) - (252. - new_closing[0].idxmax())) / float(window)) * 100.\n",
    "            aroon_down      = ((float(window) - (252. - new_closing[0].idxmin())) / float(window)) * 100.\n",
    "            aroon_series[i] = aroon_up - aroon_down\n",
    "            i += 1\n",
    "              \n",
    "        aroon_dict[each] = aroon_series\n",
    "    return aroon_dict\n",
    "\n",
    "def macd_create(highlowcloselist, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    Calculate the Moving Average Converge Divergence index, an indicator used a lot in stock\n",
    "    market prediction.\n",
    "    \"\"\"\n",
    "    macd_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        # n and m represent the period lengths, can be changed if better results are capable\n",
    "        close    = highlowcloselist[each][2]\n",
    "        window_s = (12 * 390) \n",
    "        window_l = (26 * 390) \n",
    "        \n",
    "        macd_df    = (close / close.ewm(ignore_na=False, span=window_s, min_periods=0, adjust=True).mean() - 1).fillna(0)\n",
    "        macd_df[1] = (close / close.ewm(ignore_na=False, span=window_l, min_periods=0, adjust=True).mean() - 1).fillna(0)\n",
    "        macd_df[2] = ema_12 - ema_26\n",
    "        \n",
    "        macd_dict[each] = macd_df\n",
    "    return macd_dict\n",
    "\n",
    "def rsi_create(highlowcloselist, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    Calculate the relative strength index used as another indicator for the prediction process.\n",
    "    \"\"\" \n",
    "    rsi_dict = {}\n",
    "    for each in yahoo_tickers:\n",
    "        close  = highlowcloselist[each][2]\n",
    "        deltas = (close - close.shift(1)).fillna(0)\n",
    "        window = (14 * 390)\n",
    "        \n",
    "        avg_gains  =  deltas[1:window+1][deltas > 0].sum() / window\n",
    "        avg_losses = -deltas[1:window+1][deltas < 0].sum() / window\n",
    "\n",
    "        # Set up pd.Series container for RSI values\n",
    "        rsi_series = pd.Series(0.0, deltas.index)\n",
    "\n",
    "        # Now calculate RSI using the Wilder smoothing method, starting with n+1 delta.\n",
    "        up   = lambda x:  x if x > 0 else 0\n",
    "        down = lambda x: -x if x < 0 else 0\n",
    "        \n",
    "        i = window + 1\n",
    "        for d in deltas[window+1:]:\n",
    "            avg_gains  = ((avg_gains  * (window - 1.)) + up(d))   / window\n",
    "            avg_losses = ((avg_losses * (window - 1.)) + down(d)) / window\n",
    "            \n",
    "            if avg_of_losses != 0:\n",
    "                rs = avg_gains / avg_losses\n",
    "                rsi_series[i] = 100. - (100. / (1. + rs))\n",
    "            else:\n",
    "                rsi_series[i] = 100.\n",
    "            i += 1\n",
    "        \n",
    "        rsi_list = [avg_gains, avg_losses, rsi_series]\n",
    "    return rsi_list\n",
    "\n",
    "def adx_create(highlowcloselist, yahoo_tickers):\n",
    "    \"\"\"\n",
    "    Calculate the Average Directional Index for each company, an indicator used to help in the prediction\n",
    "    process.\n",
    "    \"\"\"\n",
    "    adx_dict = {}\n",
    "    window   = (14 * 390)\n",
    "    for each in yahoo_tickers:\n",
    "        # True range is the max value of one of three operations.\n",
    "        # plus_dm is the positive directional moving list, minus_dm the negative.\n",
    "        # tr14_list is the 14 day mean of the previous 14 days worth of true ranges\n",
    "        # dx14_list is the directional index 14 day mean\n",
    "        # adx14_list is the where the final average directional index calculations go. \n",
    "        high  = highlowcloselist[each][0]\n",
    "        low   = highlowcloselist[each][1]\n",
    "        close = highlowcloselist[each][2]\n",
    "        \n",
    "        plus_df  = (high - high.shift(1)).fillna(0)\n",
    "        minus_dm = (low.shift(1) - low).fillna(0)\n",
    "        plus_dm[plus_dm < 0]   = 0\n",
    "        minus_dm[minus_dm < 0] = 0\n",
    "        \n",
    "        tr_df     = (high - low)\n",
    "        tr_df[1]  = (high - close.shift(1)).fillna(0)\n",
    "        tr_df[2]  = (low  - close.shift(1)).fillna(0)\n",
    "        tr_max_df = tr_df.max(axis=1)\n",
    "        \n",
    "        # Find the starting 14 day sums for true range, pos directional moving and negative\n",
    "        tr14           = sum(tr_max_df[0][1:window+1])\n",
    "        pos_dm14       = sum(plus_dm[0][1:window+1])\n",
    "        neg_dm14       = sum(minus_dm[0][1:window+1])\n",
    "        tr14_series    = pd.Series(0.0, tr_df.index)\n",
    "        posdm14_series = pd.Series(0.0, plus_dm.index)\n",
    "        negdm14_series = pd.Series(0.0, minus_dm.index)\n",
    "        dx14_series    = pd.Series(0.0, tr_df.index)\n",
    "        \n",
    "        i = window + 1\n",
    "        for y in xrange(window+1, len(tr_max_df)):\n",
    "            # Moving averages calculated\n",
    "            tr14      = tr14     - (tr14     / float(window)) + tr_max_df[0].ix[y]\n",
    "            pos_dm14  = pos_dm14 - (pos_dm14 / float(window)) + plus_dm[0].ix[y]\n",
    "            neg_dm14  = neg_dm14 - (neg_dm14 / float(window)) + minus_dm[0].ix[y]\n",
    "                \n",
    "            # Positive and negative 14 day directional indexes\n",
    "            pos_di14  = (pos_dm14 / tr14) * 100.\n",
    "            neg_di14  = (neg_dm14 / tr14) * 100.\n",
    "                \n",
    "            # Sum of pos and neg directional index can't be 0\n",
    "            if (pos_di14 + neg_di14) != 0:\n",
    "                dx14 = (pos_di14 - neg_di14) / (pos_di14 + neg_di14) \n",
    "            else:\n",
    "                dx14 = None    \n",
    "                    \n",
    "            tr14_series[i]    = tr14\n",
    "            dx14_series[i]    = dx14\n",
    "            posdm14_series[i] = pos_dm14\n",
    "            negdm14_series[i] = neg_dm14\n",
    "            i += 1\n",
    "        \n",
    "        # Starting adx calculated by summing the previous 14 days worth of dx14_list calcs\n",
    "        adx14      = sum(dx14_series[0][window+1:window+window+1])\n",
    "        adx_series = pd.Series(0.0, dx14_series.index)\n",
    "        \n",
    "        i = window + 1\n",
    "        for y in xrange(0, len(dx_df)):\n",
    "            # Calc adx\n",
    "            adx14         = ((adx14 * 13.) + dx14_series[0].ix[y]) / float(window)\n",
    "            adx_series[i] = adx14\n",
    "            i += 1\n",
    "\n",
    "        adx_df    = tr14_series\n",
    "        adx_df[2] = posdm14_series\n",
    "        adx_df[3] = negdm14_series\n",
    "        adx_df[4] = adx_series\n",
    "        \n",
    "        adx_dict[each] = adx_df\n",
    "    return adx_dict\n",
    "\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def company_news(newstickers):\n",
    "    \"\"\"\n",
    "    Use Google's server and use https://github.com/hongtaocai/googlefinance module to retrieve\n",
    "    the real-time stock news data for each company stock symbol fed to it.\n",
    "    \"\"\"\n",
    "    tickernewslist = {}\n",
    "    \n",
    "    for each in newstickers:\n",
    "        tickernewslist[each] = getNews(each)  \n",
    "    return tickernewslist\n",
    "\n",
    "def stock_splits(stock_split_dates):\n",
    "    \"\"\"\n",
    "    Read in the stock split site data to discover if any of our watched companies have \n",
    "    stock splits in the near future so the data can be adjusted for it. Return which \n",
    "    companies if any are discovered on it.\n",
    "    \"\"\"\n",
    "    splitup        = urllib.urlopen(stock_split_dates).read()\n",
    "    companies      = splitup.find('Announced')\n",
    "    stop           = splitup.find('th_No_BG', companies)\n",
    "    company_splits = []\n",
    "    \n",
    "    # Find which companies are listed along with the stock split ratio,\n",
    "    #  the ex-date, and the payment date.\n",
    "    while True:\n",
    "        done      = splitup.find(')</a>',stop)+1\n",
    "        next_stop = splitup.rfind('(', stop, done)\n",
    "        ratio_s   = splitup.find('<td>',done)+4\n",
    "        ratio_e   = splitup.find('<',ratio_s)\n",
    "        payment_e = splitup.find('2016',done)+4\n",
    "        payment_s = splitup.rfind('<td>',stop,payment_e)+4\n",
    "        exdate_s  = splitup.find('<td>',payment_e)+4\n",
    "        exdate_e  = splitup.find('</td>',exdate_s)\n",
    "        \n",
    "        company_splits.append([splitup[next_stop+1:done-1],\n",
    "                               splitup[exdate_s:exdate_e],\n",
    "                               splitup[ratio_s:ratio_e],\n",
    "                               splitup[payment_s:payment_e]])\n",
    "        \n",
    "        tbody = splitup.find('</table>',done)\n",
    "        test  = splitup.find('(',done)\n",
    "        \n",
    "        if tbody < test:\n",
    "            break\n",
    "        stop = done\n",
    "    return company_splits\n",
    "\n",
    "def dividend_find(dividend_dates): \n",
    "    \"\"\"\n",
    "    Like the stock_splits() function, searches a site to find if any of our companies have\n",
    "    an upcoming dividend so as to adjust for it. Return a list of companies, if any.\n",
    "    \"\"\"\n",
    "    company_dividends = []\n",
    "    for x in xrange(0,2):\n",
    "        if x != 0:\n",
    "            dividends      = urllib.urlopen(dividend_dates).read()  \n",
    "            end            = dividends.find('Next')-2\n",
    "            start          = dividends.rfind('href=',0,end)+6\n",
    "            next_day       = dividends[start:end]\n",
    "            dividend_dates = 'http://www.nasdaq.com/dividend-stocks/'+next_day \n",
    "            \n",
    "        dividends = urllib.urlopen(dividend_dates).read()  \n",
    "        start     = dividends.find('Payment Date')\n",
    "        \n",
    "        while True:\n",
    "            start      = dividends.find('&#40;',start)+5\n",
    "            end        = dividends.find('&#41;',start)\n",
    "            ex_date_e  = dividends.find('2016',end)+4\n",
    "            ex_date_s  = dividends.rfind('>',end,ex_date_e)+1\n",
    "            div_e      = dividends.find('</',ex_date_e+1)\n",
    "            div_s      = dividends.rfind('>',ex_date_e,div_e)+1\n",
    "            rec_date_e = dividends.find('2016',div_e)+4\n",
    "            rec_date_s = dividends.rfind('>',div_e,rec_date_e)+1\n",
    "            proceed    = dividends.find('2016',rec_date_e)+4\n",
    "            pay_date_e = dividends.find('2016',proceed)+4\n",
    "            pay_date_s = dividends.rfind('>',proceed,pay_date_e)+1\n",
    "            \n",
    "            company_dividends.append([dividends[start:end],\n",
    "                                    dividends[ex_date_s:ex_date_e],\n",
    "                                    dividends[div_s:div_e],\n",
    "                                    dividends[rec_date_s:rec_date_e],\n",
    "                                    dividends[pay_date_s:pay_date_e]])\n",
    "            \n",
    "            test = dividends.find('&#40;',start)\n",
    "            if test == -1:\n",
    "                break\n",
    "            start = end      \n",
    "    return company_dividends\n",
    "\n",
    "def yahoo_backup():\n",
    "    \"\"\"\n",
    "    Due to Google occasionally blocking our google server api, a yahoo backup is \n",
    "    set up to retrieve stock info from google finance's page. It is far slower so\n",
    "    it's to be avoided if at all possible. Increasing latency between each call can\n",
    "    help Google from your blocking.\n",
    "    \"\"\"\n",
    "    test_array = []\n",
    "    yahoo      = 'http://finance.yahoo.com/q?s='\n",
    "    tickers    =     ['BPOP','FITB','HBAN','CMCSA','EBAY',\n",
    "                      'AAPL','AMAT','BRCD','CSCO','GOOG','INTC',\n",
    "                      'LVLT','MSFT','MU','NVDA','ORCL','QCOM',\n",
    "                      'SIRI','SNDK','WIN','YHOO','BHP','BP',\n",
    "                      'RIO','XOM','GE','F','MO','XRX','GS','JPM',\n",
    "                      'LYG','MS','RF','USB','WFC','MRK','PFE','LMT',\n",
    "                      'MGM','AMD','EMC','GLW','HPQ','S','T',\n",
    "                      'USO','GLD','SPY',\n",
    "                      '%5EDJI','^GSPC','%5EIXIC', \n",
    "                      'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "    \n",
    "    # Retrieve the stock price for each company\n",
    "    for each in tickers:\n",
    "        stock       = yahoo + each\n",
    "        page        = urllib.urlopen(stock).read()\n",
    "        price       = page.find('time_rtq_ticker')\n",
    "        price_stop  = page.find('</span>',price)\n",
    "        price_start = page.rfind('>',price_stop-10,price_stop)+1\n",
    "        \n",
    "        test_array.append(page[price_start:price_stop])\n",
    "    return test_array\n",
    "\n",
    "def get_prev_10d1min_intraday():\n",
    "    \"\"\"\n",
    "    Added to retrieve the previous 10 days worth of intraday trading data with 5 minute\n",
    "    intervals.\n",
    "    \"\"\"\n",
    "    tickers    = ['BPOP','FITB','HBAN','CMCSA','EBAY',\n",
    "                  'AAPL','AMAT','BRCD','CSCO','GOOG','INTC',\n",
    "                  'LVLT','MSFT','MU','NVDA','ORCL','QCOM',\n",
    "                  'SIRI','SNDK','WIN','YHOO','BHP','BP',\n",
    "                  'RIO','XOM','GE','F','MO','XRX','GS','JPM',\n",
    "                  'LYG','MS','RF','USB','WFC','MRK','PFE','LMT',\n",
    "                  'MGM','AMD','EMC','GLW','HPQ','S','T',\n",
    "                  'USO', 'GLD', 'SPY',\n",
    "                  '.DJI','.INX','IXIC',\n",
    "                  'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "    \n",
    "    pages = {}\n",
    "    for each in tickers:\n",
    "        page = 'http://www.google.com/finance/getprices?i=60&p=10d&f=d,c&df=cpct&q='+each\n",
    "        pages[each] = urllib.urlopen(page).read()\n",
    "    complete_list = []\n",
    "    day_list = []\n",
    "    \n",
    "    for each in tickers:\n",
    "        current = pages[each]\n",
    "        start = current.find('\\na')+2\n",
    "        end = len(current)\n",
    "        test = True\n",
    "        df_list = []\n",
    "        \n",
    "        while test == True:\n",
    "            date = current.find(',',start)\n",
    "            price = current.find('\\n',date)\n",
    "            df_list.append(float(current[date+1:price]))\n",
    "\n",
    "            if price != end-1:\n",
    "                if current[price+1] == 'a':\n",
    "                    day_list.append(df_list)\n",
    "                    df_list = []\n",
    "                start = price+2    \n",
    "            else:\n",
    "                test = False\n",
    "                complete_list.append(day_list)\n",
    "                day_list = []        \n",
    "    return complete_list\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def real_time_quotes(tickers, closings, outlist, attributes, periods, periods2):\n",
    "    \"\"\"\n",
    "    As the function name implies, it retrieves stock data in real time. It will be started at\n",
    "    the beginning of the trading day(9:30AM Eastern) and ends at the end of the trading day\n",
    "    (4:00PM Eastern). It retrieves the data from Google's server by calling getQuotes which uses\n",
    "    the same program used to retrieve stock news. Credit goes to https://github.com/hongtaocai/googlefinance\n",
    "    for creating the program to retrieve the data.\n",
    "    \n",
    "    Once the data is retrieved, it's returned in a list of dictionaries, one for each company. We'll\n",
    "    take this info, convert the price to a float from a string. Then that data is taken and used to create\n",
    "    our indicators in real time. Half are calculated in the function calculate_attributes() which is \n",
    "    called here, the other half is called from that function and calls calculate_extra_attributes().\n",
    "    \n",
    "    If the Google server blocks our retrieval process, we call our yahoo_backup() function which retrieves\n",
    "    the data straight from the yahoo finance's website. This is considerably slower so it's always better to\n",
    "    increase the sleep time between each retrieval to slow down how often we're retrieving data as this has\n",
    "    proved to be effective in combatting being blocked in the first place.\n",
    "    \n",
    "    Returns 3 dictionaries: \n",
    "        -tickerlist = Just the a list of dictionaries for each day for the whole trading day for each company.\n",
    "                      Each company can be called with its stock ticker symbol and that retrieves the list of \n",
    "                      dictionaries.\n",
    "        -combined   = Lists the latest indicator list. There are 24 indicators ranging from bollinger bands, \n",
    "                      to PE/Ratios, to Volatilities, etc.. as well as daily returns from the top 5 major indexes\n",
    "                      including the S&P, NYSE, etc. Also the daily returns for the top 7 major sectors, such as\n",
    "                      technology, healthcare, etc.\n",
    "        -last_close = The most current closing price for each company, this will be used to update the day-end \n",
    "                      closing price that's placed in the closing price dictionary. This closing price dictionary\n",
    "                      is a pickled file to increase speed and has the closing prices of the stocks since going\n",
    "                      public.\n",
    "    \"\"\"\n",
    "    tickerlist     = [[] for i in range(59)]\n",
    "    last_close     = [[] for i in range(59)]\n",
    "    mylist         = [[] for i in range(59)]\n",
    "    combined_list  = [[] for i in range(59)]\n",
    "    day_low        = [[] for i in range(59)]\n",
    "    day_high       = [[] for i in range(59)]\n",
    "\n",
    "    # Use the python time module to time how long to retrieve stock data for. A normal\n",
    "    #  trading day means 6.5 hours of trading data.\n",
    "    seconds, minutes, hours, count  = 60, 60, 6.5, 0\n",
    "    len_quotes = len(tickers)\n",
    "    \n",
    "    t_end = time.time() + seconds * minutes * hours\n",
    "    while time.time() < t_end:\n",
    "        try:\n",
    "            start = time.time()\n",
    "            # Try to retrieve the quotes from the Google server\n",
    "            next_quotes = getQuotes(new_tickers)  \n",
    "                \n",
    "            # Append each companies interval data to the list entry list\n",
    "            for x, name in zip(range(len_quotes), tickers):\n",
    "                tickerlist[x].append(next_quotes[x])\n",
    "                last_close[x] = float(next_quotes[x]['LastTradePrice'].replace(',',''))\n",
    "                \n",
    "                # If the latest stock price is a day low or day high, set that price as the day low or high.\n",
    "                if (last_close[x] < day_low[x]) or (last_close[x] > day_high[x]):\n",
    "                    if last_close[x] < day_low[x]:\n",
    "                        day_low[x] = last_close[x]\n",
    "                    else:\n",
    "                        day_high[x] = last_close[x]\n",
    "                \n",
    "                if count > 0:\n",
    "                    # Append current stock price to our year's worth of closing prices\n",
    "                    mylist[x].append(last_close[x])\n",
    "                    \n",
    "            # Setup prev years closing dfs\n",
    "            if count == 0:\n",
    "                mylist, index_returns = make_year_list(closings, mylist, last_close, tickers, index_returns)\n",
    "                \n",
    "            if count > 0:\n",
    "                m = 46\n",
    "                index_returns = []\n",
    "                for index in mylist[46:]:\n",
    "                    minute         = mylist[m].loc[len(mylist[m])-1, 0] / mylist[m].loc[len(mylist[m])-2,    0] - 1\n",
    "                    hour           = mylist[m].loc[len(mylist[m])-1, 0] / mylist[m].loc[len(mylist[m])-61,   0] - 1\n",
    "                    day            = mylist[m].loc[len(mylist[m])-1, 0] / mylist[m].loc[len(mylist[m])-391,  0] - 1\n",
    "                    two_day        = mylist[m].loc[len(mylist[m])-1, 0] / mylist[m].loc[len(mylist[m])-781,  0] - 1\n",
    "                    three_day      = mylist[m].loc[len(mylist[m])-1, 0] / mylist[m].loc[len(mylist[m])-1170, 0] - 1\n",
    "                    five_day       = mylist[m].loc[len(mylist[m])-1, 0] / mylist[m].loc[len(mylist[m])-1950, 0] - 1\n",
    "                    index_returns += [minute, hour, day, two_day, three_day, five_day]\n",
    "                    m += 1\n",
    "            \n",
    "            # Call the attributes function which calculates our list of 24 indicators in real time which \n",
    "            #  will be used to feed to the real-time recurrent neural network for prediction purposes.\n",
    "            combined_list, mylist, attributes = calculate_attributes(closings, tickers, last_close, \n",
    "                                                         mylist, attributes, combined_list, day_low, \n",
    "                                                         day_high, index_returns, periods, periods2)\n",
    "            \n",
    "            end       = time.time()\n",
    "            calc_time = end - start\n",
    "            # Print what loop number we are on, then sleep for 60 seconds before continuing\n",
    "            stdout.write(\"\\r%d\" % count)\n",
    "            stdout.flush()\n",
    "            # Every loop should take exactly 60 seconds, no matter how long the calcs take\n",
    "            time.sleep(60 - calc_time)\n",
    "        \n",
    "        except:\n",
    "            # If Google's server denies our retrieval, call yahoo_backup()\n",
    "            start2 = time.time()\n",
    "            next_quotes = yahoo_backup()\n",
    "            for x in xrange(0,len(next_quotes)):\n",
    "                tickerlist[x].append(next_quotes[x])\n",
    "                #last_close[x]  = float(next_quotes[x].replace(',',''))\n",
    "                    \n",
    "            print \"PRIMARY FAIL\", count\n",
    "            \n",
    "            end2       = time.time()\n",
    "            calc_time2 = end2 - start2\n",
    "            time.sleep(60-calc_time)\n",
    "            pass\n",
    "        count += 1\n",
    "\n",
    "    return tickerlist#, combined, last_close\n",
    "\n",
    "def calculate_attributes(closings, tickers, last_close, mylist, attributes, combined_list, \n",
    "                         day_low, day_high, index_returns, periods, periods2):\n",
    "    \"\"\"\n",
    "    Used to calculate the indicators needed for the prediction process.\n",
    "    \n",
    "    These indicators are placed together in a list. All of these indicators are combined in one list.\n",
    "    Then passed to our real time function. This function is called every time step, so each time \n",
    "    step will calculate it's indicators and this will eventually be used for our recurrent network\n",
    "    that will use online learning to process the indicators and predict stock prices for us.\n",
    "    \n",
    "    Indicators calculated:\n",
    "        -vol   = Volatility Index:\n",
    "                    -Degree of variation of a trading price series over time as measured by the \n",
    "                     standard deviation of returns.           \n",
    "        -aroon = Aroon Index:\n",
    "                    -Determines whether a stock is trending or not and how strong the trend is.        \n",
    "        -macd  = Moving Average Convergence Divergence:\n",
    "                    -Trend following momentum indicator that shows the relationship between \n",
    "                     two moving averages of prices.          \n",
    "        -cci   = Commodity Channel Index:\n",
    "                    -Identifying cyclical trends not only in commodities, but also equities \n",
    "                     and currencies.          \n",
    "        -adx   = Average Directional Index:\n",
    "                    -Measures trend strength without regard to trend direction.          \n",
    "        -kd    = Stochastic Oscillator Index:\n",
    "                    -Momentum indicator that uses support and resistance levels.           \n",
    "        -rsi   = Relative Strength Index:\n",
    "                    -Chart the current and historical strength or weakness of a stock or market \n",
    "                     based on the closing prices of a recent trading period.           \n",
    "        -boll  = Bollinger Bands:\n",
    "                    -Measure the \"highness\" or \"lowness\" of the price relative to previous trades.          \n",
    "        -sma   = Simple Moving Average:\n",
    "                    -Average stock price over a certain period of time.          \n",
    "        -mom   = Momentum:\n",
    "                    -Rate of acceleration of a security's price or volume.           \n",
    "        -pe    = Price/Earnings Ratio:\n",
    "                    -Ratio for valuing a company that measures its current share price relative to \n",
    "                     its per-share earnings.\n",
    "    \"\"\"\n",
    "    # The attributes are indicator values for historical stock data\n",
    "    highlowclose = attributes[0] \n",
    "    adx_dict     = attributes[1]\n",
    "    rsi_dict     = attributes[2]\n",
    "    macd_dict    = attributes[3]\n",
    "    kd_dict      = attributes[4]\n",
    "    \n",
    "    cci,  highlowclose = cci_ind(tickers, mylist, highlowclose, day_low, day_high, periods)\n",
    "    adx,  adx_dict     = adx_ind(tickers, mylist, highlowclose, day_high, day_low, adx_dict, periods)\n",
    "    kd,   kd_dict      = kd_ind(tickers, mylist, highlowclose, kd_dict, periods)\n",
    "    macd, macd_dict    = macd_ind(tickers, mylist, macd_dict, periods2)\n",
    "    rsi,  rsi_dict     = rsi_ind(tickers, mylist, rsi_dict, periods)\n",
    "    aroon              = aroon_ind(mylist, periods)\n",
    "    vol                = vol_ind(mylist, periods)\n",
    "    bol                = bol_ind(mylist, periods)\n",
    "    mom                = mom_ind(mylist, periods)\n",
    "    sma                = sma_ind(mylist, periods)\n",
    "    pe                 = pe_ind(mylist, periods)\n",
    "\n",
    "    # append the indicators to the index/etf's minute/hour/day/2day/3day/5day return values\n",
    "    for x in range(59):\n",
    "        combined = index_returns+cci[x]+adx[x]+kd[x]+macd[x]+rsi[x]+aroon[x]+vol[x]+bol[x]+mom[x]+sma[x]+pe[x]\n",
    "        combined_list[x].append(combined)\n",
    "        \n",
    "    attributes = [highlowclose, adx_dict, rsi_dict, macd_dict, kd_dict]\n",
    "  \n",
    "    return combined_list, mylist, attributes\n",
    "\n",
    "def make_year_list(closings, mylist, last_close, tickers, index_returns):\n",
    "    \"\"\"\n",
    "    Function is called the first time calculate_attributes() is called, and it sets up several\n",
    "    different variables. It will return the mylist list which is a list of lists, and the previous\n",
    "    year's worth of closing prices is placed in the list for each company.\n",
    "    The global variables set up are day low, the day's low price, and the day high variable\n",
    "    \"\"\"\n",
    "    x           = 0\n",
    "    # Set up last years worth of data for each ticker, as well as current highs, lows\n",
    "    for each in tickers[:60]:\n",
    "        day_low[x]     = last_close[x]\n",
    "        day_high[x]    = last_close[x]\n",
    "        df             = closings[each][len(closings[each]) - (253 * 390) : len(closings[each])]\n",
    "        mylist[x]      = pd.DataFrame(df[0].values.tolist())\n",
    "        \n",
    "        # Append current stock price to our year's worth of closing prices, then calc indicators.\n",
    "        mylist[x].append(last_close[x])\n",
    "        x += 1\n",
    "    \n",
    "    m = 46\n",
    "    index_returns = []\n",
    "    for index in mylist[46:]:\n",
    "        minute         = mylist[m].loc[len(mylist[m])-1, 0] / mylist[m].loc[len(mylist[m])-2,    0] - 1.\n",
    "        hour           = mylist[m].loc[len(mylist[m])-1, 0] / mylist[m].loc[len(mylist[m])-61,   0] - 1.\n",
    "        day            = mylist[m].loc[len(mylist[m])-1, 0] / mylist[m].loc[len(mylist[m])-391,  0] - 1.\n",
    "        two_day        = mylist[m].loc[len(mylist[m])-1, 0] / mylist[m].loc[len(mylist[m])-781,  0] - 1.\n",
    "        three_day      = mylist[m].loc[len(mylist[m])-1, 0] / mylist[m].loc[len(mylist[m])-1170, 0] - 1.\n",
    "        five_day       = mylist[m].loc[len(mylist[m])-1, 0] / mylist[m].loc[len(mylist[m])-1950, 0] - 1.\n",
    "        index_returns += [minute, hour, day, two_day, three_day, five_day]\n",
    "        m += 1\n",
    "  \n",
    "    return mylist, index_returns\n",
    "\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def macd_ind(tickers, mylist, macd_d, periods):\n",
    "    x = 0\n",
    "    macd_list = [[] for i in range(59)]\n",
    "    for name in tickers:\n",
    "        macd = []\n",
    "        length  = len(mylist[x])\n",
    "        len_p   = len(periods) \n",
    "        last_cl = mylist[x].loc[length-1, 0]\n",
    "        \n",
    "        \n",
    "        for y in range(len_p):\n",
    "            le         = len(macd_d[name][y])\n",
    "            macd_smult = 780. / (periods[y]   + 390.)\n",
    "            macd_lmult = 780. / (periods[y+3] + 390.)\n",
    "            \n",
    "            macd_small = (last_cl - macd_d[name][y].loc[le-391, 0]) * macd_smult + macd_d[name][y].loc[le-391, 0]\n",
    "            macd_large = (last_cl - macd_d[name][y].loc[le-391, 1]) * macd_smult + macd_d[name][y].loc[le-391, 1]\n",
    "                          \n",
    "            macd_d[name][t].append([macd_small, macd_large])\n",
    "            macd.append(macd_small - macd_large)\n",
    "            \n",
    "        macd_list[x] = macd\n",
    "        x += 1\n",
    "    return macd_list, macd_d\n",
    "\n",
    "def cci_ind(tickers, mylist, highlowcloselist, day_low, day_high, periods):\n",
    "    x = 0\n",
    "    constant = 0.015\n",
    "    cci_list = [[] for i in range(59)]\n",
    "    for name in tickers:\n",
    "        cci         = []\n",
    "        le          = len(mylist[x])\n",
    "        length      = len(highlowcloselist[name])\n",
    "        last_cl     = mylist[x].loc[le-1, 0]\n",
    "        new_typical = (day_low[x] + day_high[x] + last_cl) / 3.\n",
    "        \n",
    "        for each in periods[:8]:\n",
    "            typical_mad  = highlowcloselist[name][3][length - each:][0].mad()\n",
    "            typical_mean = highlowcloselist[name][3][length - each:][0].mean()\n",
    "            cci.append((new_typical - typical_mean) / (constant * typical_mad))\n",
    "            \n",
    "        highlowcloselist[x].append([day_high[x], day_low[x], last_cl, new_typical])  \n",
    "        cci_list[x] = cci\n",
    "        x += 1\n",
    "    return cci_list, highlowcloselist\n",
    "\n",
    "def rsi_ind(tickers, mylist, rsi_dict, periods):\n",
    "    x = 0\n",
    "    rsi_list = [[] for i in range(59)]\n",
    "    for name in tickers:\n",
    "        rsi       = []\n",
    "        le        = len(mylist[x])\n",
    "        last_cl   = mylist[x].loc[le-1,   0]\n",
    "        last_day  = mylist[x].loc[le-391, 0]\n",
    "        last_diff = last_cl - last_day\n",
    "        \n",
    "        if last_diff >= 0:\n",
    "            up   = last_diff\n",
    "            down = 0.0\n",
    "        else:\n",
    "            up   = 0.0 \n",
    "            down = abs(last_diff)\n",
    "           \n",
    "        y = 0\n",
    "        for each in periods[:8]:\n",
    "            length = len(rsi_dict[name][each])\n",
    "            avg_g  = ((rsi_dict[name][0].loc[length - 1, y] * (each - 1.)) + up)   / float(each)\n",
    "            avg_l  = ((rsi_dict[name][1].loc[length - 1, y] * (each - 1.)) + down) / float(each)\n",
    "            rsi_dict[each][0][y].append(avg_g)\n",
    "            rsi_dict[each][1][y].append(avg_l)\n",
    "            \n",
    "            if avg_l != 0:\n",
    "                rs = avg_g / avg_l\n",
    "                rsi.append(100. - (100. / (1. + rs)))\n",
    "            else:\n",
    "                rsi.append(100.)\n",
    "            y += 1\n",
    "                \n",
    "        rsi_list[x] = rsi\n",
    "        x += 1\n",
    "    return rsi_list, rsi_dict\n",
    "\n",
    "def vol_ind(mylist, periods):\n",
    "    vol_list = [[] for i in range(59)]\n",
    "    for x in mylist:\n",
    "        vol = []\n",
    "        le  = len(mylist[x])\n",
    "        \n",
    "        for each in periods[:8]:\n",
    "            vola = ((mylist[x][le-each:] / mylist[x][le-each:].shift(1) - 1.).std() * np.sqrt(each))[0]\n",
    "            vol.append(vola)\n",
    "        \n",
    "        vol_list[x] = vol\n",
    "    return vol_list\n",
    "\n",
    "def bol_ind(mylist, periods):\n",
    "    bol_list = [[] for i in range(59)]\n",
    "    for x in mylist:\n",
    "        bol     = []\n",
    "        length  = len(mylist[x])\n",
    "        last_cl = mylist[x].loc[length-1, 0]\n",
    "        \n",
    "        for each in periods[:8]:\n",
    "            rm   = mylist[x][length - each:][0].mean()\n",
    "            rstd = mylist[x][length - each:][0].std()\n",
    "            uppr = rm + rstd * 2.\n",
    "            bol.append((last_cl - rm) / (uppr - rm))\n",
    "            \n",
    "        bol_list[x] = bol\n",
    "    return bol_list\n",
    "\n",
    "def mom_ind(mylist, periods):\n",
    "    mom_list = [[] for i in range(59)]\n",
    "    for x in mylist:\n",
    "        mom = []\n",
    "        length = len(mylist[x])\n",
    "        last_cl = mylist[x].loc[length-1, 0]\n",
    "        \n",
    "        for each in periods[:8]:\n",
    "            mom.append((last_cl / mylist[x].loc[length - each - 1, 0]) - 1.)\n",
    "            \n",
    "        mom_list[x] = mom\n",
    "    return mom_list\n",
    "\n",
    "def adx_ind(tickers, mylist, highlowcloselist, day_high, day_low, adx_d, periods):\n",
    "    x = 0\n",
    "    adx_list = [[] for i in range(59)]\n",
    "    for name in tickers:\n",
    "        adx      = []\n",
    "        last_day = mylist[x][len(mylist[x])-391, 0]\n",
    "        trn      = max((day_high[x]-day_low[x]), abs(day_high[x]-last_day), abs(day_low[x]-last_day))\n",
    "        posdm    = day_high[x] - highlowcloselist[name].loc[len(highlowcloselist[name])-1, 0]\n",
    "        negdm    = day_low[x]  - highlowcloselist[name].loc[len(highlowcloselist[name])-1, 1]\n",
    "        \n",
    "        if posdm < 0:\n",
    "            posdm = 0\n",
    "        if mindm < 0:\n",
    "            negdm = 0\n",
    "        \n",
    "        y = 0\n",
    "        for each in periods[:8]:\n",
    "            le   = len(adx_d[name][y])\n",
    "            tr   = adx_d[name][y].loc[le-1, 0] - (adx_d[name][y].loc[le-1, 0] / float(each)) + trn\n",
    "            pdm  = adx_d[name][y].loc[le-1, 1] - (adx_d[name][y].loc[le-1, 1] / float(each)) + posdm\n",
    "            ndm  = adx_d[name][y].loc[le-1, 2] - (adx_d[name][y].loc[le-1, 2] / float(each)) + negdm\n",
    "            pdi  = (pdm / tr) * 100. \n",
    "            ndi  = (ndm / tr) * 100.\n",
    "            dx   = (pdi - ndi) / (pdi + ndi)\n",
    "            nadx = ((adx_d[name][y].loc[le-1, 3] * 13.) + dx) / float(each)\n",
    "            \n",
    "            adx_d[name][y].append([tr, pdm, ndm, nadx])\n",
    "            adx.append(nadx)\n",
    "            y += 1\n",
    "        \n",
    "        adx_list[x] = adx\n",
    "        x += 1\n",
    "    return adx_list, adx_d\n",
    "\n",
    "def kd_ind(tickers, mylist, highlowcloselist, kd_dict, periods):\n",
    "    x = 0\n",
    "    kd_list = [[] for i in range(59)]\n",
    "    for name in tickers:\n",
    "        kd      = []\n",
    "        le      = len(highlowcloselist[name])\n",
    "        last_cl = mylist[x].loc[le-1, 0]\n",
    "        \n",
    "        y = 0\n",
    "        for each in periods[:8]:\n",
    "            length   = len(kd_dict[name][y])\n",
    "            prev_min = min(highlowcloselist[name][1][le - each:])\n",
    "            prev_max = max(highlowcloselist[name][0][le - each:])\n",
    "            cl       = last_cl  - prev_min\n",
    "            hl       = prev_max - prev_min\n",
    "            k        = (cl / hl) * 100.\n",
    "            d        = (kd_dict[name].loc[length-1, y] + kd_dict[name].loc[length-391, y] + k) / 3.\n",
    "            \n",
    "            kd_dict[name][y].append(k)\n",
    "            kd.append(d)\n",
    "            y += 1\n",
    "        \n",
    "        kd_list[x] = kd\n",
    "        x += 1\n",
    "    return kd_list, kd_dict\n",
    "\n",
    "def aroon_ind(mylist, periods):\n",
    "    aroon_list = [[] for i in range(59)]\n",
    "    for x in mylist:\n",
    "        aroon  = []\n",
    "        length = len(mylist[x])\n",
    "        \n",
    "        for each in periods[2:10]\n",
    "            aroon_up   = ((each - (length - mylist[x][length - each:][0].idxmax())) / float(each)) * 100.\n",
    "            aroon_down = ((each - (length - mylist[x][length - each:][0].idxmin())) / float(each)) * 100.\n",
    "            aroon.append(aroon_up - aroon_down)\n",
    "        \n",
    "        aroon_list[x] = aroon\n",
    "    return aroon_list\n",
    "            \n",
    "def sma_ind(mylist, periods):\n",
    "    sma_list = [[] for i in range(59)]\n",
    "    for x in mylist:\n",
    "        sma    = []\n",
    "        length = len(mylist[x])\n",
    "        \n",
    "        for each in periods[6:14]:\n",
    "            sma.append(mylist[x][length - each:].mean())\n",
    "        \n",
    "        sma_list[x] = sma\n",
    "    return sma_list\n",
    "\n",
    "def pe_ind(mylist, periods):\n",
    "    pe_list = [[] for i in range(59)]\n",
    "    for x in mylist:\n",
    "        pe      = []\n",
    "        length  = len(mylist[x])\n",
    "        last_cl = mylist[x].loc[length-1, 0]\n",
    "\n",
    "        for each in periods[7:]:\n",
    "            pe.append(last_cl / last_cl - mylist[x].loc[length - each - 1, 0])\n",
    "\n",
    "        pe_list[x] = pe\n",
    "    return pe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data_ready():\n",
    "    \"\"\"\n",
    "    First function called at the beginning of the trading day. It first figures out what day\n",
    "    it is, the previous trading day and the next trading day. It opens the previous days datafile\n",
    "    that will be used to calculate intra-day daily return values.\n",
    "    \n",
    "    Setup the stock ticker symbols for both the Google and Yahoo servers, the Google for real-time\n",
    "    stock data, and the yahoo for previous high/low values. Then call the setup function to create\n",
    "    the dictionaries for several of the indicators getting the previous data for these indicators\n",
    "    by using the historical stock data brought in from the pickled file called yahoo. Then put all\n",
    "    these newly created dictionaries in a list called attributes.\n",
    "    \n",
    "    Then find the companies with upcoming stock splits and dividends and compare them to our list\n",
    "    to see if we have any companies with upcoming dates so we can adjust for them. As of right now\n",
    "    (2016-06-11), the function to adjust has not been created but will be in the future.\n",
    "    \n",
    "    Finally call the company_news() function to retrieve info for each company and index/sector for\n",
    "    new articles on them. As of right now the function to automatically read the data, and convert the\n",
    "    data to extra information to help in prediction, has not been created but will be created soon. It\n",
    "    will utilize a neural network to comprehend the data, possible using Google's new Parsy McParseFace\n",
    "    module just released that is built for NLP(Natural Language Processing).\n",
    "    \"\"\"\n",
    "    \n",
    "    cl          = open('smallcompanyclosingslist.pickle','rb')\n",
    "    ye          = open('2016-06-09dayendtickerlist.pickle', 'rb')\n",
    "    yahoo       = open('historicalyahoodata.pickle', 'rb')\n",
    "    closings    = pickle.load(cl)\n",
    "    yesterday   = pickle.load(ye)\n",
    "    yahoo_data  = pickle.load(yahoo)\n",
    "    cl.close()\n",
    "    ye.close()\n",
    "    yahoo.close()\n",
    "    \n",
    "    # Ticker symbols for both yahoo and google servers\n",
    "    new_tickers    = ['BPOP','FITB','HBAN','CMCSA','EBAY',\n",
    "                      'AAPL','AMAT','BRCD','CSCO','GOOG','INTC',\n",
    "                      'LVLT','MSFT','MU','NVDA','ORCL','QCOM',\n",
    "                      'SIRI','SNDK','WIN','YHOO','BHP','BP',\n",
    "                      'RIO','XOM','GE','F','MO','XRX','GS','JPM',\n",
    "                      'LYG','MS','RF','USB','WFC','MRK','PFE','NYSE:LMT',\n",
    "                      'MGM','AMD','EMC','GLW','HPQ','S','T',\n",
    "                      'NYSEARCA:USO','NYSEARCA:GLD','NYSEARCA:SPY',\n",
    "                      'INDEXDJX:.DJI','INDEXSP:.INX','INDEXNASDAQ:.IXIC',\n",
    "                      'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "    \n",
    "    yahoo_tickers  = ['BPOP','FITB','HBAN','CMCSA','EBAY',\n",
    "                      'AAPL','AMAT','BRCD','CSCO','GOOG','INTC',\n",
    "                      'LVLT','MSFT','MU','NVDA','ORCL','QCOM',\n",
    "                      'SIRI','SNDK','WIN','YHOO','BHP','BP',\n",
    "                      'RIO','XOM','GE','F','MO','XRX','GS','JPM',\n",
    "                      'LYG','MS','RF','USB','WFC','MRK','PFE','LMT',\n",
    "                      'MGM','AMD','EMC','GLW','HPQ','S','T',\n",
    "                      'USO', 'GLD', 'SPY',\n",
    "                      '%5EDJI', '^GSPC', '%5EIXIC', \n",
    "                      'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "    \n",
    "    # All period lengths for indicators. days * 390 intervals per day\n",
    "    #################################################################\n",
    "    # kd/voli/mom/rsi/adx/cci/bol = 3-20days, aroon = 8-30days, sma = 14-100days, pe = 16-252days \n",
    "    # In order: 3, 5, 8, 10, 12, 14, 16, 20, 25, 30, 40, 50, 100, 252 days\n",
    "    period_list  = [1170, 1950, 3120, 3900, 4680, 5460, 6240, 7800, 9750, 11700, 15600, 19500, 39000, 98280]\n",
    "    #\n",
    "    # macd_small_period  = 3-14 days, macd_large_period  = 12-30 days\n",
    "    # In order: 3, 5, 8, 10, 12, 14, 16, 20, 26, 30, 40  \n",
    "    period_list2 = [1170,  1950,  3120, 3900, 4680,  5460,  6240, 7800, 10140, 11700, 15600]\n",
    "    #################################################################\n",
    "    \n",
    "    # Setup attribute dictionaries\n",
    "    highlowcloselist = highlowcloselist_create(yahoo_data, yahoo_tickers, period_list)\n",
    "    adx_dict         = adx_create(highlowcloselist, yahoo_tickers, period_list)\n",
    "    rsi_dict         = rsi_create(highlowcloselist, yahoo_tickers, period_list)\n",
    "    macd_dict        = macd_create(highlowcloselist, yahoo_tickers, period_list2)\n",
    "    aroon_dict       = aroon_create(highlowcloselist, yahoo_tickers, period_list)\n",
    "    vol_dict         = volatility_create(highlowcloselist, yahoo_tickers, period_list)\n",
    "    cci_dict         = cci_create(highlowcloselist, yahoo_tickers, period_list)\n",
    "    kd_ratio_dict    = kd_ratio_create(highlowcloselist, yahoo_tickers, period_list)\n",
    "    attributes       = [highlowcloselist, adx_dict, rsi_dict, macd_dict, kd_ratio_dict]\n",
    "    \n",
    "    # Find companies with upcoming dividends and stock splits\n",
    "    div_dates   = 'http://www.nasdaq.com/dividend-stocks/dividend-calendar.aspx'\n",
    "    split_dates = 'http://www.nasdaq.com/markets/upcoming-splits.aspx'\n",
    "    dividends   = pd.DataFrame(dividend_find(div_dates), columns=['Symbol','ExDiv','Div','RecDate','PayDate'])\n",
    "    splits      = pd.DataFrame(stock_splits(split_dates),columns=['Symbol','ExDate','Ratio','Payable'])\n",
    "    divs        = dividends['Symbol'].values\n",
    "    spls        = splits['Symbol'].values\n",
    "    \n",
    "    # Print out which companies have stock splits and dividends upcoming, if any\n",
    "    for each in divs:\n",
    "        if each in new_tickers:\n",
    "            print each, \"DIV\"\n",
    "    for each2 in spls:\n",
    "        if each2 in new_tickers:\n",
    "            print each2, \"SPLITS\"\n",
    "            \n",
    "    #todays_news  = company_news(tickers)\n",
    "    #news_file = today_trading+'daynews.pickle'\n",
    "    #tn = open(news_file, 'wb')\n",
    "    #pickle.dump(todays_news, tn)\n",
    "    #tn.close()\n",
    "    return new_tickers, closings, outlist, yesterday, attributes, period_list, period_list2#, todays_news\n",
    "\n",
    "def run_program():\n",
    "    \"\"\"\n",
    "    Function will wait until the start of the training day(9:30AM) and start the\n",
    "    process about 2 minute before start by calling get_data_ready() which takes roughly\n",
    "    2 minutes to process everything so it starts recording and calculating in real-time\n",
    "    at about 9:30.\n",
    "    \n",
    "    Until the time is between 9:28 and 9:30, it will check if we're in that range, else\n",
    "    it sleeps for 60 seconds and does this until its called.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        time.sleep(60)\n",
    "        now      = datetime.datetime.now()\n",
    "        now_time = now.time()\n",
    "        \n",
    "        if now_time >= datetime.time(9,28) and now_time <= datetime.time(9,30):\n",
    "            ts, cls, olist, yest, attrs, p, p2 = get_data_ready()\n",
    "            tlist, dlist, combined, last_cl    = real_time_quotes(ts, cls, olist, yest, attrs, p, p2)\n",
    "            break\n",
    "\n",
    "    return tlist, dlist, combined, last_cl\n",
    "    \n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tickerlist, dailylist, combined, closings = run_program()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def day_end_operations(tickers, combined, last_close):\n",
    "    \"\"\"\n",
    "    An end of day function called once the trading day is over to update our pickled\n",
    "    files filled with daily closing prices and indicator values.\n",
    "    \n",
    "    Open our pickled files, read them in, and add our latest closing prices and \n",
    "    indicator values to them to show the day end values.\n",
    "    \n",
    "    Finally once new values are appending, write the files back to disk.\n",
    "    \"\"\"\n",
    "    \n",
    "    # closings represents our dictionary filled with each companies daily closing\n",
    "    #  prices for its entirety trading.\n",
    "    # stats represents our calculated daily indicator values since the all indexes\n",
    "    #  were available which is about since 2004.\n",
    "    cl       = open('smallcompanyclosingslist.pickle','rb')\n",
    "    fe       = open('smallcompanyfeatureslist.pickle','rb')\n",
    "    closings = pickle.load(cl)\n",
    "    stats    = pickle.load(fe)\n",
    "    cl.close()\n",
    "    fe.close()\n",
    "    \n",
    "    try:\n",
    "        i = 0\n",
    "        for each in tickers:\n",
    "\n",
    "            date           = datetime.date.today()\n",
    "            day_end_close  = last_close[i]\n",
    "            last_stats     = combined[i]\n",
    "            close_df       = pd.DataFrame([day_end_close], index=[date])\n",
    "            stats_df       = pd.DataFrame(last_stats, index=[date])\n",
    "            closings[each] = closings[each].append(close_df)  \n",
    "            stats[each]    = stats[each].append(stats_df)\n",
    "            i += 1  \n",
    "\n",
    "        cl2 = open('smallcompanyclosingslist.pickle','wb')\n",
    "        fe2 = open('smallcompanyfeatureslist.pickle','wb')\n",
    "        pickle.dump(closings,cl2)\n",
    "        pickle.dump(stats,fe2)\n",
    "        cl2.close()\n",
    "        fe2.close()  \n",
    "    except:\n",
    "            print each\n",
    "            raise \n",
    "    \n",
    "    return closings, stats\n",
    "\n",
    "print \"Done\"\n",
    "\n",
    "def yahoo_historical_retrieval(yahoo_tickers):\n",
    "    historical, b = {}, 0\n",
    "    \n",
    "    for each in yahoo_tickers:\n",
    "        try:\n",
    "            test = Share(each)\n",
    "            history = test.get_historical('2011-07-01','2016-06-18')\n",
    "            historical[each] = history\n",
    "        except:\n",
    "            print each\n",
    "            raise\n",
    "    \n",
    "        stdout.write(\"\\r%d\" % b)\n",
    "        stdout.flush()\n",
    "        b += 1\n",
    "    return historical\n",
    "\n",
    "def adjust_yahoo(historical, yahoo_tickers):\n",
    "    adj_historical = {}\n",
    "    \n",
    "    for each in yahoo_tickers:\n",
    "        date, adj_close, close = [], [], []\n",
    "\n",
    "        for x in xrange(0, len(historical[each])):\n",
    "            date.append(historical[each][x]['Date'])\n",
    "            adj_close.append(float(historical[each][x]['Adj_Close'].replace(',','')))\n",
    "            close.append(float(historical[each][x]['Close'].replace(',','')))\n",
    "\n",
    "        df         = pd.DataFrame([adj_close, close, date]).T \n",
    "        df.columns = ['Adj_Close', 'Close', 'Date']\n",
    "        df         = df.set_index('Date')\n",
    "\n",
    "        adj_historical[each] = df\n",
    "    return adj_historical\n",
    "\n",
    "def unadj_intra():\n",
    "    unadj_intr = {}\n",
    "    \n",
    "    for file in os.listdir(\"C:/Users/JohnSmith2/version-control/Projects/projects/trading/intraday\"):\n",
    "        if file.endswith(\".csv\"):\n",
    "            name = str(file)[:str(file).find('_')]\n",
    "            \n",
    "            if (name != 'DJI') or (name != 'GSPC') or (name != 'IXIC'):\n",
    "                name = name\n",
    "            else:\n",
    "                name = '^' + name \n",
    "            \n",
    "            path = \"intraday/\" + str(file)\n",
    "            df   = pd.read_csv(path, sep=';', decimal=',')\n",
    "            df   = df[['timestamp','high','low','close']]\n",
    "            \n",
    "            unadj_intr[name] = df\n",
    "    return unadj_intr\n",
    "\n",
    "def adj_intra(unadj_intra, adj_yahoo):\n",
    "    adj_intr = {}\n",
    "    \n",
    "    for key,value in unadj_intra.iteritems():\n",
    "        value  = value.set_index('timestamp')\n",
    "        index2 = value.index\n",
    "        prev   = 0\n",
    "        \n",
    "        for x in xrange(1,len(value)):\n",
    "            if index2[x][8:10] != index2[x-1][8:10]:\n",
    "                value[prev:x] *= (adj_yahoo[key].loc[index2[x][:10]]['Adj_Close'] / \n",
    "                                  adj_yahoo[key].loc[index2[x][:10]]['Close'])\n",
    "                prev = x\n",
    "        \n",
    "        adj_intr[key] = value\n",
    "    return adj_intr\n",
    "\n",
    "def adjust_high_lows(adjusted_intra):\n",
    "    new_adjusted_intra = {}\n",
    "    \n",
    "    for key,value in adjusted_intra.iteritems():\n",
    "        highs  = value['high'].values.tolist()\n",
    "        lows   = value['low'].values.tolist()\n",
    "        closes = value['close'].values.tolist()\n",
    "        index  = value.index\n",
    "        prev   = 0\n",
    "\n",
    "        for x in xrange(1,len(highs)):\n",
    "            if index[x][8:10] == index[x-1][8:10]:\n",
    "                highs[x] = max(highs[prev:x+1])\n",
    "                lows[x]  = min(lows[prev:x+1])\n",
    "            else:\n",
    "                prev = x\n",
    "\n",
    "        df         = pd.DataFrame([index,highs,lows,closes]).T\n",
    "        df.columns = ['Time','Highs','Lows','Closes']\n",
    "        df         = df.set_index(['Time'])\n",
    "\n",
    "        new_adjusted_intra[key] = df\n",
    "    return new_adjusted_intra\n",
    "\n",
    "yahoo_tickers  = ['BPOP','FITB','HBAN','CMCSA','EBAY',\n",
    "                  'AAPL','AMAT','BRCD','CSCO','GOOG','INTC',\n",
    "                  'LVLT','MSFT','MU','NVDA','ORCL','QCOM',\n",
    "                  'SIRI','SNDK','WIN','YHOO','BHP','BP',\n",
    "                  'RIO','XOM','GE','F','MO','XRX','GS','JPM',\n",
    "                  'LYG','MS','RF','USB','WFC','MRK','PFE','LMT',\n",
    "                  'MGM','AMD','EMC','GLW','HPQ','S','T',\n",
    "                  'USO', 'GLD', 'SPY',\n",
    "                  '^DJI', '^GSPC', '^IXIC', \n",
    "                  'XLY','XLP','XLE','XLF','XLV','XLI','XLK']\n",
    "historical     = yahoo_historical_retrieval(yahoo_tickers)\n",
    "adj_historical = adjust_yahoo(historical, yahoo_tickers)\n",
    "unadj_intr     = unadj_intra()\n",
    "adj_intr       = adj_intra(unadj_intr, adj_historical)\n",
    "new_adjusted   = adjust_high_lows(adj_intr)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
