{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import os\n",
    "import math\n",
    "import Quandl\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as spo\n",
    "import matplotlib.pyplot as plt\n",
    "from math import exp \n",
    "\n",
    "def retrieve_data():\n",
    "    \"\"\"Retrieve the dictionaries filled with each companies dataframes in\n",
    "       both the s&p 500 and dow jones indexes, and the third dictionary\n",
    "       contains several measures of features. The data is taken from pickled\n",
    "       data files that were retrieved with an earlier retrieve data function\n",
    "       that retrieved the data from the Quandl server. If you need to add more\n",
    "       data, you need to use the previous retrieval method which will be listed\n",
    "       soon. You can also use Quandl.get(\"CODE\") where CODE is a specific quandl\n",
    "       code\"\"\"\n",
    "    # Read from file\n",
    "    adj_closing = open('adjclosingpricesfile.pickle', 'rb')\n",
    "    norm_closing = open('closingpricesfile.pickle', 'rb')\n",
    "    bol_bands = open('bolbandsfile.pickle', 'rb')\n",
    "    momentum = open('momentumfile.pickle', 'rb')\n",
    "    pe_ratio = open('peratiofile.pickle', 'rb')\n",
    "    extra_bol_bands = open('extrabollingers.pickle', 'rb')\n",
    "    extra_momentums = open('extramomentums.pickle', 'rb')\n",
    "    extra_pe_ratios = open('extraperatios.pickle', 'rb')\n",
    "    extra_adj_close = open('extrajusteddict.pickle', 'rb')\n",
    "    extra_norm_close = open('extrnormaldict.pickle', 'rb')\n",
    "    testing_ground = open('testingground.pickle', 'rb')\n",
    "    features = open('featfile.pickle', 'rb')\n",
    "    \n",
    "    # Store the retrieved dictionaries in variables\n",
    "    adjCloseDict = pickle.load(adj_closing)\n",
    "    normCloseDict = pickle.load(norm_closing)\n",
    "    bolBandsDict = pickle.load(bol_bands)\n",
    "    momentumDict = pickle.load(momentum)\n",
    "    peRatioDict = pickle.load(pe_ratio)\n",
    "    extrBolBandsDict = pickle.load(extra_bol_bands)\n",
    "    extrMomentumDict = pickle.load(extra_momentums)\n",
    "    extrPeRatioDict = pickle.load(extra_pe_ratios)\n",
    "    extraAdjClose = pickle.load(extra_adj_close)\n",
    "    extraNormClose = pickle.load(extra_norm_close)\n",
    "    testingGround = pickle.load(testing_ground)\n",
    "    featureDict = pickle.load(features)\n",
    "    \n",
    "    # Close the files\n",
    "    adj_closing.close()\n",
    "    norm_closing.close()\n",
    "    bol_bands.close()\n",
    "    momentum.close()\n",
    "    pe_ratio.close()\n",
    "    extra_bol_bands.close()\n",
    "    extra_momentums.close()\n",
    "    extra_pe_ratios.close()\n",
    "    extra_adj_close.close()\n",
    "    extra_norm_close.close()\n",
    "    testing_ground.close()\n",
    "    features.close()\n",
    "    \n",
    "    adjusted_dict_array = [adjCloseDict, normCloseDict]\n",
    "    technical_indicators = [bolBandsDict, momentumDict, peRatioDict]\n",
    "    extra_indicators = [extrBolBandsDict, extrMomentumDict, extrPeRatioDict]\n",
    "    extra_closings = [extraAdjClose, extraNormClose]\n",
    "    other_stuff = [testingGround, featureDict]\n",
    "    \n",
    "    return adjusted_dict_array, technical_indicators, extra_indicators, extra_closings, other_stuff\n",
    "adjusted_dict_array, technical_indicators, extra_indicators, extra_closings, other_stuff = retrieve_data()\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def retrieve_daily_returns(df):\n",
    "    dailyReturnsDict = {}\n",
    "    for each_dict in df:\n",
    "        for each_key in each_dict.keys():\n",
    "            each_index = each_dict[each_key]\n",
    "            daily_returns = compute_daily_returns(each_index)\n",
    "            dailyReturnsDict[each_key] = daily_returns\n",
    "    return dailyReturnsDict\n",
    "\n",
    "def compute_daily_returns(df):\n",
    "    \"\"\"Compute and return the daily return values.\"\"\"\n",
    "    daily_returns = (df / df.shift(1)) - 1\n",
    "    daily_returns.ix[0,:] = 0 #Pandas leaves the 0th row full of NaNs\n",
    "    return daily_returns\n",
    "\n",
    "def sort_by_timestep(each_technical_indicators,newBollDicts):\n",
    "    momentumDict = each_technical_indicators[1]\n",
    "    peRatioDict = each_technical_indicators[2]\n",
    "    each_company_thresholds = {}\n",
    "    for each_dict in momentumDict.keys():\n",
    "        for each_company in momentumDict[each_dict].keys():\n",
    "            np1 = np.array(momentumDict[each_dict][each_company][21:])\n",
    "            np2 = np.array(peRatioDict[each_dict][each_company][21:])\n",
    "            np3 = np.array(newBollDicts[each_company][21:])\n",
    "            len1 = len(np1)\n",
    "            len2 = len(np2)\n",
    "            len3 = len(np3)\n",
    "            if len2 != len3:\n",
    "                if len2 > len3:\n",
    "                    np1 = np1[:len3]\n",
    "                    np2 = np2[:len3]\n",
    "                else:\n",
    "                    np3 = np3[:len2]\n",
    "            t = {}\n",
    "            step_size = np1.size/18\n",
    "            np1.sort()\n",
    "            np2.sort()\n",
    "            np3.sort()\n",
    "            for i in range(0, 18):\n",
    "                mom = np1[(i+1)*step_size]\n",
    "                pe = np2[(i+1)*step_size]\n",
    "                bol = np3[(i+1)*step_size]\n",
    "                t[i] = [mom,pe,bol]\n",
    "            each_company_thresholds[each_company] = t\n",
    "    return each_company_thresholds\n",
    "\n",
    "def descretize_indicators(technical_indicators, company_t, newBollDict):\n",
    "    momentumDict = technical_indicators[1]\n",
    "    peRatioDict = technical_indicators[2]\n",
    "    each_company_descretized = {}\n",
    "    each_group_length = {}\n",
    "    \n",
    "    for each_dict in momentumDict.keys():\n",
    "        for each_company in momentumDict[each_dict].keys():\n",
    "            momentum = pd.DataFrame(momentumDict[each_dict][each_company][21:])\n",
    "            peratio = pd.DataFrame(peRatioDict[each_dict][each_company][21:])\n",
    "            bollinger = pd.DataFrame(newBollDict[each_company][21:])\n",
    "\n",
    "            len1 = len(momentum)\n",
    "            len2 = len(peratio)\n",
    "            len3 = len(bollinger)\n",
    "            if len2 != len3:\n",
    "                if len2 > len3:\n",
    "                    momentum = momentum[:len3]\n",
    "                    peratio = peratio[:len3]\n",
    "                else:\n",
    "                    bollinger = bollinger[:len2]\n",
    "            peratio_index = peratio.index\n",
    "            bollinger = bollinger.set_index(peratio_index)\n",
    "            bollinger = bollinger.rename(columns = {0:'Bol'})\n",
    "            \n",
    "            grouped = momentum.join(peratio, how='outer', rsuffix='Pe')\n",
    "            grouped = grouped.join(bollinger, how='outer', rsuffix='Bol')\n",
    "\n",
    "            t = company_t[each_company]\n",
    "            ranges = [((-1000000, t[0][0]),( t[0][0], t[1][0]),( t[1][0], t[2][0]),( t[2][0], t[3][0]),\n",
    "                        (t[3][0], t[4][0]),( t[4][0], t[5][0]),( t[5][0], t[6][0]),( t[6][0], t[7][0]),\n",
    "                        (t[7][0], t[8][0]),( t[8][0], t[9][0]),( t[9][0],t[10][0]),(t[10][0],t[11][0]),\n",
    "                       (t[11][0],t[12][0]),(t[12][0],t[13][0]),(t[13][0],t[14][0]),(t[14][0],t[15][0]),\n",
    "                       (t[15][0],t[16][0]),(t[16][0],np.inf)),\n",
    "                      ((-1000000, t[0][1]),( t[0][1], t[1][1]),( t[1][1], t[2][1]),( t[2][1], t[3][1]),\n",
    "                        (t[3][1], t[4][1]),( t[4][1], t[5][1]),( t[5][1], t[6][1]),( t[6][1], t[7][1]),\n",
    "                        (t[7][1], t[8][1]),( t[8][1], t[9][1]),( t[9][1],t[10][1]),(t[10][1],t[11][1]),\n",
    "                       (t[11][1],t[12][1]),(t[12][1],t[13][1]),(t[13][1],t[14][1]),(t[14][1],t[15][1]),\n",
    "                       (t[15][1],t[16][1]),(t[16][1],np.inf)),\n",
    "                      ((-1000000, t[0][2]),( t[0][2], t[1][2]),( t[1][2], t[2][2]),( t[2][2], t[3][2]),\n",
    "                        (t[3][2], t[4][2]),( t[4][2], t[5][2]),( t[5][2], t[6][2]),( t[6][2], t[7][2]),\n",
    "                        (t[7][2], t[8][2]),( t[8][2], t[9][2]),( t[9][2],t[10][2]),(t[10][2],t[11][2]),\n",
    "                       (t[11][2],t[12][2]),(t[12][2],t[13][2]),(t[13][2],t[14][2]),(t[14][2],t[15][2]),\n",
    "                       (t[15][2],t[16][2]),(t[16][2],np.inf))]\n",
    " \n",
    "            thrshs, day_threshs = [],[]\n",
    "            for num in xrange(0,len(grouped)):\n",
    "                test = grouped.ix[num]\n",
    "                for each_variable,each_tuple_variable in zip(test,ranges):\n",
    "                    y = 0\n",
    "                    for each_tuple in each_tuple_variable:\n",
    "                        if each_tuple[0] <= each_variable <= each_tuple[1]:\n",
    "                            thrshs.append(y)\n",
    "                            break\n",
    "                        y += 1\n",
    "                day_threshs.append(thrshs)\n",
    "                thrshs = []\n",
    "            each_company_descretized[each_company] = day_threshs\n",
    "    return each_company_descretized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initialize_qtable(): \n",
    "    bands   = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "    momen   = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17] \n",
    "    peratio = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17] \n",
    "    action  = [-1,0,1]\n",
    " \n",
    "    q_values = {} \n",
    "    state_list = []\n",
    "    for each_band in bands:\n",
    "        for each_momentum in momen:\n",
    "            for each_pe in peratio:\n",
    "                for each_action in action: \n",
    "                    state = (('bands', each_band),('momentum', each_momentum),  \n",
    "                            ('peratio', each_pe), each_action) \n",
    "                    state_list.append(state) \n",
    "\n",
    "    for each in state_list: \n",
    "        q_values[each] = 0 \n",
    " \n",
    "    return q_values\n",
    "\n",
    "def lookup_actions(state, q_values): \n",
    "    action = [-1, 0, 1] \n",
    "    q_vals_list, random_list = [],[]\n",
    "     \n",
    "    momen  = state[0] \n",
    "    pe_r   = state[1]\n",
    "    bands  = state[2]\n",
    "     \n",
    "    for each in action:\n",
    "        q_val_state = (('bands', bands),('momentum', momen),\n",
    "                       ('peratio', pe_r),each)\n",
    "        q_vals = q_values[q_val_state] \n",
    "        q_vals_list.append([q_vals, each]) \n",
    "    max_action = max(q_vals_list) \n",
    "    \n",
    "    #Boltmann method \n",
    "    prob_list = []\n",
    "    choice_1 = q_vals_list[0][0]\n",
    "    choice_2 = q_vals_list[1][0]\n",
    "    choice_3 = q_vals_list[2][0]\n",
    "    if choice_1 > 650:\n",
    "        choice_1 = 650\n",
    "    if choice_2 > 650:\n",
    "        choice_2 = 650\n",
    "    if choice_3 > 650:\n",
    "        choice_3 = 650\n",
    "    \n",
    "    choices = [choice_1, choice_2, choice_3]\n",
    "    \n",
    "    q_sum_exp = exp(choice_1)+exp(choice_2)+exp(choice_3)\n",
    "    \n",
    "    for each, each_choice in zip(q_vals_list, choices): \n",
    "        boltzmann = exp(each_choice)/q_sum_exp \n",
    "        prob_list.append([boltzmann, each[1]])\n",
    "\n",
    "    a = [prob_list[0][0], prob_list[0][1]]  \n",
    "    b = [prob_list[1][0], prob_list[1][1]]  \n",
    "    c = [prob_list[2][0], prob_list[2][1]]  \n",
    "    q_range = [a,[b[0]+a[0], b[1]], [1,c[1]]] \n",
    " \n",
    "    x = random.uniform(0,1) \n",
    "    \n",
    "    if x <= q_range[0][0]: \n",
    "        choice = q_range[0][1] \n",
    "    elif q_range[0][0] < x <= q_range[1][0]: \n",
    "        choice = q_range[1][1] \n",
    "    else: \n",
    "        choice = q_range[2][1]\n",
    "        \n",
    "    return choice, max_action \n",
    "\n",
    "def update_policy(state, action, reward, q_values, next_input): \n",
    "    each_vals_list = [] \n",
    "    discount, alpha = 0.5, 0.5 \n",
    "\n",
    "    momen  = state[0] \n",
    "    pe_r   = state[1]\n",
    "    bands  = state[2]\n",
    "\n",
    "    q_val_state = (('bands', bands),('momentum', momen),\n",
    "                   ('peratio', pe_r), action)\n",
    "    q_state = q_values[q_val_state] \n",
    "\n",
    "    updated = next_input\n",
    "    choice, max_action = lookup_actions(updated,q_values)  \n",
    "\n",
    "    new_value = q_state*(1.-alpha) + alpha*(reward + (discount * max_action[0])) \n",
    "\n",
    "    q_values[q_val_state] = new_value\n",
    "    return q_values\n",
    "\n",
    "def compute_bolls(technical_indicators, adjusted_dict_array):\n",
    "    bol_bands = technical_indicators[0]\n",
    "    bol_list,bolBandsDict = [],{}\n",
    "    for each_dict in bol_bands.keys():\n",
    "        if each_dict in ['adjDowDict', 'adjSpDict']:\n",
    "            for each_comp in bol_bands[each_dict][0].keys():\n",
    "                for upp,low,rol,adj in zip(bol_bands[each_dict][0][each_comp],\n",
    "                                       bol_bands[each_dict][1][each_comp],\n",
    "                                       bol_bands[each_dict][2][each_comp],\n",
    "                                       adjusted_dict_array[0][each_dict][each_comp]):\n",
    "                    adj_rol = adj - rol\n",
    "                    bol_list.append(adj_rol)\n",
    "                bolBandsDict[each_comp] = bol_list\n",
    "                bol_list = []\n",
    "        else:\n",
    "            for each_comp in bol_bands[each_dict][0].keys():\n",
    "                for upp,low,rol,adj in zip(bol_bands[each_dict][0][each_comp],\n",
    "                                       bol_bands[each_dict][1][each_comp],\n",
    "                                       bol_bands[each_dict][2][each_comp],\n",
    "                                       adjusted_dict_array[1][each_dict][each_comp]):\n",
    "                    adj_rol = adj - rol\n",
    "                    bol_list.append(adj_rol)\n",
    "                bolBandsDict[each_comp] = bol_list\n",
    "                bol_list = []\n",
    "    return bolBandsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "newBollDict = compute_bolls(technical_indicators,adjusted_dict_array)\n",
    "threshold = sort_by_timestep(technical_indicators,newBollDict)\n",
    "company_inputs = descretize_indicators(technical_indicators,threshold,newBollDict)\n",
    "dailyReturnsDict = retrieve_daily_returns(adjusted_dict_array)\n",
    "\n",
    "newBollDict2 = compute_bolls(extra_indicators,extra_closings)\n",
    "threshold2 = sort_by_timestep(extra_indicators,newBollDict2)\n",
    "company_inputs2 = descretize_indicators(extra_indicators,threshold2,newBollDict2)\n",
    "dailyReturnsDict2 = retrieve_daily_returns(extra_closings)\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "q_values = initialize_qtable()\n",
    "try:\n",
    "    dailyReturnsDict['normNyseDict'].drop('Stifel Financial Corporation', axis=1, inplace=True)\n",
    "    dailyReturnsDict['normNasdDict'].drop('ModusLink Global Solutions', axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for each_repeat in xrange(0,2):\n",
    "    for each_company in company_inputs.keys():\n",
    "        if each_company in dailyReturnsDict['normNasdDict'].keys():\n",
    "            returns = np.array(dailyReturnsDict['normNasdDict'][each_company][21:])   \n",
    "        else:\n",
    "            returns = np.array(dailyReturnsDict['normNyseDict'][each_company][21:])\n",
    "\n",
    "        for rounds in xrange(0, 3999):\n",
    "            # Gather state \n",
    "            updated = company_inputs[each_company][rounds]\n",
    "            rewards = returns[rounds]\n",
    "            # TODO: Update state\n",
    "            choice, max_action = lookup_actions(updated, q_values) \n",
    "            # TODO: Select action according to your policy \n",
    "            action = choice\n",
    "            # Execute action and get reward \n",
    "            if action != 0:\n",
    "                reward = action*rewards\n",
    "            else:\n",
    "                reward = rewards\n",
    "            # TODO: Learn policy based on state, action, reward \n",
    "            #print \"LearningAgent.update():inputs={},action={},reward={}\".format(updated,action,reward)#[debug]\n",
    "            next_input = company_inputs[each_company][rounds+1]\n",
    "            q_values = update_policy(updated, action, reward, q_values, next_input)\n",
    "            \n",
    "try:\n",
    "    dailyReturnsDict2['normNasdDict'].drop('Central Valley Community Bancorp', axis=1, inplace=True)\n",
    "    dailyReturnsDict2['normNasdDict'].drop('InterCloud Systems', axis=1, inplace=True)\n",
    "    dailyReturnsDict2['normNasdDict'].drop('One Horizon Group', axis=1, inplace=True)\n",
    "    dailyReturnsDict2['normNasdDict'].drop('Unity Bancorp', axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "for each_repeat in xrange(0,2):\n",
    "    for each_company2 in company_inputs2.keys():\n",
    "        if each_company2 in dailyReturnsDict2['normNasdDict'].keys():\n",
    "            returns2 = np.array(dailyReturnsDict2['normNasdDict'][each_company2][21:])   \n",
    "        elif each_company2 in dailyReturnsDict2['normNyseDict'].keys():\n",
    "            returns2 = np.array(dailyReturnsDict2['normNyseDict'][each_company2][21:])\n",
    "        elif each_company2 in dailyReturnsDict2['adjDowDict'].keys():\n",
    "            returns2 = np.array(dailyReturnsDict2['adjDowDict'][each_company2][21:])\n",
    "        else:\n",
    "            returns2 = np.array(dailyReturnsDict2['adjSpDict'][each_company2][21:])\n",
    "   \n",
    "        for rounds2 in xrange(0, len(returns2)):\n",
    "            try:\n",
    "                updated2 = company_inputs2[each_company2][rounds2]\n",
    "                rewards2 = returns2[rounds2]\n",
    "                choice2, max_action2 = lookup_actions(updated2, q_values)  \n",
    "                action2 = choice2\n",
    "                if action2 != 0:\n",
    "                    reward2 = action2*rewards2\n",
    "                else:\n",
    "                    reward2 = rewards2\n",
    "                next_input2 = company_inputs2[each_company2][rounds2+1]\n",
    "                q_values = update_policy(updated2, action2, reward2, q_values, next_input2)\n",
    "            except:\n",
    "                pass\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "otherDict = other_stuff[0]\n",
    "featureDict = other_stuff[1]\n",
    "bols = otherDict[0]\n",
    "moms = otherDict[1]\n",
    "pes = otherDict[2]\n",
    "dail = otherDict[3]\n",
    "testing = [bols,moms,pes]\n",
    "thresholds3 = sort_by_timestep(testing,)\n",
    "newBollDict3 = compute_bolls(testing)\n",
    "company_inputs3 = descretize_indicators(testing, thresholds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
