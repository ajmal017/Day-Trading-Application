{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def retrieve_codes():\n",
    "    \"\"\"Convert a csv file full of name and Quandl codes for the Dow Jones top 30 companies,\n",
    "       as well as the feature codes to a dataframe for further processing in \n",
    "       retrieve__data()\"\"\" \n",
    "    sp500_codes = pd.read_csv(\"C:/Users/JohnSmith2/Downloads/SP500.csv\")\n",
    "    dow_jones_codes = pd.read_csv(\"C:/Users/JohnSmith2/Downloads/dowjonesA.csv\")\n",
    "    features_codes = pd.read_csv(\"C:/Users/JohnSmith2/Downloads/features.csv\") \n",
    "    nasd_codes = pd.read_csv(\"C:/Users/JohnSmith2/Downloads/NASDAQComposite.csv\")\n",
    "    nyse_codes = pd.read_csv(\"C:/Users/JohnSmith2/Downloads/NYSEComposite.csv\")\n",
    "    feat_df = pd.DataFrame(features_codes)\n",
    "    dj_df = pd.DataFrame(dow_jones_codes)\n",
    "    sp_df = pd.DataFrame(sp500_codes)\n",
    "    nasd_df = pd.DataFrame(nasd_codes)\n",
    "    nyse_df = pd.DataFrame(nyse_codes)\n",
    "    dj_df = dj_df.ix[:,['name','free_code']]\n",
    "    sp_df = sp_df.ix[:,['name','free_code']]\n",
    "    nasd_df = nasd_df.ix[:,['name','free_code']]\n",
    "    nyse_df = nyse_df.ix[:,['name','free_code']]\n",
    "    return dj_df, sp_df, feat_df, nasd_df, nyse_df\n",
    "def retrieve_qunadl_data(dj_df, sp_df, feat_df, nasd_df, nyse_df):\n",
    "    \"\"\"Convert both the dow jones and features dataframes of names and codes and download each set\n",
    "        of data for each name/code pair into a seperate dataframe from the Quandl server. Take all \n",
    "        of these dataframes and put them into dictionaries, one for the dow jones info, the other\n",
    "        for the feature information.\"\"\" \n",
    "    dowJonesDict,sp500Dict,featuresDict,nasdDict,nyseDict = {},{},{},{},{}   \n",
    "    start = time.time()\n",
    "    for name, value in zip(sp_df['name'], sp_df['free_code']):\n",
    "        each = Quandl.get(value, trim_start=\"2016-04-15\", trim_end=\"2016-04-15\",\n",
    "                          authtoken=\"gEC9xAKi4avigPpoQPX1\")\n",
    "        df = pd.DataFrame(each)\n",
    "        sp500Dict[name] = df\n",
    "    end = time.time()\n",
    "    sptime = end - start\n",
    "    print \"sptime\", sptime, \"seconds for retrieval\"    \n",
    "    start2 = time.time()\n",
    "    for dow_name, dow_value in zip(dj_df['name'], dj_df['free_code']):\n",
    "        each_dow = Quandl.get(dow_value, trim_start=\"2010-04-15\", trim_end=\"2016-04-15\", \n",
    "                                authtoken=\"gEC9xAKi4avigPpoQPX1\")\n",
    "        d_df = pd.DataFrame(each_dow)\n",
    "        dowJonesDict[dow_name] = d_df\n",
    "    end2 = time.time()\n",
    "    dowtime = end2 - start2\n",
    "    print \"dowtime\", dowtime, \"seconds for retrieval\"   \n",
    "    start3 = time.time()\n",
    "    for feat_name, feat_value in zip(feat_df['name'], feat_df['free_code']):\n",
    "        each_feat = Quandl.get(feat_value, trim_start=\"2010-04-15\", trim_end=\"2016-04-15\", \n",
    "                                authtoken=\"gEC9xAKi4avigPpoQPX1\")\n",
    "        f_df = pd.DataFrame(each_feat)\n",
    "        featuresDict[feat_name] = f_df\n",
    "    end3 = time.time()\n",
    "    feattime = end3 - start3\n",
    "    print\"feattime\", feattime, \"seconds for retrieval\"   \n",
    "    i = 0\n",
    "    for nasd_name, nasd_value in zip(nasd_df['name'], nasd_df['free_code']):\n",
    "        i += 1\n",
    "        print i, nasd_name\n",
    "        each = Quandl.get(nasd_value, trim_start=\"2016-04-15\", trim_end=\"2016-04-15\",\n",
    "                        authtoken=\"gEC9xAKi4avigPpoQPX1\")\n",
    "        df = pd.DataFrame(each)\n",
    "        nasdDict[name] = df\n",
    "    i = 0\n",
    "    for nyse_name, nyse_value in zip(nyse_df['name'], nyse_df['free_code']):\n",
    "        i += 1\n",
    "        print i, nyse_name\n",
    "        each = Quandl.get(nyse_value, trim_start=\"2016-04-15\", trim_end=\"2016-04-15\",\n",
    "                        authtoken=\"gEC9xAKi4avigPpoQPX1\")\n",
    "        df = pd.DataFrame(each)\n",
    "        nyseDict[name] = df\n",
    "    return dowJonesDict, sp500Dict, featuresDict, nasdDict, nyseDict\n",
    "def create_adj_vol_and_close_dfs(dateAdjDowDict,dateAdjSp500Dict,dateAdjNasdDict,dateAdjNyseDict):\n",
    "    \"\"\"Take the dow jones dataframes and create dataframe which contain only the\n",
    "       adjusted volume and adjusted closing price data. Each dataframe will contain\n",
    "       all 30 companies going across, and time going down for the past 6 years of \n",
    "       data.\"\"\"\n",
    "    adjustedDicts,normalDicts = {},{}\n",
    "    # Make Dow Jones adjusted closing price dataframe with dates as index and\n",
    "    # companies as columns\n",
    "    i = True\n",
    "    for each in dateAdjDowDict.keys():\n",
    "        if i == True: # signifies first dictionary entry\n",
    "            df = dateAdjDowDict[each]\n",
    "            adj_close_df = df[['Adj. Close']].rename(columns={'Adj. Close': each})\n",
    "            i = False\n",
    "        else:\n",
    "            df = dateAdjDowDict[each]\n",
    "            next_adj_close_df = df[['Adj. Close']].rename(columns={'Adj. Close': each})\n",
    "            adj_close_df = adj_close_df.join(next_adj_close_df, how='outer')   \n",
    "    adjustedDicts['adjDowDict'] = adj_close_df\n",
    "    # Make S&P 500 adjusted closing price dataframe with dates as index and\n",
    "    # companies as columns\n",
    "    i = True\n",
    "    for each in dateAdjSp500Dict.keys():\n",
    "        if i == True:\n",
    "            df = dateAdjSp500Dict[each]\n",
    "            adj_close_df = df[['Adj. Close']].rename(columns={'Adj. Close': each})\n",
    "            i = False\n",
    "        else:\n",
    "            df = dateAdjSp500Dict[each]\n",
    "            next_adj_close_df = df[['Adj. Close']].rename(columns={'Adj. Close': each})\n",
    "            adj_close_df = adj_close_df.join(next_adj_close_df, how='outer')  \n",
    "    adjustedDicts['adjSpDict'] = adj_close_df\n",
    "    # Make Nasdaq google-finance-styled closing price dataframe with dates as index and\n",
    "    # companies as columns\n",
    "    i = True\n",
    "    for each_norm in dateAdjNasdDict.keys():\n",
    "        if i == True:\n",
    "            norm_df = dateAdjNasdDict[each_norm]\n",
    "            norm_close_df = norm_df[['Close']].rename(columns={'Close': each_norm})\n",
    "            i = False\n",
    "        else:\n",
    "            norm_df = dateAdjNasdDict[each_norm]\n",
    "            next_norm_close_df = norm_df[['Close']].rename(columns={'Close': each_norm})\n",
    "            norm_close_df = norm_close_df.join(next_norm_close_df, how='outer')      \n",
    "    normalDicts['normNasdDict'] = norm_close_df\n",
    "    # Make Nasdaq google-finance-styled closing price dataframe with dates as index and\n",
    "    # companies as columns\n",
    "    i = True\n",
    "    for each_norm in dateAdjNyseDict.keys():\n",
    "        if i == True:\n",
    "            norm_df = dateAdjNyseDict[each_norm]\n",
    "            norm_close_df = norm_df[['Close']].rename(columns={'Close': each_norm})\n",
    "            i = False\n",
    "        else:\n",
    "            norm_df = dateAdjNyseDict[each_norm]\n",
    "            next_norm_close_df = norm_df[['Close']].rename(columns={'Close': each_norm})\n",
    "            norm_close_df = norm_close_df.join(next_norm_close_df, how='outer') \n",
    "    normalDicts['normNyseDict'] = norm_close_df      \n",
    "    return adjustedDicts, normalDicts\n",
    "def adj_for_stk_record_nums(dowJonesDict, sp500Dict, nasdDict, nyseDict):\n",
    "    dateAdjNasdDict,dateAdjNyseDict = {},{}\n",
    "    dateAdjSp500Dict,dateAdjDowDict = {},{}\n",
    "    for each_key in dowJonesDict.keys():\n",
    "        length = len(dowJonesDict[each_key])\n",
    "        value = dowJonesDict[each_key]\n",
    "        if length > 4000:\n",
    "            dateAdjDowDict[each_key] = value\n",
    "    for each_key2 in sp500Dict.keys():\n",
    "        length2 = len(sp500Dict[each_key2])\n",
    "        value2 = sp500Dict[each_key2]\n",
    "        if length2 > 4000:\n",
    "            dateAdjSp500Dict[each_key2] = value2\n",
    "    for each_key3 in nasdDict.keys():\n",
    "        length3 = len(nasdDict[each_key3])\n",
    "        value3 = nasdDict[each_key3]\n",
    "        if length3 > 4000:\n",
    "            dateAdjNasdDict[each_key3] = value3\n",
    "    for each_key4 in nyseDict.keys():\n",
    "        length4 = len(nyseDict[each_key4])\n",
    "        value4 = nyseDict[each_key4]\n",
    "        if length4 > 4000:\n",
    "            dateAdjNyseDict[each_key4] = value4\n",
    "    return dateAdjDowDict, dateAdjSp500Dict, dateAdjNasdDict, dateAdjNyseDict\n",
    "def fill_in_nulls(adjustedDicts,normalDicts):\n",
    "    for each_adj_df in adjustedDicts.keys():\n",
    "        adj_df = adjustedDicts[each_adj_df]\n",
    "        ifnull = adj_df.isnull().values.any()\n",
    "        if ifnull == True:\n",
    "            adj_df.fillna(method=\"ffill\",inplace=\"TRUE\")\n",
    "            adj_df.fillna(method=\"bfill\",inplace=\"TRUE\")\n",
    "    for each_norm_df in normalDicts.keys():\n",
    "        norm_df = normalDicts[each_norm_df]\n",
    "        ifnull = norm_df.isnull().values.any()\n",
    "        if ifnull == True:\n",
    "            norm_df.fillna(method=\"ffill\",inplace=\"TRUE\")\n",
    "            norm_df.fillna(method=\"bfill\",inplace=\"TRUE\")\n",
    "    return adjustedDicts, normalDicts\n",
    "\n",
    "dowJonesDict, sp500Dict, featuresDict, nasdDict, nyseDict = retrieve_quandl_data(dj_df, sp_df, feat_df, nasd_df, nyse_df)\n",
    "dateAdjDowDict, dateAdjSp500Dict, dateAdjNasdDict, dateAdjNyseDict = adj_for_stk_record_nums(\n",
    "    dowJonesDict, sp500Dict, nasdDict, nyseDict)\n",
    "adjustedDicts, normalDicts = create_adj_vol_and_close_dfs(\n",
    "    dateAdjDowDict, dateAdjSp500Dict, dateAdjNasdDict, dateAdjNyseDict)\n",
    "adjustedDicts, normalDicts = fill_in_nulls(adjustedDicts,normalDicts)\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_bollinger_bands(adjCloseDict, window):\n",
    "    \"\"\"Take the adjusted closing prices dataframe and compute the bollinger bands for each company,\n",
    "       using 20 day windows for now. Will adjust the window date as needed. Computes both the upper\n",
    "       and lower bands and stores them into dataframes.\n",
    "       Note, first window is blank so you need to adjust for that by using data from 20 days forward.\"\"\"\n",
    "    eachIndexBolBandsDict = {}\n",
    "    for each_key in adjCloseDict.keys():\n",
    "        each_index = adjCloseDict[each_key]\n",
    "        i = True\n",
    "        for each in each_index.keys():\n",
    "            rm_company = get_rolling_mean(each_index[each], window)\n",
    "            rstd_company = get_rolling_std(each_index[each], window)\n",
    "            upper_band, lower_band = get_bollinger_bands(rm_company, rstd_company)\n",
    "            if i == True:\n",
    "                upper_band_df = pd.DataFrame(upper_band)\n",
    "                lower_band_df = pd.DataFrame(lower_band)\n",
    "                rm_company_df = pd.DataFrame(rm_company)\n",
    "                i = False\n",
    "            else:\n",
    "                next_upper_df = pd.DataFrame(upper_band)\n",
    "                next_lower_df = pd.DataFrame(lower_band)\n",
    "                next_rm_df    = pd.DataFrame(rm_company)\n",
    "\n",
    "                upper_band_df = upper_band_df.join(next_upper_df, how='outer')\n",
    "                lower_band_df = lower_band_df.join(next_lower_df, how='outer')\n",
    "                rm_company_df = rm_company_df.join(next_rm_df, how='outer')\n",
    "        eachIndexBolBandsDict[each_key] = [upper_band_df, lower_band_df, rm_company_df]\n",
    "    return eachIndexBolBandsDict\n",
    "def get_momentum(adjCloseDict, window):\n",
    "    i,y = 0,True\n",
    "    temp_array = []\n",
    "    eachIndexMomentumDict = {}\n",
    "    for each_dict in adjCloseDict:\n",
    "        for each_key in each_dict.keys():\n",
    "            each_index = each_dict[each_key]\n",
    "            for each_company in each_index.keys():\n",
    "                each_column = each_index[each_company]\n",
    "                each_column = each_column.as_matrix()\n",
    "                for each in xrange(len(each_column)):\n",
    "                    if i > window:\n",
    "                        temp = each_column[i]/each_column[i-window] - 1\n",
    "                        temp_array.append(temp)\n",
    "                    else:\n",
    "                        temp_array.append(0.)\n",
    "                    i += 1\n",
    "                if y == True:\n",
    "                    df = pd.DataFrame(temp_array, index=each_index.index, columns=[each_company])\n",
    "                    y = False\n",
    "                else:\n",
    "                    df2 = pd.DataFrame(temp_array, index=each_index.index, columns=[each_company])\n",
    "                    df = df.join(df2, how='outer')\n",
    "                temp_array = []\n",
    "                i = 0\n",
    "            y = True\n",
    "            eachIndexMomentumDict[each_key] = df\n",
    "    return eachIndexMomentumDict\n",
    "def pe_ratio(adjCloseDict, window):\n",
    "    i,y = 0,True\n",
    "    pe_array = []\n",
    "    eachIndexPeRatioDict = {}\n",
    "    for each_key in adjCloseDict.keys():\n",
    "        each_index = adjCloseDict[each_key]\n",
    "        for each_comp in each_index.keys():\n",
    "            each_column = each_index[each_comp]\n",
    "            each_column = each_column.as_matrix()\n",
    "            for each in xrange(len(each_column)):\n",
    "                if i > window:\n",
    "                    each_return = each_column[i] - each_column[i-window]\n",
    "                    each_pe = each_column[i]/each_return\n",
    "                    pe_array.append(each_pe)\n",
    "                else:\n",
    "                    pe_array.append(0.)\n",
    "                i += 1\n",
    "            if y == True:\n",
    "                pe_df = pd.DataFrame(pe_array, index=each_index.index, columns=[each_comp])\n",
    "                y = False\n",
    "            else:\n",
    "                pe_df2 = pd.DataFrame(pe_array, index=each_index.index, columns=[each_comp])\n",
    "                pe_df = pe_df.join(pe_df2, how='outer')\n",
    "            pe_array = []\n",
    "            i = 0\n",
    "        y = True\n",
    "        eachIndexPeRatioDict[each_key] = pe_df\n",
    "    return eachIndexPeRatioDict\n",
    "def get_rolling_mean(values, window):\n",
    "    \"\"\"Return rolling mean of given values, using specified window size.\"\"\"\n",
    "    return pd.rolling_mean(values, window=window)\n",
    "def get_rolling_std(values, window):\n",
    "    \"\"\"Return rolling standard deviation of given values, using specified window size\"\"\"\n",
    "    return pd.rolling_std(values, window=window)   \n",
    "def get_bollinger_bands(rm, rstd):\n",
    "    \"\"\"Return upper and lower Bollinger Bands.\"\"\"\n",
    "    upper_band = rm + rstd * 2\n",
    "    lower_band = rm - rstd * 2\n",
    "    return upper_band, lower_band\n",
    "def normalize_data(df_dict):\n",
    "    \"\"\"Normalize the adjusted_closing_price dataframes\"\"\"\n",
    "    normalize = []\n",
    "    for each in df_dict:\n",
    "        norm_df =  each / each.ix[0,:]\n",
    "        normalize.append(norm_df)\n",
    "    return normalize\n",
    "\n",
    "eachIndexBolBandsDict = compute_bollinger_bands(adjusted_dict_array[1], 20)\n",
    "eachIndexMomentumDict = get_momentum(adjusted_dict_array[1], 10)\n",
    "eachIndexPeRatioDict = pe_ratio(adjusted_dict_array[1], 20)\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data(df, title=\"Stock prices\", xlabel=\"Date\", ylabel=\"Price\"):\n",
    "    \"\"\"Plot stock prices with a custom title and meaningful axis labels.\"\"\"\n",
    "    ax = df.plot(title=title, fontsize=12)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    plt.show()\n",
    "def plot_bollinger(adj_close_df):\n",
    "    \"\"\"Takes the rolling means and the upper and lower bands and plots the data. Currently using only\n",
    "       a 140 day graph, but can easily change to show less or more information by changing the adjusting\n",
    "       closing price dataframe.\"\"\"\n",
    "    rm_SPY = get_rolling_mean(adj_close_df, window=20)\n",
    "    rstd_SPY = get_rolling_std(adj_close_df, window=20)\n",
    "    upper_band, lower_band = get_bollinger_bands(rm_SPY, rstd_SPY)\n",
    "    # Plot raw SPY values, rolling mean and Bollinger Bands\n",
    "    ax = adj_close_df[20:160].plot(title=\"Bollinger Bands\", label='IBM')\n",
    "    rm_SPY[20:].plot(label='Rolling mean', ax=ax)\n",
    "    upper_band[20:].plot(label='upper band', ax=ax)\n",
    "    lower_band[20:].plot(label='lower band', ax=ax)\n",
    "    # Add axis labels and legend\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()     \n",
    "def compute_and_plot_daily_returns(adj_close_df):\n",
    "    \"\"\"Compute the daily return values for each company by calling compute_daily_returns() and then\n",
    "       plot the returned values for a 20 day period. This 20 day period can be adjusted as necessary\n",
    "       by increasing or decreasing the size of the adj_close_df when this function is called. \"\"\"\n",
    "    #Compute daily returns\n",
    "    daily_returns = compute_daily_returns(adj_close_df)\n",
    "    plot_data(daily_returns, title=\"Daily returns\", ylabel=\"Daily returns\")\n",
    "    \n",
    "plot_bollinger(adjusted_dict_array[0]['adjDowDict'][['IBM']][:160])\n",
    "compute_and_plot_daily_returns(adjusted_dict_array[0]['adjDowDict'][0:20])\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "52582\n",
      "11149\n",
      "436269\n"
     ]
    }
   ],
   "source": [
    "#buy/sell/nothing == actions\n",
    "#holding/shorting/bollinger/momentum/pe/rewardsinceentry == state\n",
    "#dailyreturn == reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
