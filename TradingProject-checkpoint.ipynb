{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import Quandl\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as spo\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def retrieve_data():\n",
    "    \"\"\"Retrieve the dictionaries filled with each companies dataframes in\n",
    "       both the s&p 500 and dow jones indexes, and the third dictionary\n",
    "       contains several measures of features. The data is taken from pickled\n",
    "       data files that were retrieved with an earlier retrieve data function\n",
    "       that retrieved the data from the Quandl server. If you need to add more\n",
    "       data, you need to use the previous retrieval method which will be listed\n",
    "       soon. You can also use Quandl.get(\"CODE\") where CODE is a specific quandl\n",
    "       code\"\"\"\n",
    "    \n",
    "    # Read from file\n",
    "    dow_myfile = open('dowfile.pickle', 'rb')\n",
    "    sp_myfile = open('spfile.pickle', 'rb')\n",
    "    nasd_myfile = open('nasdtotalfile.pickle', 'rb')\n",
    "    nyse_myfile = open('nysetotalfile.pickle', 'rb')\n",
    "    feat_myfile = open('featfile.pickle', 'rb')\n",
    "    \n",
    "    # Store the retrieved dictionaries in variables\n",
    "    dowJonesDict = pickle.load(dow_myfile)\n",
    "    sp500Dict = pickle.load(sp_myfile)\n",
    "    nasdDict = pickle.load(nasd_myfile)\n",
    "    nyseDict = pickle.load(nyse_myfile)\n",
    "    featuresDict = pickle.load(feat_myfile)\n",
    "    \n",
    "    # Close the files\n",
    "    dow_myfile.close()\n",
    "    sp_myfile.close()\n",
    "    nasd_myfile.close()\n",
    "    nyse_myfile.close()\n",
    "    feat_myfile.close()\n",
    "    \n",
    "    return dowJonesDict, sp500Dict, featuresDict, nasdDict, nyseDict\n",
    "\n",
    "dowJonesDict, sp500Dict, featuresDict, nasdDict, nyseDict = retrieve_data()\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_rolling_mean(values, window):\n",
    "    \"\"\"Return rolling mean of given values, using specified window size.\"\"\"\n",
    "    return pd.rolling_mean(values, window=window)\n",
    "\n",
    "def get_rolling_std(values, window):\n",
    "    \"\"\"Return rolling standard deviation of given values, using specified window size\"\"\"\n",
    "    return pd.rolling_std(values, window=window)\n",
    "    \n",
    "def get_bollinger_bands(rm, rstd):\n",
    "    \"\"\"Return upper and lower Bollinger Bands.\"\"\"\n",
    "    upper_band = rm + rstd * 2\n",
    "    lower_band = rm - rstd * 2\n",
    "    return upper_band, lower_band\n",
    "    \n",
    "def compute_daily_returns(df):\n",
    "    \"\"\"Compute and return the daily return values.\"\"\"\n",
    "    daily_returns = (df / df.shift(1)) - 1\n",
    "    daily_returns.ix[0,:] = 0 #Pandas leaves the 0th row full of NaNs\n",
    "    return daily_returns\n",
    "\n",
    "def normalize_data(df_dict):\n",
    "    \"\"\"Normalize the adjusted_closing_price dataframes\"\"\"\n",
    "    normalize = []\n",
    "    for each in df_dict:\n",
    "        norm_df =  each / each.ix[0,:]\n",
    "        normalize.append(norm_df)\n",
    "    return normalize\n",
    "\n",
    "def adj_for_stk_record_nums(nasdDict, nyseDict, sp500Dict, dowJonesDict):\n",
    "    dateAdjNasdDict,dateAdjNyseDict = {},{}\n",
    "    dateAdjSp500Dict,dateAdjDowDict = {},{}\n",
    "    \n",
    "    for each_nasd in nasdDict.keys():\n",
    "        length = len(nasdDict[each_nasd])\n",
    "        value = nasdDict[each_nasd]\n",
    "        if length > 4000:\n",
    "            dateAdjNasdDict[each_nasd] = value\n",
    "\n",
    "    for each_nyse in nyseDict.keys():\n",
    "        length2 = len(nyseDict[each_nyse])\n",
    "        value2 = nyseDict[each_nyse]\n",
    "        if length2 > 4000:\n",
    "            dateAdjNyseDict[each_nyse] = value2\n",
    "\n",
    "    for each_sp in sp500Dict.keys():\n",
    "        length3 = len(sp500Dict[each_sp])\n",
    "        value3 = sp500Dict[each_sp]\n",
    "        if length3 > 4000:\n",
    "            dateAdjSp500Dict[each_sp] = value3\n",
    "            \n",
    "    for each_dow in dowJonesDict.keys():\n",
    "        length4 = len(dowJonesDict[each_dow])\n",
    "        value4 = dowJonesDict[each_dow]\n",
    "        if length4 > 4000:\n",
    "            dateAdjDowDict[each_dow] = value4\n",
    "            \n",
    "    dateAdjustedDicts = [dateAdjDowDict, dateAdjSp500Dict, dateAdjNasdDict, dateAdjNyseDict]\n",
    "    for each_dict in dateAdjustedDicts:\n",
    "        for each in each_dict.keys():\n",
    "            df = each_dict[each]\n",
    "            ifnull = df.isnull().values.any()\n",
    "            if ifnull == True:\n",
    "                df = df.fillna(method=\"ffill\",inplace=\"TRUE\")\n",
    "                df = df.fillna(method=\"bfill\",inplace=\"TRUE\")\n",
    "                each_dict[each] = df\n",
    "    \n",
    "    return dateAdjustedDicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def create_adj_vol_and_close_dfs(adjDicts, normDicts):\n",
    "    \"\"\"Take the dow jones dataframes and create dataframe which contain only the\n",
    "       adjusted volume and adjusted closing price data. Each dataframe will contain\n",
    "       all 30 companies going across, and time going down for the past 6 years of \n",
    "       data.\"\"\"\n",
    "    adjustedDicts,normalDicts = {},{}\n",
    "    \n",
    "    i,y = True, True\n",
    "    for each_dict in adjDicts:\n",
    "        for each in each_dict.keys():\n",
    "            if i == True: # signifies first dictionary entry\n",
    "                df = each_dict[each]\n",
    "                adj_close_each_df = df[['Adj. Close']].rename(columns={'Adj. Close': each})\n",
    "                adj_vol_each_df = df[['Adj. Volume']].rename(columns={'Adj. Volume': each})\n",
    "                i = False\n",
    "            else:\n",
    "                df = each_dict[each]\n",
    "                next_adj_close_each_df = df[['Adj. Close']].rename(columns={'Adj. Close': each})\n",
    "                next_adj_vol_each_df = df[['Adj. Volume']].rename(columns={'Adj. Volume': each})\n",
    "                adj_close_each_df = pd.merge(adj_close_each_df, next_adj_close_each_df, left_index=True, right_index=True)\n",
    "                adj_vol_each_df = pd.merge(adj_vol_each_df, next_adj_vol_each_df, left_index=True, right_index=True)\n",
    "        \n",
    "        if y == True:\n",
    "            adjustedDicts['adjDowDict'] = [adj_close_each_df,adj_vol_each_df]\n",
    "            y = False\n",
    "        else:\n",
    "            adjustedDicts['adjSpDict'] = [adj_close_each_df,adj_vol_each_df]\n",
    "        i = True\n",
    "    \n",
    "    i,y = True,True\n",
    "    for each_norm_dict in normDicts:\n",
    "        for each_sp in each_norm_dict.keys():\n",
    "            if i == True:\n",
    "                sp_df = each_norm_dict[each_sp]\n",
    "                adj_close_sp_df = sp_df[['Close']].rename(columns={'Close': each_sp})\n",
    "                adj_vol_sp_df = sp_df[['Volume']].rename(columns={'Volume': each_sp})\n",
    "                i = False\n",
    "            else:\n",
    "                sp_df = each_norm_dict[each_sp]\n",
    "                next_adj_close_sp_df = sp_df[['Close']].rename(columns={'Close': each_sp})\n",
    "                next_adj_vol_sp_df = sp_df[['Volume']].rename(columns={'Volume': each_sp})\n",
    "                adj_close_sp_df = pd.merge(adj_close_sp_df, next_adj_close_sp_df, left_index=True, right_index=True)\n",
    "                adj_vol_sp_df = pd.merge(adj_vol_sp_df, next_adj_vol_sp_df, left_index=True, right_index=True)      \n",
    "    \n",
    "        if y == True:\n",
    "            normalDicts['normNasdDict'] = [adj_close_sp_df, adj_vol_sp_df]\n",
    "            y = False\n",
    "        else:\n",
    "            normalDicts['normNyseDict'] = [adj_close_sp_df, adj_vol_sp_df]\n",
    "        i = True\n",
    "            \n",
    "    return adjustedDicts, normalDicts\n",
    "\n",
    "dateAdjustedDicts = adj_for_stk_record_nums(nasdDict,nyseDict,sp500Dict,dowJonesDict)\n",
    "adjCloseDicts = [dateAdjustedDicts[0],dateAdjustedDicts[1]]\n",
    "normCloseDicts = [dateAdjustedDicts[2], dateAdjustedDicts[3]]\n",
    "adjustedDicts,normalDicts = create_adj_vol_and_close_dfs(adjCloseDicts, normCloseDicts)\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compute_bollinger_bands(adj_close_df_indexes, window):\n",
    "    \"\"\"Take the adjusted closing prices dataframe and compute the bollinger bands for each company,\n",
    "       using 20 day windows for now. Will adjust the window date as needed. Computes both the upper\n",
    "       and lower bands and stores them into dataframes.\n",
    "       Note, first window is blank so you need to adjust for that by using data from 20 days forward.\"\"\"\n",
    "    \n",
    "    eachIndexBolBandsDict = {}\n",
    "    for each_index in adj_close_df_indexes:\n",
    "        i = True\n",
    "        for each in each_index:\n",
    "            rm_company = get_rolling_mean(each_index[each], window)\n",
    "            rstd_company = get_rolling_std(each_index[each], window)\n",
    "            upper_band, lower_band = get_bollinger_bands(rm_company, rstd_company)\n",
    "\n",
    "            if i == True:\n",
    "                upper_band_df = pd.DataFrame(upper_band)\n",
    "                lower_band_df = pd.DataFrame(lower_band)\n",
    "                rm_company_df = pd.DataFrame(rm_company)\n",
    "                i = False\n",
    "            else:\n",
    "                next_upper_df = pd.DataFrame(upper_band)\n",
    "                next_lower_df = pd.DataFrame(lower_band)\n",
    "                next_rm_df    = pd.DataFrame(rm_company)\n",
    "\n",
    "                upper_band_df = pd.merge(upper_band_df, next_upper_df, left_index=True, right_index=True)\n",
    "                lower_band_df = pd.merge(lower_band_df, next_lower_df, left_index=True, right_index=True)\n",
    "                rm_company_df = pd.merge(rm_company_df, next_rm_df, left_index=True, right_index=True)\n",
    "        \n",
    "        if eachIndexBolBandsDict == {}:\n",
    "            eachIndexBolBandsDict['dow'] = [upper_band_df, lower_band_df, rm_company_df]\n",
    "        else:\n",
    "            eachIndexBolBandsDict['sp500'] = [upper_band_df, lower_band_df, rm_company_df]\n",
    "\n",
    "    return eachIndexBolBandsDict\n",
    "\n",
    "def get_momentum(adj_close_df_indexes, window):\n",
    "    i,y = 0,True\n",
    "    temp_array = []\n",
    "    eachIndexMomentumDict = {}\n",
    "    for each_index in adj_close_df_indexes:\n",
    "        for each_company in each_index.keys():\n",
    "            each_column = each_index[each_company]\n",
    "            each_column = each_column.as_matrix()\n",
    "            for each in xrange(len(each_column)):\n",
    "                if i > window:\n",
    "                    temp = each_column[i]/each_column[i-window] - 1\n",
    "                    temp_array.append(temp)\n",
    "                else:\n",
    "                    temp_array.append(0.)\n",
    "                i += 1\n",
    "            if y == True:\n",
    "                df = pd.DataFrame(temp_array, index=each_index.index, columns=[each_company])\n",
    "                y = False\n",
    "            else:\n",
    "                df2 = pd.DataFrame(temp_array, index=each_index.index, columns=[each_company])\n",
    "                df = pd.merge(df, df2, left_index=True, right_index=True)\n",
    "            temp_array = []\n",
    "            i = 0\n",
    "        y = True\n",
    "        if eachIndexMomentumDict == {}:\n",
    "            eachIndexMomentumDict['dow'] = df\n",
    "        else:\n",
    "            eachIndexMomentumDict['sp500'] = df\n",
    "\n",
    "    return eachIndexMomentumDict\n",
    "\n",
    "def pe_ratio(adj_close_df_indexes, window):\n",
    "    i,y = 0,True\n",
    "    pe_array = []\n",
    "    eachIndexPeRatioDict = {}\n",
    "    for each_index in adj_close_df_indexes:\n",
    "        for each_comp in each_index.keys():\n",
    "            each_column = each_index[each_comp]\n",
    "            each_column = each_column.as_matrix()\n",
    "            for each in xrange(len(each_column)):\n",
    "                if i > window:\n",
    "                    each_return = each_column[i] - each_column[i-window]\n",
    "                    each_pe = each_column[i]/each_return\n",
    "                    pe_array.append(each_pe)\n",
    "                else:\n",
    "                    pe_array.append(0.)\n",
    "                i += 1\n",
    "            if y == True:\n",
    "                pe_df = pd.DataFrame(pe_array, index=each_index.index, columns=[each_comp])\n",
    "                y = False\n",
    "            else:\n",
    "                pe_df2 = pd.DataFrame(pe_array, index=each_index.index, columns=[each_comp])\n",
    "                pe_df = pd.merge(pe_df, pe_df2, left_index=True, right_index=True)\n",
    "            pe_array = []\n",
    "            i = 0\n",
    "        y = True\n",
    "        if eachIndexPeRatioDict == {}:\n",
    "            eachIndexPeRatioDict['dow'] = pe_df\n",
    "        else:\n",
    "            eachIndexPeRatioDict['sp500'] = pe_df\n",
    "        \n",
    "    return eachIndexPeRatioDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "adj_close_df = [dow_adjusted[0],sp_adjusted[0]]\n",
    "eachIndexBolBandsDict = compute_bollinger_bands(adj_close_df, 20)\n",
    "eachIndexMomentumDict = get_momentum(adj_close_df, 20)\n",
    "eachIndexPeRatioDict = pe_ratio(adj_close_df, 20)\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def plot_data(df, title=\"Stock prices\", xlabel=\"Date\", ylabel=\"Price\"):\n",
    "    \"\"\"Plot stock prices with a custom title and meaningful axis labels.\"\"\"\n",
    "    ax = df.plot(title=title, fontsize=12)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_bollinger(adj_close_df):\n",
    "    \"\"\"Takes the rolling means and the upper and lower bands and plots the data. Currently using only\n",
    "       a 140 day graph, but can easily change to show less or more information by changing the adjusting\n",
    "       closing price dataframe.\"\"\"\n",
    "    rm_SPY = get_rolling_mean(adj_close_df, window=20)\n",
    "    rstd_SPY = get_rolling_std(adj_close_df, window=20)\n",
    "    upper_band, lower_band = get_bollinger_bands(rm_SPY, rstd_SPY)\n",
    "    # Plot raw SPY values, rolling mean and Bollinger Bands\n",
    "    ax = adj_close_df[20:160].plot(title=\"Bollinger Bands\", label='IBM')\n",
    "    rm_SPY[20:].plot(label='Rolling mean', ax=ax)\n",
    "    upper_band[20:].plot(label='upper band', ax=ax)\n",
    "    lower_band[20:].plot(label='lower band', ax=ax)\n",
    "    # Add axis labels and legend\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()    \n",
    "      \n",
    "def compute_and_plot_daily_returns(adj_close_df):\n",
    "    \"\"\"Compute the daily return values for each company by calling compute_daily_returns() and then\n",
    "       plot the returned values for a 20 day period. This 20 day period can be adjusted as necessary\n",
    "       by increasing or decreasing the size of the adj_close_df when this function is called. \"\"\"\n",
    "    #Compute daily returns\n",
    "    daily_returns = compute_daily_returns(adj_close_df)\n",
    "    plot_data(daily_returns, title=\"Daily returns\", ylabel=\"Daily returns\")\n",
    "    \n",
    "plot_bollinger(adj_close_df[0]['Nike'][:160])\n",
    "compute_and_plot_daily_returns(adj_close_df[0][['IBM','Nike','Visa']][0:20])\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(adjustedDicts['adjDowDict'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
